
2025-FALL / ECSE-324-001
Captions
Search current recording by keyword
Brett Meyer, Prof: Yay! After that brief delay, let's get started. Before we dive into, or dive back into lecture material, I just wanted to draw your attention to the fact that the midterm is 3 weeks from today. That includes your reading break, which I completely forgot about until today. The last material that is covered on the midterm is the stuff we'll talk about on Wednesday. So then you have plenty of time to get your head wrapped around all the stuff that we've been talking about. I definitely encourage you to make good use of the lecture channel in Teams. ask questions, come to office hours, whatever, get the support that you need. A big part of the… midterm? is going to be understanding and working with assembly code, so it definitely benefits you to get going on Lab 2. Lab 2 is due shortly after the break, and about a week before the midterm. But I can tell you today that what lab… what the midterm is going to look like is I'm going to give you two implementations of the same assembly language program, and then ask you a bunch of questions about them. That's most of what the exam is. So, don't wait to dive into assembly language programming. The more time you have with it, the easier time you'll have understanding how it works and everything. And, after today, you'll have been… you'll have heard in lecture all the stuff that you need to do all of it, instead of just the first part. Yes? Well, so, I don't think they're sensible to choose one or the other. And, because reviewing notes only helps you if you know what you don't know. So I think it makes sense to start doing practice problems where you do not download the solutions. Don't do it. Don't walk through the solutions, don't walk through the problems with the solutions there, because then you won't know what you don't know. And work on problems, and figure out where you get stuck. And then review based on where you get stuck. There really isn't a lot of sense going over and over and over the lecture material unless you have identified places where you don't understand things. And yeah, there's a million practice problems to go and do. The IDEN, I think, is going to be doing a midterm review session. I think that's also… yeah, that's… the first two tutorials right… or the last two tutorials right before the midterm are going to be midterm review sessions. That's on the 23rd and 24th. He'll be going through the last midterm that I wrote, that's winter 2024. The tutorial questions have… tutorials have been largely, when appropriate, based on the previous midterm that I wrote. There's a bunch of midterms to go and look at. Looking at Professor Dubach's midterms is also useful. I don't tend to write questions the exact same way that he does, but his questions will definitely test your understanding of the material in the same way that mine will. So, lots and lots of problems. You want to be starting that sooner rather than later. Any questions about logistics? Okay. We've got Lab 1 graded, we'll… I could have the grades posted, sometime early this week. Okay. So… Last thing that we did last week was we started looking at this big program. And, this is the second version of it that we looked at. And this big program is kind of like some of the first big programs that you might have written, where everything is just in main, no function calls. We didn't talk about function calls yet, because they take special care in feeding, and so we're going to spend a lot of today talking about how function calls work, and the mechanisms that enable them Especially the stack. So, you've written code with function calls before. You've probably not written assembly with function calls. But just like… any control flow operation, we're gonna use branching. We're just not going to use branching the way that you've been exposed to it in the past. And the next few code examples will illustrate why. So we have this simple program in C over on the left, where main calls a function increment counter. And all the… all the, function does is it modifies a global variable, and then returns. So, in our assembly, we can set the value of the counter to be 0 at initialization, just like the C code. We can write some code implementing the function. And then there's this question, How do we get there? Well… We can use a label to identify where the function starts, and then you can branch. Seems simple enough. But now we have a problem. What's the first problem that we have here on this slide? Yeah, Santiago. Yeah, that's the… that's the issue here. When the function ends with the last store instruction, the next instruction to execute is the branch, and so we essentially have an unintentional infinite loop. We never reach statement 1, which is what we're supposed to do after we increment the counter. So we can branch to get into increment counter, but we have to have a way of getting back out. We need to return from the function. So we can do that, too, with another branch. So we put a label in for statement 1, Guess we had one before. And then at the end of the function. we go back to where we were. Let's see, do I have a build there? No, I don't. What's the problem with this? This is not a general solution. Why not? Have you ever called a function from more than one place? That's sort of the point of functions. There isn't really a point to have a function that you only call in one place unless the purpose is just code organization. You're not saving anything, it's actually making your code less efficient because you have to branch to it and then branch back out. You're wasting compute if you only have a function that's used one place, and you're not saving code size. The whole point of functions is reuse. Libraries are all about code reuse, but we can't do code reuse here, Because my function returns To exactly one place! That's a problem. Can't do recursion this way. It's actually impossible. So… If I wanted to call my function two times, I don't have a way To make this code work with a simple branch instruction. Because I haven't… I don't have a way here to specify where I should go back to. Branch instructions, conditional or otherwise, that you've seen so far, have a single place that they are thinking about going. A single label So we need something more sophisticated than this. And this is where the link register comes in. Some time ago, the link register was mentioned along with the program counter and the stack pointer as being a special purpose register, and we didn't really talk about how it was used. This is where the link register is used. Its sole purpose Is to enable function returns. So, we have a second branch instruction. BL is not branch less. It's branch and link. And yes, you can have a conditional branch in length, you can say BLLT, For branch and link less than. But in general, in this particular case, we don't want a conditioned function call, we just want to make the function call, so BL, branch and link. And what branch and link does… is… it saves… The value of the program counter for the next instruction after the branch and link instruction into the link register, and then it goes to the address that is specified. So… What we can do, down here in the bottom, is instead of B, we can say BL. And then the link register will be… will save The next location in instruction memory as the place we're supposed to return to. So then the link register has our return address. And we have a third branch instruction, BX, BX, we do not specify an address label in assembly, we instead specify a register. If we do BXLR, then the value of the link register goes into the PC, and we go to the instruction that follows the branch and link instruction. Why? for branch and link, is PC-4 going into the link register? Does that mean I'm going backwards? ARDA. Because of pipelining, So… Right. That's right. So, because of pipelining, By the time we are actually doing the execute stage of branch and link. PC is PC plus 8 relative to that instruction. But we don't want to skip the next one. So we have to do PC plus 8 minus 4, that's where we're trying to go to when we return from a function. Because whenever we're in the execute stage of an ARM version 7, processor. The program counter is already two instructions ahead of the one that is executing. Okay, so we go back to our example. If we rewrite it like this, then we're good. We branch in Link for the first call in Maine. That saves the address of the second branch and link instruction in the link register. And then we go into the function. when we BXLR, we return to that location. the program counter gets that value, which means that the next instruction to be executed is the second branch and link instruction. And when that executes, it saves in the link register whatever the first instruction is at statement 2. And then it goes into the function, and then it can return to that spot. And continue on. And now we can write functions that we can call from anywhere, and we will be able to get back there without any problems. Questions? This resolves most of the issues with subroutine calling. It doesn't yet allow us to do… Recursion, though. We will see how we do that in just a little bit, but you can write a whole lot of programs Just with these two extra instructions, branch and link, and BX. Branch to an address in a register. This look good? Okay. So… The next issue to be addressed is, what if I have nested function calls? So, in my program here on the left. main calls boo, which calls coo, and then coo executes and then returns. So, in main. when I call Boov, the address for M gets saved into the link register. And then when I'm in CU, the address for B gets saved in the link register. But now, I don't have what I saved to get back to Maine anymore. It can't just do nested function calls with this current functionality. Because I just overwrote my link register, now I can't get back. I'll never… You can never go home again. To fix this, we need something more flexible, especially if you think about recursion, Where… you might call a long series of functions in order to do the thing that you want to do. We don't need to return a fixed number of times, we kind of need a structure that will allow us to return an arbitrary number of times to get back to Maine without ever losing the location in Maine that we need to return to. I don't know how much… Time you spend using a debugger, but if you're programming with a debugger instead of with print statements, you can actually look at the call depth of your program. At a particular point of execution, and you might be 8 or 12 or 20 function calls deep. we need to be able to keep track of 8 or 12 or 20 return addresses in order to be able to get back to Maine so our program can actually end. So, we do that with a stack. And you are familiar with stacks, yes? You cover this in your data structures class? Fabulous. So… This is review, then. The way a stack operates, it's last in, first out. We push stuff onto the top of the stack, and then we pop stuff off of it, and if you want, you can peek at the values that are there, and it's sometimes useful to have ways to know whether or not something is Empty. I bet when you implemented a stack in a data structures class, you had function… extra function calls to do that. The stack in… that we use in computing for this particular purpose, we don't necessarily care too much about whether or not it's empty. Because if you write your program correctly. It'll only ever be empty when it's supposed to be. the emulator that you'll be using, or already using for Lab 2 will tell you when you've messed something up. It checks what the stack pointer value is before you go into a function and after, and if there's a mismatch, then we've got a problem. And it'll tell you so, which is very handy. So remember, 32-bit address space. That's from 8 zeros to 8Fs, that's how many different addresses we have. And… In this class in general. Our program lives at small addresses, starting from zero. Data that we allocate for our program tends to live… to live nearby. the stack… Starts at the other end. The top of the stack is the last word in the address space. at FFFFFF. C? And the stack grows up in this diagram. Whereas the heap… grows down. You've probably… have you heard of the heap before? You have. Happy day! So, inside of data, that's where statically allocated data goes, data that the compiler or the assembler knows about when it's doing its assembling or compiling. The heap is where dynamically allocated data goes. If you ever call malloc, or if you ever say new, space is allocated in the heap. The heap grows from one end, the stack grows from another. We talk about the stack enabling Theoretically, infinite function calling, but it's not really infinite, because at some point, your stack will run into your heap, and then you're out of memory, and your program crashes. But as long as you have enough memory. You can have very, very, very deep call stacks. by… we're gonna save a bunch of information on the stack, actually, between function calls. And as long as you don't ever allocate so much stack that you run into stuff that you've allocated on the heap, then you're fine. In this class, we have no heap, because you're programming entirely in assembly without an operating system that is keeping track of where dynamically allocated memory is available. In this class, you only have text. data that's basically intact anyway, and stack. And… So, with the kinds of programs that we're writing, you will never run out of memory. I don't think it's possible. Unless you set out to do it very intentionally. I guess if I had you do… actually, I guess… You do have a recursive function that you have to implement, and if you do it wrong, you might ride out of memory. If you get into an infinite loop of recursive calls, eventually your stack will grow into your text and data section. But, That takes hard work and a lot of patience while you wait for the emulator to run. I saw a hand up someplace. Yes, William. And then you set a seat. Right, because FFF… FFFFFFF is the last byte in memory, but the word… for that, starts at… C? Does that make sense? Okay. Alright. So, in ARM version 7, The stack pointer is a register in your register file, like the program counter. Not all instruction set architectures put the stack pointer in the register file. For others, it's a special purpose register, like the CPSR. For the instruction register. R13 is our stack pointer. Just as a little tip when you're messing around with the emulator, sometimes when you hit reset. The stack pointer might not go back to zero, which is what you want it to be whenever your program starts. If it's not, You might get different behavior, different times you run it, so always, when you're debugging, go and make sure that the stack pointer is zero when you're restarting execution. I don't know why it doesn't automatically do that when you press the reload and other stuff, but it… when you press reload in your… in the emulator, it doesn't reset the values of registers, for whatever reason. Some things to note about the stack. The stack is word-aligned. You are not allowed to push You're not allowed to put A half word on the stack. You're not allowed to put a byte on the stack. Only words on the stack. And the stack pointer, since the stack is word-aligned, the stack pointer address must always be divisible by 4. I can't remember what the emulator might or might not complain about this. Real hardware complains about this. Because it's a way of basically checking that your, use of the stack is following the rules. Let's see… So… We have some push and pop instructions. Like you'd expect. Simple push and pop, or just loads and stores. Because the stack is word-aligned, we're doing LDR and STR, rather than LDRH or whatever. And… when I push, I have that top store instruction. The stack pointer is always pointing at the current top of stack. So I don't want to write a new element there, I want to decrement the stack pointer and then write there. So we see our RTL for the push instruction is SP gets SP-4, and then we write to that location. And the assembly for that can be captured in a single instruction in ARM version 7. We have the brackets around our effective address, and the exclamation mark says, update the stack pointer with the address inside of the effective address calculation. We could write this in more than one instruction. We could perform a subtract on the stack pointer, and then just perform a store. But ARM version 7 allows us to do it in a single instruction. And then when we pop, we do the opposite. We read from the location pointed to by the stack pointer, and then we increment by 4. We tend to push stuff onto the stack when we go into functions. We pop stuff off the stack when we go out of functions. Just like in C and Java, you should have a delete Every single time you have a new, they should match, but you don't run out of memory. We need to do the same thing in ARM assembly. For every push we have, we ought to have a corresponding pop, otherwise, our program's not going to work. If you ever want to know what's on the stack without pushing or without popping it off, you can just perform a normal load. Using the stack pointer as the base address, and some constant offset from it. This is super useful for cases where we put arguments to functions on the stack. And then we want to look at them. For manipulation inside of the function. Yes, Santiago. At that pointer, when you start up your program, will be initialized to zero. When you push the first thing on the stack, 0 minus 4 is FFFFFFFC. That's where the data will go. You push another time, Minus 4, F, F, F, F, F, F, F. 8. That's where the data will go. Sort of from the way our picture is drawn here, it'll be sort of the next word up, the next word up, the next word up. I could also flip this upside down and have low addresses on the bottom, and then the stack starts at the top, and then sort of grows down, and… and so on. Yes. The green at the top. You can peek at whatever address you want. the SP stay the address? Yes. So if we look at our load instruction here, we have our effective address calculation, SP plus a constant, but there's no exclamation mark, so we're not modifying it. And there's no 4 outside of the effective address calculation, so we're not modifying it. That load instruction there does not change the stack pointer. The other two do, just in different ways. The other two memory axes change the stack pointer. Okay, so we talked about load multiple and store multiple. A lot of the architecture of load multiple and store multiple is designed around pushing and popping. For instance, we talked about how Load multiple and store multiple. End up putting things on into memory or out of memory in sort of opposite order, based on the register indices. that's to support pushing and popping. So I can say, I can specify, in ARM version 7, I can specify push RJ, pop RJ, those are the load and store instructions that those are. I can also say push, and then in curly braces, put a whole bunch of registers, and then that becomes a store multiple. for all of those different registers, and it updates the stack pointer. A single instruction, and it's going to write 1, 2, 3, 4 registers onto the stack. And… I think push does it from left to right, and pop does it from right to left. So if I do push, and then I do pop. whatever I pushed out of R1, I will pop back into R1, because the order in which the memory accesses are performed is the opposite. One is the opposite of the other. Remember that the order in which you write them in the curly braces has no effect on the operation of the instruction. The order is purely defined by the instruction itself, either from least register to highest register, or highest register to least register. You don't get to control the order. Also remember that this is sort of special to ARM version 7. ARM version 8 does not have this. In ARM version 8, if you want to push multiple registers onto the stack, you need a separate instruction for each one of them. Because this is not pipeline friendly. So it's not high-performance friendly. Yes, Arda. Yes. So we decreased the spec record before loading. Before storing, yes. Nope. the clicker. Value… DoorMultiple only ever works with words. So it's always 4. You can't store multiple things smaller than words. Same deal, it's always words. So, the only… we have special instructions for doing… Half words, or bytes, LDRH, LDRB… But LDR and LDM… Both work with 4 byte words. Maeve, you had your hand up. So the exclamation there means the same thing that it means here. At a high level, the exclamation mark says, update this register that I'm using to calculate my addresses. So here, we want to… we're updating the stack pointer to be SP equals SP minus 4. Here, we're going to be updating the stack pointer to be whatever it ought to be, to point to the next location after we've done all of that. storing. Did that answer your question? Awesome. The exclamation mark, Means update the register. After my memory access. Okay. So… Here's back… here we are back looking at our nested function calls. Main calls… Boo. So, the… main saves LR. Does X mean… I think Professor Dubak updated this slide, so just give me a second to actually… Figure this… out. Okay, so the… when main saves LR with the branch and link instruction. the top… there's nothing at the top of the stack, or it's X. It's empty, so don't care. When main saves LR at the branch and link, the return address, the location M, is in the link register. So then, maine calls Boo. And then inside of Boo. We have to save the value inside of the link register, so that we can get back there. after we call the following function. So we put M, which is where I'm supposed to go back to in main, into the stack. And then, from Boo, we call coup. And then, inside of crew, there's no additional function call, so we don't have any other, operations in the stack. When we're in there. B, which is the label inside of Boo, is what's inside of the link register. Boo returns, using the value of the link register, And… When that happens. We have to then restore the previous value of the link register to that register. Where's that value? It's on the stack. It's M. So, we have to pop M off the stack, back into the link register, and then we can BXLR from boo to get back to main. Basically, every time you have a function that calls another function, you have to save the previous value of the link register. On the stack, so that you can get back to it. And with that simple protocol, it doesn't matter how many function calls deep you go. If this function calls a function, you save the link register, and it doesn't matter how many more times that has to happen, as long as you do that, you'll be able to put stuff onto the stack, and then follow your trail back home. It turns out that the link register is not the only register that we might want to push onto the stack when we call a function. So let's make things more complicated now. More C code. We've got main at the bottom, main calls max. We want to find the maximum of 1 and 2, and then add 3 to it. That's what's happening in Maine. So we want to figure out how to get those values to our max function so it can use them and then return the maximum value between A and B back to us. that we can… Writes our max function. It's useful when you're writing functions to put the assumptions that you're making about them in comments above, just so… it's always useful in assembly language programming to write comments where you state what your intended purpose is, because sometimes you might state your purpose and then write assembly that's different, and you're trying to debug, and you might want to Make sure that you can line up stated purpose and actual implementation. So, Max is being implemented with arguments in R0 and in R1. And then the code is comparing them. We're forming a subtract. and updating the, the program status register, the CPSR, That gives us the ability to do MoveGT and moveLE. No branch instruction used to implement our if-else. We just have two conditionally executed instructions. One that moves R0 into R0. didn't really need to do that. And another that moves R1 into R0. Our return value… is in R0 in this case. We pass arguments into this function with R0 and R1, we're getting values out of it using R0. It turns out that that's pretty much the convention in ARM version 7. We'll talk about that in more detail here. But that's how we're getting information in and out of this function. And then, in order to implement what's happening in main, we just put the values that we want in R0 and R1, For the sake of safety, we can push the link register, call branch and link to go to max, pop the link register to restore the previous return value. Because if you're just… if you're not writing all of your software, you don't know if the next function is going to call multiple functions, maybe you want to protect your stuff anyway. And then the last instruction there is an add We save the result in R11, 3 plus R0, And that finishes our calculation. in ARM, There's another multi-hundred-page document for you to decide not to read. The arm procedure call standard. It defines how compilers write assembly when it's assembling functions. If everyone follows the rules specified in the RM procedure call standard, then everyone can write code that will work well together. Because it says, this is how you pass arguments to functions. These are the… Registers that functions can change, without telling you, and other stuff like that. So, in ARM version 7, R0 through R3, otherwise known as A1 through A4, are the argument registers. A compiler that is passing arguments to a function that requires 4 or fewer arguments will use registers R0 through R3, starting with R0. And you should do that, too. And that's why this is okay. At the start of main, R0 has 1 in it, but when the function call returns, R0 has our answer in it. The ARM procedure call standard says that when I'm calling a function, I shouldn't expect anything that I have in R0 through R3 to still be there after I get back from the function call. If I care about it, I need to save it myself. Because the function is going to use R0 through R3 to return information to me. The argument registers are also known as scratch registers. The compiler will use them for intermediate computations. Anything that's in R0 through R3 before the function call might not be there afterward. That's how we pass information back and forth. So, let's see. That's what I thought. So here's a list of our 16 registers. And… the ARM procedure call standard, Species the rules. For how each of these different registers are used by functions. Again, R0 through R3, or A1 through A4. On exams, I don't tend to use R0 through R15, I tend to use the other names, A1 through A4, V1 through V8, Jack Pointer LRPC. I don't use R0 through R15 in general on exams. In functions, We use A1 through A4 to pass arguments, Or for calculations. A function that uses those does not have to save the old value. Therefore, before I call a function, if I care about what's in there. I need to save it myself. It turns out that that's essential for recursion to work. V1 through V8? If a function that you call uses those, it has to save the old value that was in there first. I can push V1 onto the stack, and then I can change the value of V1 and use it for intermediate calculations, whatever, and then before I return, I have to pop V1 back into place so that I return the function… I return the state of the computer exactly the way I found it. A1 through A4 can get trashed by function calls, but that's it. Anything else that a function uses, it has to fix up before it returns. Leave the register file cleaner than the way you found it. We… For your purposes in this class. R11 and R12 are just additional general-purpose registers. R12 is used by compilers, The intra-procedure scratch register to, set up and tear down function calls. The frame pointer… The frame pointer is also talking about the stack. It's used by debuggers and other such things to point to the beginning of the stack before a function was entered. MakeStack relative addressing straightforward. You likely won't ever find a need to use R11 as a frame pointer in this class. Guys have a question? Yeah. Bye, appreciate it. Like, helping it. Which one? So… Why am I looking for? So, we push… We push the link register before we call branch and link, because when we call branch… when we do the branch and link instruction, we're going to be overwriting the value in the link register. So if what's in there is something that I care about. then I want to save it, because the branch and link instruction is going to override it. And… 107. registered. Absolutely. So… You see my… my program over here on the left, Void Main? I don't have an explicit return statement in there, but it does return. Because in a operating system, Maine is called by something. And so if I want to be able to return to what's called main, so that I can start to unwind my program, deallocate memory, hand control back to the operating system, I have to have a way of getting back there. So there is… after main executes, there's a place I'm supposed to return to, a program counter value. that I'm supposed to return to, to clean up the execution of my program. So, that's what's in the link register when main starts. And then I push LR in order to save that, because otherwise I lose it when I have the branch and link instruction. And then after the branch and link After the function returns with BXLR, back to the pop instruction there, then I can restore that link register value. whatever was on the stack is going back into the link register, and that value is wherever I go after main is done. Does that answer your question? Fabulous. Awesome. Pushing and bumping up our gear is just in case. Yes. That's right. The push and pop here is just in case the main function is a callee. In all of the stuff that you will write for this class. Your start, which is essentially your main, is not a callee. It's not being called by an operating system, there is no place to return to, so in your programs for this class in main, you don't have to push LR or pop it, because LR is gonna be arbitrary. Because it will not have been written to, to get into starch. But every other function that you write, if it calls another function, you have to push the link register, because otherwise you can't return. Okay. So, here's… that's just a different implementation? Yeah. So here's a different implementation of our program. In this version. Instead of overwriting R0 right away, you can see our MoveGT and MoveLE, they copy from A1 into V1, or A2 into V1. V1 is just R4, the first variable register, that is a callee save. A1 through A4 are caller save. So if… Max… is going to change the value of V1. We have to first push onto the stack the old value. Then we can mess it up. It's like you take a picture of a blackboard before you erase it, so that you can redraw what was on there when you're done. We take a picture of the state of V1, erase it by writing a new value to it, unrelated to the previous value, and then when we're done, we restore the old value of V1. But still note here that at the end, the last instruction of my function is actually to copy V1 into A1, because that's how I'm returning the computation of this function. And since this function does not call any other function, I don't need to also push the link register. And so then our… Codes down here. we can put 3 into V1, And max, the max function will change V1 from being 3 to being either 1 or 2, but then it will restore 3, And so then I can still do V1 plus A1, and it'll be 3 plus… 2 in this particular example, five. And this is perfectly legal assembly. If you want to go try it out yourself, just copy-paste from the lecture notes into the emulator. What are we doing next? Questions about this? Cool. So, there's still additional issues to consider. What if, for instance, we need to pass more than 4 arguments? Or what if our arguments don't fit neatly into 4 words? In that case, we have no choice but to use the stack. So, this… if I want to pass a struct as an argument to a function. One reason to use pointers is you could pass a pointer to the struct, and then you have no problem, because the pointer to the struct is just a 32-bit memory address. But if I want to put the… if I want to pass by… Value, rather than by reference. that I'm passing those 5 integers, A, B, C, D, E, those are… that whole struct that contains that is the argument that I'm sending to my function. Then… I can't just use A1 through A4, and I can't use any other registers to pass arguments, and so I have to use the stack, at least in part. Now, I don't actually know how the compiler would handle this. I am trusting Professor Dubac and the way that he wrote this slide. Because the way he wrote this slide is that… The first 4 integers Here, go through… The registers that we have for passing arguments, and then the fifth goes on the stack. It is perfectly legal for the compiler to just decide to put all of them on the stack. But that's slower. Why? The stack is in memory. So to push things onto the stack, I have to store to memory. And to read things from the stack, I have to… to pop things from the stack, I have to read from memory. So we don't want to use the stack unless we have to. Because memory accesses are slow. So… If I'm going to implement SUM where A through D are in registers and E is on the stack. And I want to return a sum of the five values. then I can… Add A and B, temporary value in C, temporary value in D, in those first three instructions. And then, I have to read… peek into the stack to get the value for E, and then I can add it. Why is E there? I would have expected it to… load from just the stack pointer, rather than the stack pointer plus 4. But maybe I'm missing something. So then… We're loading the value of E from the stack. I'm gonna check this assembly after class today, and update it if necessary. We get the value E off of the stack, and we can add that to our running sum And then we can return. Now, the way we set this up to make this call work in the first place. We have to put all the values that we want into A1 through A4, and then we have to… push, The final value… The fifth parameter onto the stack. That's gonna subtract 4 from the stack, update the value, update the stack to point to that location. Oh, that's why. Then, this code here… Pushes the link register. So… Chalk. So first, the stack pointer is pointing to the top of stack. There might be something there, we don't know, and it doesn't matter. When we push V2 onto the stack. That pointer decrements, and then we get… Whatever the value of V2 is, which is undefined here, let's say it's 6. And then we push LR, And so stack pointer goes down to here, and then the value of LR is, I don't know, it doesn't matter, we'll say it's that. And so then, when we're actually inside of the sum. when we want to get the value E, out of memory. stack pointer is pointing to the return address that I pushed onto the stack. If I want to get to the number 6, I need to do stack pointer plus 4, that's where the argument is. I wouldn't write the assembly this way. The link register is being pushed right before the function call here, just to remind us all that it's important to do that. But I wouldn't… I would actually push link register at the start of main. Anytime I'm inside of a function that calls a function, I push link register right away. And then if I'm putting things on the stack before a function call, I don't have to worry about… Whether or not the link register is in the way. then the stuff that's at the top of the stack is just gonna be whatever I need for the function sum here. But the math works out. Yes, Basam? The question is, does pushing both at the same time, like if I did push V2 comma LR instead of push V2 push LR, which one is computationally more efficient? Which is the first one? Pushing them both at the same time is more computationally efficient. We can figure that out by counting up the number of clock cycles. If I'm gonna push two registers, I fetch, I decode, and then I've got two cycles and execute. Four. In the next case, It's interesting. I fetch, I decode, I execute. But overlapped with decode is fetch. And overlapped with execute is decode. And then, one cycle later, I have my execute. Also, 4. It takes the same amount of time, But… This implementation uses up more memory to store my instructions. So it's… Almost a break-even. But having a… using store multiple instead of… Store and then store? Would save code size. Did that answer your question? Because I… instead of storing two instructions, I only… instead of saving two instructions in memory, I only save one. I can… Instructions are data. The more instructions I have in memory, the more memory I need. So, if I have ways of compressing a bunch of instructions into fewer instructions, that literally saves money. Justin. So that's… I mean, possibly. If fetching takes one clock cycle, then it… For the purposes of this class, It… isn't slower. In real computers, It is… It can, it can possibly be slower to have two instructions, because my second… the second access for the second push instruction might not take the same amount of time as the first one. Because of caching, which we will talk about later in this class, So that's another reason that having… like, in general, we want to try to minimize the number of memory accesses that we have. Using two push instructions does not minimize the number of memory accesses that we have. For the purposes of this class, we don't concern ourselves too, too much about that, because we don't really get into the details of what can go wrong. But Computer Architecture 425 goes into that stuff in great detail. Does that answer your question? Does that confirm your suspicion? Okay. So the last little line here, I think… oh, last two lines. You push twice, But we only popped once. Which means that after POPLR, The stack pointer is NOT the same value as it was before we did all this pushing. So I have a last instruction here to reset the stack pointer. Through the value that it was, at the end. And the reason that I do that… I mean, I could… Pop V2… But I don't need the value of V2 anymore. It was a… it was something that I sent to the function, To be an argument, And that's a memory access, if I'm gonna pop it. So, adding is definitely cheaper than popping, and I don't need the value anymore, so I can just ignore it. I'm moving the stack pointer… I'm essentially erasing it. Because… I have to say. If you ever get turned around wondering which direction the stack pointer is moving when you push and pop, you're in good company, because I always have to go back and refer to stuff like this. I think that that is… wrong. I think we should be adding 4. Instead of adding negative 4. Because we want… Because we subtract 4… let's see… here it is. We subtract 4 and save the value there, and so then if we want to eliminate it, we have to add 4. I think that last line is wrong, but I will double check. by just putting the code in the emulator and seeing if it complains. And I will update the slide and send a message on Teams if it's wrong. And then the last line here. Is just doing the final work of, the main function. Yes. Is that staff is… Like, range of patterns. Yeah, it starts at zero, and then you subtract. So then it goes to very high addresses and goes down. Or if we… I think it's going the wrong direction. But I could be mistaken about that, because the stack is going to be, you know, all Fs, and the addresses get smaller as we put things on the stack, and they get larger as we take things off. So I think that last instruction should be add 4, rather than add negative 4. But I will double check that. It's just, you can pop it there. You can only pop from the top of the stack. When you say pop, You're performing a load instruction. That uses the stack pointer as the base address. and then manipulates the stack pointer. So you can peek into any part of the stack that you want. But you can't pop any address that you want. The stack is a last-in, first-out data structure. E2 is already gone. V2 does not get popped, because we aren't updating the stack pointer inside of Max. We're just looking at the value on the stack. But another good programming convention is that any function that puts stuff on the stack should take it off. Any function that did not put something on the stack but it needs should not take it off. Again, because… We live in a world of collaborative software engineering, where people write libraries. Like, you will only ever write in your history, in your total career as a software engineer, you will write just the tiniest fraction of code that you actually end up using. So it's… Critically important that everyone that writes software does so with the same exact assumptions. So that your code is interoperable. So… Main is what puts it on the stack. Main has to take it off. Some cannot take it off. Because maybe you wrote main and… Arda wrote some, and… you're not talking to each other, because you're in different companies, or whatever. There's, like, Nope. You may have… That's right. So our SP plus 4 is our effective address, but we are not changing the stack pointer because there's no exclamation mark. We're just peaking. Okay. So here, we're passing a bunch of values. You can instead pass pointers Passing, that's called passing by reference. You pass the address of the thing that you want to work on. So, in our C code here, we have two different implementations of a function that adds 3 to an argument that it gets. We can pass either the value A on the top one, or we can pass a reference to A. And, and sort of see how these two implementations work out in assembly. If we pass by value, Then… We can set things up. let's say what we want to add to A… the thing that we want to add 3 to is 77. So we initialize i to be equal to 77, We do that by setting up i as a location in memory, it is initialized to the value 77. We perform a load using I as the effective address that gets 77 into A1. We push the link register, then we branch and link into our first function, which is adding 3 to the value. The value is NA1. So inside of this function, I guess we're gonna get to that on the next… I thought for sure that we had… I guess not. We don't have… we don't see the implementation of, add3VAL and AD3REF in assembly. But the difference in between the two ways that you call it. Actually, you call it the exact same way. You just set it up a little bit differently. So… A1, in the second case, is the address of i, instead of the value of I, and we get the address of I by putting the equal sign in front of it. Remember that i is a memory address. When you… anytime you specify a label, I colon, the assembler will figure out what memory address I is at. that memory address is essentially being copied and pasted into any instance of i. It's being used as an effective address in the first load instruction, and we say equal i, that's saying I want the value of the address into the register, and then it goes like so. Not for sure… nope, we don't. Okay. I'm not gonna talk about the stack pointer, I mean, the frame pointer. Okay. Alright. At this point, You can write every single possible assembly language program. You know all there is to know about that. We just have a few final slides on how ARM version 7 instructions are encoded. We've had little previews of this all along the way. every single ARM version 7, instruction… Is encoded in this way. Where the first 4 bits are always a condition code. Everything else depends on what it is. Remember, you can do MoveGT. If you don't specify the GT for a move instruction, the condition that it executes under is the always condition. E. So if you… when you go and write your program in the emulator, and if you go and look at where the instructions are in memory. If you haven't specified a condition for the instructions, you'll see that the first 4 bits are always E. for an instruction that's always executed. Branch instructions, conditional branch instructions, will not have an E in the first 4 bits. There are 16-bit versions available for a lot of ARM instructions, but we're not going to talk about those in the class. They're called thumb encodings. Again, they're there to save code size. We have all these different conditions that we can use to decide whether or not an instruction is executed. The way that the other 28 bits are used depends on what the instruction is supposed to be doing. We have data processing instructions. The white bits there, that's… the opcode? the S in bit 20? That specifies whether or not the instruction is supposed to be updating the CPSR, The I in the 25th bit specifies whether or not we're using an immediate field. So we have two examples of ad instructions here. Add GES, is a conditional add only if the status bits are, are true for greater than or equal. We see the condition code is not E. The condition code there is… D? Right? That's A, sorry. The condition code is A. I is 0, because it's not an immediate value. The S… we have an S at the end, so S is 1, saying update the… The condition codes, and then, you see the way that the operands are encoded. They're encoded in a very straightforward way, a nice 4-bit boundary thing, so you can look at your instructions in hex, and you can see, oh, this one's working on register 2, the number 2 just… is just there in the hexadecimal representation of the instruction. 2, 1, and then, because we're working with a third register operand, 3 is in the least significant bits of operand 2. The next instruction uses an immediate value, so I is 1, does not update the CPSR, so S is 0, and is using 15 as the immediate value, so operand 2 is F in the last 4 bits. The immediate value in coding is odd. We have operand 2 is 12-bits, but you can't always do 12-bit operands, because in general, the assumption is you have an 8-bit immediate value with an optional 4-bit rotation. 4 bit… 4 bits of rotation means how far can we rotate? We can do 16 bits! We can rotate things up to 16 bits, unless we only allow rotation of even numbers of things. Which is what we do. So, you can make a very large or unusual immediate value by taking an 8-bit value and rotating it 2, 4, 6, 8, so on, bit positions. You can take your 8 bits, and they can… the assembler will figure this out for you, by the way. You specify any arbitrary large number. And if it can be represented. By taking 8 bits and rotating it like this, it will do it for you. Otherwise, it'll say, nope. Can't make that immediate value work for you. Sorry. Load and store instructions look an awful lot like data processing instructions. RD is your destination register, RN is your address register, the address might be PC, and so we do PC relative addressing by putting the constant offset into operand 2. Note that whereas Working with Opera N2 in this case, you're working with signed numbers. Unless maybe you rotate? Here, you're working with unsigned numbers, and one of the bits in the opcode is determining whether or not it's a positive number or a negative number. Are you adding or are you subtracting, essentially? Branch instructions. Branch instructions look the most different from everything else, based on the stuff that we're going to look at. And the branch instruction format has been optimized to give us as large an office as possible. Range is sort of a problem for PC relative addressing, right? We can only get data that is up to 4K bytes in one direction or another. If all we could do was branch that far, that would be a problem. So, we have a very special instruction encoding for branch instructions that gives us 24 bits that we can use for offsets. And it's worse than that, too. So… Every other time we do address calculation, the immediate value is in bytes, but in branch, it's in words. Again, this gives us more range. We effectively have a 26-bit offset that we're adding. Because instructions are always word-aligned, we can do this You calculate how far away your destination is, And you shift right twice. Dividing by 4, And that's the number that you put in the offset. With the plus 8 thing, too. You have PC plus 8, plus the displacements. You have to shift it, though. And that means that we can actually go really far away with our branch instruction. I tend to ask questions about this on exams. So, make a note of how branches are encoded differently than other immediate… other things where we have immediate values. The L bit in the instruction encoding is there to specify link. If L is 1, it's a branch and link instruction. If it's not, It's a zero. BX is not covered by this instruction encoding, because for BX, We're branching to a register. And I would bet, but I'm not positive, that it probably looks more like this. Because for BX, we don't need a huge offset. We're just going to a particular location that's in a register at the moment. Okay. I'm out of time. And we got to the last slide. So I will see you on Wednesday for the last material covered by the midterm.

Seek back 10 seconds

Pause

Seek forward 30 seconds

Mute
Current Time 
0:07
/
Duration 
1:12:44
 
1x
Playback Rate

Captions

Fullscreen

Picture-in-Picture
