
2025-FALL / ECSE-324-001
Captions
Search current recording by keyword
Brett Meyer, Prof: Okay, so today… We're gonna start… one of the… I think it might be the biggest chunk of the class. We've got two weeks looking at instruction set architecture. We'll define that a bit more precisely shortly, but you can think of instruction set architecture. As the interface between hardware and software. It's the contract between software writers and hardware designers. Instruction set architecture defines the features that are available in hardware, but not their implementation. Instruction set architecture allows someone to write a compiler that will produce code that will execute as expected on a particular hardware platform. We're gonna spend… 4 lecture periods, about 2 weeks. Looking at what the instruction set architecture is for the ARM version 7 instruction set architecture. So that you will have all the tools that you need to understand how an ARM version 7 processor is supposed to work, and therefore write your own assembly language programs for Labs 2, 3, and 4. If you're done with Lab 1, You could start Lab 2, or you could take a few days off. Lab 2 is posted, available. You can start to dig into assembly language programming about as early as you like. You'll know enough after today to at least start messing around. So let's get into it. Nevermind. Okay. Alright, so… Instruction Set Architecture, or ISA, it defines… The assembly language instructions, like what we've talked about, add, subtract, XOR and LoadStore. It specifies what operations are available. all the different, unique ways that they can be used. Not all ISAs are the same. x86 ISA is very different from ARM. Even Intel produces different processors with different ISAs. Some ISAs specify a single branch instruction, others specify many, some specify a single kind of load instruction, others specify many. You can find processors that only have about 30 instructions, like the ARM Cortex-M0, very small, very low cost. It is not unusual for processors to have, however, hundreds of instructions that are available. PowerPC isn't really a thing anymore, but that's the last time I actually went and looked and did a count, and it came in with about 200 instructions, about a quarter of which were different load and store instructions. ISA defines all these options, And they also define things like, How many registers are there? What are the different ways of accessing memory? What are the assumptions that the processor is making about how memory is organized? And, the ISA will often also specify things about timing. So, if you have a sequence of instructions, if you have the definition of an ISA, you often have enough information to go through and count out How long will it take for a particular set of instructions to execute? Like I was saying, you can think of the ISA as a contract, Compiler writers, software writers. do not know and cannot access the carefully protected intellectual property that defines the implementation of processors, but the ISA tells them everything that they need to know in order to write compilers and write software. It exposes the features that are available, not how they're implemented. An example of that is that there are many, many ways to design an adder circuit. The ISA will not tell you How binary arithmetic is being performed. But it will tell you what binary arithmetic operations are possibly performed in the system. The mainstream ISAs today would be x8664, the 64-bit flavor of x86. ARM has their different things that they do. We talk about ARM version 7 here, but the ARM processors in your laptops and phones are ARM version 8. the different flavor of the ARM ISA. We won't be talking about those differences, but if you take If you take a look at what RISC-V defines, it's a lot more similar to ARM version 8, for instance. I'll point out some of these differences as they arise. Power ISA is for… Related to PowerPC, that's an IBM instruction set architecture. They don't make hardware anymore, but their legacy lives on. Okay. Another way to think about an ISA is that it's kind of like… a spec? Or a datasheet? It's publicly available information. So, when we talk about x86, you might think of Intel, but you should also think of AMD. AMD and Intel both implement processors that respect x86, They do so in different ways. x86 is not an open spec, not just anybody can go and implement a processor, but there's antitrust legislation going back, I don't know how far, that ensured that there was always a competitor to Intel, which is funny today. When they're the one that needs the government bailouts, but whatever. Something else that's interesting about ISAs is that they tend to be… Legacy specs? So, x86 was introduced in 1978, If you find software compiled by an x86 compiler in 1978, it will run on any modern x86-64 processor. Who is that really useful for? What kind of enterprises benefit from that? governments? Archaeologists? Banks? Universities? There's a lot of legacy software out there. Imagine if Intel released a new processor and Minerva wouldn't run on it anymore. Minerva is legacy software. A lot of enterprise software is legacy software from the standpoint that it was designed and implemented long ago, and it's just been a patchwork of fixes since then. No, I… Probably don't hate Minerva as much as you do. But it's a pain. But it's also hard to change. And so, anytime Intel releases a new processor, they enforce backwards compatibility so that you can just drop in a new computer, and any software that was previously written will run on it. That doesn't mean that the processors today are as slow and inefficient as in 1978. But it means that if you recompile software with x8664, there are new features available on new Intel processors that weren't available in 1978 that will make your software faster, more efficient, or whatever, but backwards compatibility exists. One thing that's really interesting about that is that ARM has basically said, we're not going to do backwards compatibility. They sort of have processor families, they're always improving their instruction set architecture, but their clientele has historically been different. When you put… A processor inside of a dishwasher. You don't worry too much about backwards compatibility. No one is updating software on their dishwasher. Laptops and stuff become different. But… Even in phones, the App Store allows for the controlled deprecation of old versions of the ISA, because if your phone is old enough, you can't install software on it anymore. They do not enforce infinite backwards compatibility like Intel has. Okay, we're gonna live in the arm world. Because most of the world is the ARM world. Arma has really taken things over. I don't have new numbers. I'm sure that they're bigger than these numbers. But there's hundreds of billions of ARM processors that have shipped. And, like, in tens of billions per year at this point. And again, that's not just in phones or in laptops. But it's also in cars, If you have ridden in a recent car at all, chances are you're surrounded by ARM processors. They're in the braking system, they're in the engine control unit, and so on. So it's, A good piece of technology to be somewhat familiar with? ARM technology. We're talking about ARM in class, because you'll be using ARM in the labs. Before the pandemic, you would have programmed that development board. But since then, you can program in the comfort of your own home with a simulator of that development board. It has a single core arm. ARM version 7 is the, the mobile and embedded system version of ARM, rather than the high-performance version of ARM. That means there are other flavors of ARM version 7 that include things like fault tolerance. For your braking system, they're also very low-power and low-cost versions. And so on. There's some documentation that you can go look at if you want. I also have links to all this stuff in my courses. the ARM ISA, if you were to go and look at it, I think that one's about 1,000 pages. Welcome to Real Engineering. Where specs are not… printable anymore. Big documents, lots of technical information. We'll make sure to point you to the stuff that you actually care about for the purposes of this course. Alright. Let's get into it. So… From this point on, unless I tell you otherwise, when I talk about the features of the computers in class, we are talking about ARM version 7. a real thing. We are not going to talk about everything about ARM version 7. We're going to talk about a sanitized version for the sake of simplicity that teaches you what you need to know to actually program real devices, but without necessarily understanding the 1,000-page document, related to how these things are actually built. So, the ARM ISA… The ARM ISAs are risk ISAs. There's an asterisk there, because it's mostly risk. Meaning, we have 32-bit instructions, 32-bit registers, 32-bit addresses. 32-bit memory space, like you would expect in a RISC processor. One thing that ARM does always and forever is take these standard operating principles and then figure out clever ways of violating them in order to give you more performance, smaller code, less energy, and these other different kinds of things. So it's really good engineering, The foundational principle is risk, With a lot of optimization. It's a load store architecture. Only loads and store instructions can access memory. Of course, we access memory to read instructions, too, so don't forget about that. All arithmetic and logic instructions operate in registers, just like a load and store architecture. But there are some features which normally are only seen in risk, meaning we have some instructions that don't simply do a thing. For instance. You might think you have a load instruction that just accesses memory, and you would have an add instruction that you might use to manipulate the addresses used to access memory. In ARM, we have load instructions that also change the addresses that are being used. So you have a single instruction that performs two operations. One is to read from memory, and another is to update a register. That's an option. So you have a complex operation in a single instruction, I like to ask exam questions about those. One of the other things that ARM does, right from the get-go, in terms of optimization, is you can compile in ARM For 16-bit instructions. There's basically, in the ARM version 7 ISA, a 32-bit version and a 16-bit version. Why would you ever want to do a 16-bit version? What's the value of that? Yeah. Yeah, and Leo, right? More compact, meaning what? Like, space in my backpack, or what? Let's be precise here about the metrics. What does more compact mean? Simpler meaning what? What am I measuring that says simpler? I don't understand how that helps me. Let's be really precise here, Arda. More efficient in accessing it. More efficient. What does that mean? So, if you go to a customer, they don't care about compacts. or efficient, they care about performance, power, cost, area. These are things that can be measured. When I make my… When I make my ISA 16 bits. what of those metrics can I actually change, Rachel? If you load 32 bits, you're loading 2 instructions at once, we're getting closer. What does it mean? What is the value add? If you're a salesperson, a lot of engineers go into an engineering sales position to try to pitch products, so what do you tell customers? Low cost, and what was the first thing you said? Increased speed? In this particular case, not. But low cost, yes. Why lower cost if I'm compiling to 16-bit instructions instead of 32? Yes. There's definitely lower power consumption per instruction. I'm accessing fewer bits, and a lot of my memory… a lot of my power cost is in accessing memory. So when I compile a program with 16-bit instructions. The program takes up less memory. And if I'm building a computer for a dishwasher, and my program takes less memory, I can put a smaller memory chip in my dishwasher. And that's gonna make the dishwasher less expensive to manufacture. So that can either mean savings for your customer. Or more money in your pocket as the salesperson. Trade-off is that 16-bit instructions are less expressive than 32-bit instructions, so we tend to take more instructions to do the same thing. It's like 30-40% more instructions, but it's not 2x. So it's 30-40% more instructions, but my instructions are all about half the size in memory, so there's a code size win. but not necessarily a performance win, because I'm executing more instructions. There might be a power win if memory accesses dominate where I'm spending power. As engineers, these are the sorts of trade-offs that you need to start to think about. Because for everything else, we can just ask ChatGPT. Okay. Carrying on, then. On version 7. It is byte addressable. That means that every address specified by a CPU points to a single byte. Memory is Little Indian. Thank God for that. Memory is organized in a sensible way. ARM version 7 has Word, password, and byte memory access instructions. The default one is going to be a word access, and again, a CPU word is 4 bytes, or 32 bits. But we can access half words, or bytes. ARMS ISA does also specify, however, that as far as memory is concerned, all memory accesses are word-aligned. the hardware perspective. That means that… If, for instance. if I have… 4 bytes of memory, and I want to load this one. What's going to happen in hardware Is that this whole 32-bit thing is gonna be read from memory. And then something, somewhere between the memory and the processor is going to identify that that is the thing that is going to the processor. The hardware will not perform anything other than a 32-bit Or 4-byte memory access. The processor asks for 1 byte. The memory delivers 4, the processor only gets one because of the processor-memory interface and whatever magic it's doing to do that. It also means things like, Let's see… That's kinda gross. Ugh. If I have two words next to each other in memory, And let's say my address… Is for this one. but I want an entire word, So I get that byte. That bites, that bites, and that bites. That's a thing that ARM hardware will allow you to do, But it takes… So it's, like, one load instruction, Specifying this address. But in hardware, it's two memory accesses, because the hardware memory hierarchy has to access this, grab the byte, access this, grab those 3 bytes, then stitch them together to hand it off to the processor. So there's physical constraints on the organization of memory. The processor can do whatever it wants. The memory system and the interconnect will deliver what it requests, but sometimes some operations are more expensive than others, because of the magic that the hardware has to do to satisfy the processor's requests. Carrying on. We have 32-bit processors. There are… sorry, we have 32-bit registers. There are 16 of them. How many bits in my instruction, do I need to address The register file, then. If I want to specify a register operand, how many bits do I need to do that? 4. 4 bits. Address A is 4 bits. Address B is 4 bits. Address C, 4 bits. Because I have 16 options. If I had 32 registers, I would need 5 bits. I only have 4? Most of them are general-purpose registers, meaning that you can basically use them for whatever you want. There are a few special purpose ones, like the program counter. The program counter is in the register file. It is register 15. That means that you can use… you can write instructions that manipulate the program counter. This is a bad idea. Lucy. Is there, like… Is there a high-performance reason for that? So putting it in the register file probably allows Arm to take advantage of whatever circuit-level magic they've done to make accessing the register file fast. It also does mean that when we have branch instructions. There can be some magic for how it's accessing the program counter out of the register file. I don't really know. This is trade secret level kind of stuff. It's definitely an interesting choice. It means that you can, if you want to change what instruction is executing next, you can write to the program counter. In your software, directly. We'll look at how we update the program counter with different kinds of instructions in a little bit. But it does mean that there are some interesting ways to return from functions, for instance. We'll talk about the link register in the context of returning from function calls. The stack pointer, you've learned about the stack, right? Yes? Do you know what the stack is? a couple people, does… so does that mean that the rest of you don't know what the stack is in computing? You don't know what… do you know what a stack is, or a… LIFO is in the data structures perspective. Do you know what a stack is from a data structure's perspective? Yes, okay. The stack is super important when it comes to function calls. Again, we'll be looking at supporting function calls later on, probably not today. So… R0 through R12 are so-called general purpose registers. There are additional rules about how they can be used. There's documentation that talks about that. We will also talk about that, but it's kind of like… the rules that you'll have to respect for the labs are the kinds of rules that are in the ARM architecture procedure call standard. We will talk about them in detail, but it's kind of like Who cleans up, and who sets things up, and what's the appropriate use of a particular register versus another one, and so on. And, the simulator will complain at you if you don't respect some of the rules, and, your code won't work if you don't respect some of the other ones. But the ARM procedure call standard? It's really in place so that compiler writers Know how to make code that will work together. Because if, If I'm compiling software from various different sources, I want it all to coexist, because software writers aren't all sitting in the same room. And also, it's there for assembly language programmers like you all, so that when you write code that is going to execute alongside code that's been compiled. You make the same assumptions that the compilers are making, so again, your code won't break each other's other stuff. Yes. Connor? Yeah. Yeah. Is the LR the same as the No, the link register is different from the instruction register. The link register is specifically used for handling function calls and returns from function calls. The instruction register isn't in the register file. So the instruction register is what saves the instruction that we've led… that we've read from memory that we're going to be performing. That is not a software-accessible register. all the things that we're talking about here in terms of ISA, these are software accessible features. Does that answer your question? Fabulous. Okay. There is another software accessible register. I don't think that it's in the register file, but there's really no way of knowing unless you pay a licensing fee to get a RTL-level implementation of an ARM processor, and sort of look at it. I haven't done this. It's expensive. It's called the Current Program Status Register. It does a bunch of different things, but one of the things that it does is it keeps the ALU flags. So when you have an ALU instruction that has a result that's negative, or zero, or there's carry, or there's overflow. that information is saved in the CPSR, but the CPSR also does stuff like manage… whether or not the processor is executing in privileged mode, or user mode. Is it handling an interrupt, or is it not? These kinds of things. Any questions so far? Yes, Muhammad. It must certainly be… Yeah. So, the question is… you know, if memory… if we have a memory access to this byte, but I want a whole word, so I get 4, what is happening in between the processor and the memory to make sure that the processor gets just those bytes and not the other ones that have to be accessed? And that's a good question. So, you'd have to have some sort of logic Between the processor and the memory, where you save the first byte that you're keeping from the first memory access. And then you sort of overwrite all the other stuff that you're not keeping with the second access. So there's some sort of combinational logic that's taking the output of the memory array and then routing the different bits. Like a rotate kind of a thing going on, right? And you'd have to have… you'd have to have state, because we can only access one word at a time from memory, for instance, or at least that's the underlying assumption. Did that answer your question? Alright. Okay, so let's actually start taking a look at some ARM version 7 assembly language syntax. You'll be unsurprised to see that it looks kind of like the syntax that we've looked at so far. So here's our first program. A single ad instruction. like we've talked about before, the destination register is the first one, the next two after that, R2 and R3, are the source, registers, The ad at the front, that specifies the instruction. In assembly language, we call that a mnemonic, because the processor doesn't know anything about add, subtract, multiply, or whatever. All it knows is binary. And so, add is going to correspond to some collection of bits in the instruction format indicating the operation that's supposed to be performed, and add is shorthand. You don't need to write assembly language like this. You could write it entirely in binary. The ISA Tells you exactly what all of the bits ought to be for all of the instructions. And incidentally, if you're… Grandparents… were computer scientists, or computer engineers. That's how they wrote their code. In binary, probably on punch cards. And everyone that I've ever talked to that had to do this has a story where They didn't have a rubber band around their punch cards, and they tripped going down the hill to the mainframe and scattered their punch cards all over the place. Sounds terrible, doesn't it? I guess the modern-day equivalent would be… I accidentally overwrote my working code with the template that I downloaded from my courses and destroyed all of my work. That's, like, the same sort of thing. You have to remember how to rewrite it. It's kind of like having to remember how to put your cards back in order. Yeah. It's the same problem, just a different era. It's a lot more convenient to write assembly with mnemonics than it is in binary, so you don't have to do that. Although sometimes you might find yourself looking at the machine code and just sort of wondering. what it's doing, and you could go and look at the ARM version 7 documentation and see. But the assembler that you have access to will take care of that for you. If you're curious, when you write programs in C or Java. assembly is one of the last passes, so C in Java will take your… in C in Java, your high-level syntax will be taken, transformed into a graph that sort of represents the order of operations and their inputs, and at some point, that graph will get translated into assembly language instructions. And then it'll be assembled from that into machine code. But when you're programming in C or Java, turning it into a machine-specific thing happens at the very end. There's a lot of stuff that happens before that. Okay. So we have our simple add instruction. With our source registers and our destination register. We have a different kind of add instruction, too. one where we might provide an immediate value. What if I just want to take our 5 and add 24 to it? I tell the assembler that's what I want by putting the pound sign or the hash symbol in front of the number 24. You can also specify constants in hex by putting 0x after the pound sign, but this specifies it in decimal. Some instruction set architectures have a separate named instruction for this. Might be ADDI for add immediate. The arm assembler just says, well, if you put an immediate value there, then we know how to Set up the op codes to get it right. So in this particular case, Operands 2… It's not a second source register, it's the number 24. So we've looked at something like this picture before. The instruction format from the last set of slides was intentionally tailored to look approximately like this. This is not the format for all… for all ARM version 7 instructions. But it is the format for many of them. So we have the op code in the middle. That specifies what the operation is. So the opcode for add will be different from the op code for add immediate. And we'll take a look at how that works in just a little bit. You can see the destination register there again, 15 down to 12. One of the first… the first source register, RN19 down to 16. We have operand 2, like we talked about, a little bit ago, and then we have this condition code at the front. Now, when we were talking about processor design. We only had condition bits at the front for branch instructions. ARM allows you to specify a condition for any instruction. I can add greater than. And we'll take a look at how that happens in a little bit, and what the relative advantages are. The operand 2… is odd. And I can't say that I fully understand all of its uses and restrictions. Operand 2 is 12 bits. But that does not mean that you can always have a 12-bit immediate value. Sometimes you can. I don't understand fully the differences. The assembler will complain at you if you try to use an immediate value that is not supported by the instruction format for that particular instruction. In general, it's an 8-bit value, and we can optionally rotate it, or it can be our second source register, which we can also optionally rotate, or shift. And we'll see why that matters or is useful in a little bit. Muhammad. I don't know. Yeah. I, you know, you can go and play around with it. There are some cases where you can get 12 bits in there, and other cases where you can't, and it's like, it's… I don't understand, and I can't be bothered to read the hundreds of pages of documentation that would be required for me to fully understand it. But just know that the assembler will say, nope, you're not allowed to do that when you're not allowed to do that, and then you have to change your program logic. Yes, your name? You're… Okay? Can you say that again? Yes. There's a condition for every instruction. Every single instruction in ARM It's preceded by condition bits that specify whether or not it's executed. Yes, not just branches. Branches work in an entirely different way than what we've previously talked about in ARM version 7, and they work in an entirely different way, I think, again, in ARM version 8, but I'm not positive about that. But yes. Just like for a branch, you can say branch greater than, I can say add greater than. Yeah, you will… You'll see. Don't worry, you're not expected to understand how that works right now. But we'll get to it. It's actually a really cute and clever trick that Arm has done. You can write code without branches. And still have the effect of branches. You can write if-else without branches by using condition codes for your instructions, and sometimes it's more efficient to do so. Alright. So we have a bunch of slides now, looking at different classes of instructions. The first one is the move instruction. The idea of a move instruction is to make a copy of some data. Not copy of data in memory, only load and store instructions access memory. So, with a move instruction, I can copy from one register to another. I can also load immediate values into registers. So, for instance, if you look at the second move instruction, in this case. I can use a 16-bit immediate value and put that into a destination register. So, we were just talking about this instruction format, and already, on our first slide here, we have something that does not respect it. A slightly different flavor of instruction in that second move instruction and in the fourth one. The second move instruction in the fourth one are a pair… What is the use of that combination of instructions? The first one allows us to move a 16-bit value into a register, and the second one allows us to move a 16-bit value into the top half of a register. what if I wanted to… Fully specify a 32-bit value in a register. How would I go about doing that here? Yeah. If I have a 32-bit value, let's say my 32-bit value is dead beef, beef. goes into the bottom half of the register using the move instruction. Dead goes into the top half of the register with the move T instruction. Why would I ever want to fully specify a 32-bit value? Well, all memory addresses Our fully specified 32-bit values. And I cannot put a 32-bit immediate value in an instruction. My instruction is 32 bits. Are you tracking with me, Lucy? Maybe. Do y'all understand what I'm talking about? Yeah. There's two 16-bit. But, right after accessing that. Fortunately not. The question is, every time I access memory, do I have to take my address first in 16 bits, and then another 16 bits, and move them both into a register, and no. There are other ways of doing it. Whether or not they're faster or slower depends on the hardware implementation. We will take a look at it. It's definitely inconvenient to do that kind of manipulation, but it's a possibility, and that's why that instruction is there. The other way of getting a 32-bit value into a register is reading from memory. So if memory is really slow. Then this might be the better alternative. Lucy. The move expression will always… Prioritize the… the significant… the longer quarter bits first. And then the move team will just do it at the top. So the move instruction… We'll just take what the immediate value is, and copy it into the lower 16 bits. And then the move top will take the same immediate value and… or the, you know, whatever immediate value is specified and put it in the Fire order 16 bits. Specify, like, if we have, not 15 bits. For example, it looks like we have, like, 13. 9. Would it just, like, append the register and leave gaps in the middle? So, the… that's a good question. This is a 16-bit copy and paste. And so, if you only specify in your program a value that could be represented with 13 bits, the first question that the assembler is going to have is, is it positive, or is it negative? If it's positive, it's going to pad with zeros. If it's negative, it's going to pad with ones. And that 16-bit value is what gets copied into… the register. And then, I imagine if we were to look at the register transfer language for move, if you're moving a negative value, then it's going to actually pad the whole 32 bits. with ones. So that if your immediate value is negative, a move of an immediate value into a 32-bit register is going to result in a negative number being in the register. And if that's the case, which I think it is, but I don't remember exactly, then the only way to build a 32-bit number correctly is to move into the bottom first, and then move into the top second. Because moving into the bottom is going to either pad with zeros or with ones, depending upon the sign of the value. Yes. Sign extension. So, the processor… Anytime it's… anytime, with an asterisk, because not actually. But in this particular case. When we take an immediate value out of an instruction, the sign extension unit says, this is a positive number, fill in with zeros. This is a negative number, fill in with ones, and then that's the thing that goes into the 32-bit register file. Because we're never… we're not taking 16 bits and only moving 16 bits into the register file. So move T has sort of a funny operation if it's only manipulating the top. Somehow. And MoveT might actually… probably the way that MoveT works. Is that you read the value out of the register file. And then just sort of paste over part of it, and then write back. Basically, performs an implicit masking. Okay. Logic instructions. For logic instructions, we have all the ones that you would expect. AND, OR XOR. And the various complements. And then there's also… This bit clear instruction. which allows you to provide a mask in operand 2, it can be a register, it can be an immediate value, and you then perform an AND with the inverse of that in order to clear particular bits, if you want to do bit-level manipulation. Shift and rotate instructions. Same basic deal. We can provide immediate values for the amount that we want to shift, we can provide registers for the amount that we want to shift. We can shift left, we can shift right, we can perform arithmetic shift. Arithmetic shift, again, performs sign extension. Logical shift does not. There was a question a few lectures ago about rotates. Rotate takes bits that fall off one side, and… Puts them back on the other. There's only one rotate instruction. Rotate right. But you can give it a negative number. Which makes it a rotate left. So, if we flip back, To our instruction format here, Talked about how operand 2… Can be an immediate value or a register, and if it's a register, we have an optional amount of shifting that we can do. That allows us to do stuff like… The bottom add instruction? The bottom add instruction? is adding R1 plus R2 after it's been shifted left twice. Every time we shift left, it's the same as multiplying by 2. So, I can take R1 plus R2 times 4 in that particular case. You might be thinking, why would anybody ever want to do that? The first time I taught this course, I had the same question. Why would anybody want to do that? Let's see, do I actually… I did. Okay. The reason why that's particularly useful is that… Let's say you have a loop. And in that loop, you're manipulating an array. And that array is of integers. An integer in ARM version 7, the int data type, is 32 bits. 4 bytes. So let's say in every iteration of my loop, I'm accessing another element of my array. How do I do that? With my… iterator variable i, and put i in square brackets, and that gets me the element for that particular loop iteration. And every time I go through the loop iteration, I goes up by 1. Maybe I is stored in register 2. And maybe R0 is the address that I'm trying to access from. So when I take I and multiply by 4, That gives me the offset into my array in bytes. Instead of in… integers. The offset in integers isn't particularly useful. The offset in bytes is very useful. So we'll see in load and store instructions as well, we do this shift operation by 2 if we're accessing words, by 1 if we're accessing half words, by 0 if we're just accessing bytes. It's a very useful way to save instructions. And address calculation. Ryan. Exactly. You're not, like. That is a good question. It is not any operation, but it is there for a shift operation. Would you be able to do a shift right? Maybe… Could you do a rotate? Maybe… The… the situation… in the hardware design is that in ARM version 7, the implication is that our ALU The second input to it has our shifter sitting in front. So the shifter… Is not inside of the… maybe there is another shifter inside the ALU, but there's definitely a shifter in front of the second input to the ALU, and so you can perform whatever kind of shift operation you might want within some limitations. On an operation… on an operand coming out of the register file. before it goes into the ALU. And you'll just have to experiment to see what kind of options are available. The ISA documentation can be kind of cryptic in terms of specifying what the possibilities are. Lucy. So… You can only do this type of shifting on the second operand, yes. And it's exclusively shifting operations, yes. Yasim. It is on the value of R2. Because… No ALU operation manipulates register file addresses. Does that make sense? So we're basically… whenever we have an instruction, we're providing registers that are being operated on. It's the data in the register that is being manipulated. Okay. More instructions! Multiply! For the add and subtract instructions, we can have immediate values. For multiply, We cannot. I… don't know why. But if you want to multiply by 3, You can't just put pound 3 in place of R4, you have to move 3 into R4, and then call your multiply instruction. So there's something odd about the way that the hardware is wired up such that I can't send an immediate value to my multiplier. It might have something to do with this next instruction, multiply and accumulate. Multiply and accumulate is a decidedly unrisk instruction, because I'm performing a multiplication, and then an addition. That sounds a little CISC-y. However. Computer engineering is driven by applications. And basically, every filtering application out there, period. as multiply and accumulation. You know what else does? Machine learning. This instruction is extraordinarily important. If I can save and add every single time I have a multiply when I'm trying to do them together, that can be a tremendous performance improvement. What else is odd about the MLA instruction? Well, that's in the comments. Santiago. Yeah! We have an instruction here with 3 inputs and 1 output. So in the processor design part of the course, our register file Only ever produced two values. Address… the one based on address A, and the one based on address B. This implies that there's actually a third read port on the register file. So maybe address A, B, and C are ones that come out, and address D is what goes in. And we'll see later on that the ARM version 7 register file, you can read up to 3 operands and write up to 2. So it's more complicated than the register file that we've been working with so far, and again, that's to enable Time-saving operations that are often combined, especially in signal processing applications. Because, remember, computer engineering, it's just heuristics. Which basically means things that are usually good ideas, Not always. Creating shareholder value. Muhammad. The signal processing thing that I said. So… A lot of signal processing. Has a very well-defined computational template. we load a weight from memory, we load a data value from memory, we multiply them together, we add it to a running result, and we save it back to memory. Then we go back to the top of our loop. Digital signal processors? Special purpose processes for signal processing, they'll actually combine a bunch of that stuff into a single instruction, because it is such a common way of doing input-output transformation. And we have some support for things like that in the ARM version 7 ISA, even though it's not strictly risk. ARM, they're not purists. They care about performance. So they break the rules, and this is an example of that. So, one thing that I thought about when I was going through these slides again yesterday to get ready for today is, I don't know… where that third source operand gets saved in the instruction format. We could look it up in the documentation, and they would tell us. But this particular format only has room For 3 register operands, but there is a whole bunch of extra space in operand 2, right? We could potentially specify 5 registers, if we wanted to. There's enough room to do that. So, presumably, the third input operand is being… is somewhere in operand 2. Okay. There are other arithmetic instructions that we are not going to talk about in this class that are available in ARM version 7. They are also useful in signal processing. Just one second. For instance, we can do sub-word parallel operations. Our data path is 32 bits. But a lot of machine learning these days is done on 8 bits, maybe 16 bits, sometimes 4 bits. My data type is 4 bits, or 8. Or 12. What subword parallel means is that I've got a 32-bit adder. I could do one 32-bit addition. Or, with a MUX in the middle, I could do two 16-bit editions. At the same time. Or 4 8-bit editions at the same time. So instead of having 4 ad instructions, one after the other, I can just do one. Which is, again, a huge energy and time savings if you can structure your data and your program accordingly. ARM version 7 has support for this kind of stuff. And someone had their hand up… oh, Rachel, yes. Okay. No, but there will be an eye that we will look at. S is for something else that we'll talk about shortly. But yes. The S there is a special flag that indicates the behavior, the desired behavior of the instruction, and I think we'll get to that sometime in the next couple of slides. There's also an I. that I think we will see. Division! Our processors can do multiplication, If you try to write a division instruction, in your… Lab 2… The assembler will complain. It'll say, division is not supported. I didn't realize this one of the first years I was teaching this class, and so I was designing Lab 2, and you had to do a division somewhere in it, and I was writing my implementation, and like, you can't do division, and I realized I can't assign this programming question, because you can't do division, I had to do something else instead. The reason why division isn't always supported In hardware is that, for one, division instructions are very rare. They're just not used a lot in signal processing, for instance. And two, Division in hardware is slow and takes up a lot of transistors. It's slow, Because unlike multiplication, we cannot easily parallelize division. When you do longhand multiplication, you sort of write out all of the different partial products. You do that one at a time, and then you add things up sort of one at a time. And you might think, well, that's not any slower than doing long division, but in a processor, we can do all of that addition essentially in parallel. We can do a multiplication in the same time that we can do an addition. We just have to use a lot more hardware to do it. We cannot paralyze division in this way. Processors do division the same way that you do, again, with the iterative approach of, like, trying to subtract out the thing, and then you figure out how much is left, and you subtract it out again, and so on, and so on and so on. If you have 32 bits. And you want to do a division, it can take, like, literally 32 clock cycles. We don't tend to build hardware for it, ARM has decided not to, and instead, You're writing in… If you're writing code for ARM and you need to use division, you would call a software routine that implements that algorithm. In a series of subtractions and shifts. Instead of actually doing it in hardware. So, you won't be doing division in labs 2, 3, or 4. Yes. We are not talking about flowing point yet. This is all integer data path stuff. This is, like… 8 divided by 3. 21 divided by 7. unsupported, unless you… I guess one interesting Lab 2 assignment for the future could be to ask students to implement division in software. But I'll have to write that down as a possibility, maybe for next year. Questions? Okay. Next up, memory instructions. Right, so… Which is the point in the class Where it's really helpful if you remember pointers from C programming. So if I lose you in the course of talking about pointers, you should send me a message on Teams, and we can make sure to get you up to speed, explain anything that you're missing, because Pointers… And they're… not like in the, how do I program with pointers, really, but in sort of the fundamental sense of what pointers do and how they do it. That's how we're going to talk about memory access instructions. Because pointers make explicit the idea of a variable that is an address in memory. Java hides this from you. C does not. Computer hardware also does not. Computer hardware makes explicit the idea that an address is a variable that we manipulate and we use to interact with memory. So… Let's say I define an array of shorts. A short is a half word in our 32-bit architecture. That means it is 16 bits, 16-bit data type. So I have that array, 1, 2, 3, 4, 5. The byte view of memory is there in the middle, where the lower byte Has the number, and the upper byte is zeros, because all of my numbers are small. The largest short is 32,000-ish. None of my numbers were that big. The half-word view just has what you would expect. At address 0, it's 1. At address 2, it's 2. At address 4, it's 3, and so on. That's how that data goes into memory. when I write C code, To figure out how to navigate this stuff. what's happening underneath the hood, if I want to increment a pointer. Is that the software has to know how big your data type is. And it has to know what B… base address of the array is. With those two things together, you can get at an arbitrary element of your array. When we talk about the base address, that's kind of like using the ampersand operator. We do AND in front of our variable name, that returns the base address. In this case, that would be 1000 in hex. Not 1,000 decimal, 1000 in hex. Then the size of my type is 2 bytes. And then the i value is just whichever one I want to try to index. So if i is equal to 0, then the size of doesn't matter, I just get the one that's at the base. If i is equal to 3 in this case, then I want the number 4, so I have 2 times 3 is 6, Base address plus 6 gets me element with the value 4. As you begin to manipulate arrays in assembly, you will have to replicate this stuff. For Lab 2, I give you code in C, And then you translate it into assembly. I intentionally give you code with weird data types. So that you have to think about this. You have to know How far are each of my elements separated by, from each other in memory? Are you with me on this stuff? Here. Alright. So, I have it programmed. My program specifies an array, and then I have a for loop. And in that for loop, I read from the array, and later on, I write back to it. In this particular example, I'm using integers. Integers in a 32-bit architecture are 4 bytes. Integers in a 64-bit architecture are 8 bytes. We're in the 32-bit world in this class. 4 bytes. So if I want to read… the i-th element, I need the base address of the array, and I need to know the size of the element. I multiply the size by i, add it to the base address, and that gives me the memory address that I want to use to perform my access. So let's look at how we do that. Same program. The first, load instruction. Now, just like… if you remember when we talked about ad. You could specify add with 3 register operands, or you could specify add with 2 register operands and an immediate value. The mnemonic doesn't change. It is the same with load. LDR, Load Register. We will use LDR, For a lot of different kinds of load instructions. The way that the operands will be specified, lots of different ways. We're gonna look at them, but LDR, if I'm accessing a 4-byte word, it's always just LDR. In terms of understanding how those operands get oriented. I want you to see the square brackets there. That is not optional syntax. The square brackets go around the part, of the… Specification of the instruction that is used to calculate the address. This is a pretty simple calculation. We're just using Rn. Or, if you think back to processor design, it's like RN plus 0. Rn goes to the input A of the AOU. 0 comes from the immediate value of the instruction, it goes to input B of the AOU. We're doing Rn plus 0 to calculate our address. We'll look at all the different options for address calculation in a couple of slides, but I want you to look for that bracket. The placement of the bracket is super important. Because you'll see, it doesn't always include everything that's on the right. Yes. Alright. Or is there any other… This is just an example load. We haven't specified anything else about how we're going to make it do that work yet. Yeah, it's awesome. How many what? How many clock cycles does load take? Does this load take? Is that what you're saying? If we assume that I can access memory in one cycle, I have to fetch my load instruction, I have to decode my load instruction, and then I have to execute it, which access is memory. In ARM version 7 world, we assume a three-stage pipeline. For our purposes, we're not going to get more fancy than that, so we'll say 3 cycles. Does that answer your question? No, because the plus zero doesn't add more clock cycles, because I calculate the address. always and forever in the ALU, and then the output goes to the memory interface, and… It doesn't matter if… it's like adding zero or adding another register doesn't take any more time. There might be a difference in the energy that's used, because different number of bit transitions, but it's… Whatever addition I do, same amount of time. Lucy. So, we have, the… Emotics. Normally, we could be, like, LDRRZ that anybody better flow, what's… that repeater in the RD? It uses what… it uses the number that is in Rn to access memory to get a value to go into RD. No. Is there a different syntax if we're just using register values? Move. A move instruction allows us to copy from one register to another. a load or a store always and forever accesses main memory. They always what? Use a square brackets. Yes, load and store, use square brackets. Around the square bracket, we're saying, this is the index into memory. Use this calculation To get me stuff from memory. Yes! The first… so in the byte view, the first address is not 16 bits, it's 8 bits, it's 1 byte. So each of the boxes in the byte view is 8 bits, but each of the boxes in the half-word view is 16 bits. So, I can specify the number 1, In hex, 0x00001. Top of that is one byte, the other half is another, and we can see that in bytes 0 and 1 in the byte view. So those two memory locations together specify our number. That's right. And if I have integers instead, I need 4 boxes to specify my number. If I have a double or a long, I need 8. If I have some complex class or struct, I might mean… I might need many bytes To specify a single instance of it in memory. You multiply by the size, and the most fundamental unit of memory access is a byte, so the size of function in C returns how many bytes do I need to store my data type. And it works on all the primitives, but it also works on structs. It works on classes, too. You say size of, and it tells you how much memory is allocated every single time you copy one of these into memory. And then, with that information, you can sort of step from one to the next in an array. Does that answer your question? Fabulous. Okay. So, to Muhammad's question. How do we actually make a load do this work? Well… So we know that the size of our data type is 4. So I need to move 4 into a register, because I can't multiply by an immediate value. Incidentally, the first couple years that this class was taught. We didn't try to run this code and see if it broke or not, and we realized, oh. We were specifying multiplying by an immediate value, and that's not legal, so we had to rewrite it. But here's… this works. You can copy and paste this into the emulator, and it will function. We need to multiply by 4 to do our math, so we move a 4 into R2. And then we… if we assume i is in R0, we move… we multiply R2 and 0 and put that into R2. That gives me the offset from the base of the array to get the element that I want. I times the size. And then I've got the base of the array in R1, so R1 plus R2 into R3 gives me a fully specified address. And then I can perform a load from the address in R3, give me the data in R4, that gives me the element that I'm trying to access. So… V equals ARRI? That becomes… They have instructions. Move, multiply, add. That performs my… address calculation. And then the load. Now, ARM, in its infinite wisdom, has given us functionality that allows to combine a lot of these things We will see at the end that we can actually do this in a single instruction. It's a much more complicatedly specified load than what we have here. But here you can see all the basic steps that are required in order to perform this basic memory access. You with me? I can't remember if it's part A of Lab 2 or Part B, but one of them, you're manipulating two-dimensional arrays. So, you'll definitely come to grips with this by the time you finish that. Yes. If we run out of registers, the initiative values, we have to start storing and memorizing them. Yeah. If you run out of registers, Lucy's thinking ahead here. You only have 16 registers, and only 12 of, I guess, 13 of them are general purpose. Have you ever written a program where you needed to keep track of more than 13 bits of information? It's likely that you have. If you run out of registers. What else can you do but start to use memory? Fortunately, there are… standard mechanisms for doing this that are not so awful. And we will, I think, talk about that at some point, and if not, I'll be sure to mention how it works. But yes. you use the stack. That's the… The short answer that you… and you don't know what it means yet, but… the stack is used for temporary storage. That's where you would, keep your values. That's what compilers do, too. When a compiler runs out of registers for your program. Spills the register file into memory. And then just has to load stuff back in later on. Santiago. Yes, we could use multiply accumulate here, maybe. Yeah, because we're doing a multiplication and an add, and then going into a fourth register, yeah. That would be one way to get some efficiency. We'll see that the load functionality actually is able to do a lot of this for us. Muhammad. Say that again? Yes. Yes, if you have a 2D array, then you have an outer loop and an inner loop, and… And you have to branch back and forth, yeah. And you also have to see… if you have a 2D array, you've got a row and a column, which means more multiplication. in your address calculation, but we'll… we'll look at an example. I'm not expecting you to just figure it out. Okay. that I have the code here, And I put it into… memory here. and I initialized some register values, And… when I… when I run the code. This is the state of the register file after I'm done. So we can see that… R2… R2 starts off as 4. But then we multiply it by the size of the… By the size of the element, which gives us… 12. And… Let's see, hold on a second. R2 is 12, but Y. We move forward, then we multiply, I don't… hmm. Oh, yeah, because 4 is the size. R0 is I. And I is 3. So we multiply i, the index that we want, by the size, that gets us 12. We then add 12, and the base address, which is in R1, the base address is 10000, so then we get 100C. That's the address that we want to actually access. And then if we flip back, No, that's different. But if we… if we look here, The value specified by the fourth element, i equals 3 is 15, And 15 is what I get in R4. F. Okay. Let's start to generalize this a little bit, because we have actually a lot of power to do address calculation inside of our square brackets, and we're not doing any of it here. So… In general, when you have a load instruction or a store instruction, STR, store, register, again, that's a 4-byte memory access. The thing that goes after the comma Is your effective address calculation. Some, but not necessarily all of which, will be enclosed in square brackets. Effective address calculation just means what's the math that I need to do to calculate what you want to access? The general template for this is base address plus oxteth. If I have an array or a complex data structure, I can use the ampersand symbol in front of it to get the base address. if I have… an array, then the index into it is straightforward. If I have a complex struct or something, and I want to index a particular member, it's a little bit more complicated, but it's still base plus offset to get any element of a data structure. We also have load and store instructions for half words and bytes. We'll look at a list of them later. they don't all support the exact same kinds of effective address calculation. Again, the emulator will complain at you if you try to do something that's illegal. So, for instance, we can do shifting in our effective address calculation, just not for all of the different kinds of load and store instructions. The three basic types of… Calculating effective addresses. is, one, we've already seen, register indirect, where the effective address is just the value that's specified by a particular register. Two. immediate offset, where the offset is a constant that is known at assembly time, you can write it down, like, R2 plus 4. So we would do R2 comma 4 inside of our square brackets. Or, we can do an offset in a register. So we want to do… we would specify off N, RM, and then a shift. again, inside of our square brackets. So the shift allows us to take the value in RM, and shift it to the left twice, because maybe R3 is I, and the data type is an integer, and I would want to shift left twice to multiply by 4, and that way I can just go from one integer to the next in my loop. Another funny thing about ARM, Load and store… load and store instructions? Our case where the immediate value? is not signed. All the other immediate values that we've talked about so far, sine extension, sign extension, sign extension, but not here. Here, the immediate value is a full 12 bits of magnitude. There's a separate opcode for when I'm adding it, and a different one for when I'm subtracting it. And that's just an engineering choice, because they decided that they would rather give access to 2 to the 12 bytes in either direction than just 2 to the 11 bytes in either direction. And maybe they had an extra bit of opcode that they could use to do that. And… We'll stop there, because I've gone one minute over. See you later!

Seek back 10 seconds

Pause

Seek forward 30 seconds

Mute
Current Time 
0:03
/
Duration 
1:20:49
 
1x
Playback Rate

Captions

Fullscreen

Picture-in-Picture
