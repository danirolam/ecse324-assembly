
2025-FALL / ECSE-324-001
Captions
Search current recording by keyword
OK. So real quick before we. Get into the Electric Material for Today lab. One was due. Lab 2 is out the you should be able to do all of Part 1 for the lab right now. At least by the end of today, you'll be able to do all of Part 1. Let's see. Yeah. One thing I'll say about Lab 2 that I also said about Lab 1 is you don't want to wait until the Friday before it's due to start. It's too much. My my solutions. Each program is about 100 assembly lines long, which is not a small program. So you want to start early. You also want to write and test incrementally. I don't know if your. Strategy to write software is to just. Write it all and hope for the best, and then start debugging from there. That's actually a lot harder than writing little bits of functionality and then testing them. You'll want to start trying to do this sooner rather than later, because testing in assembly with no print statements is very different from testing anything else where you have print statements. The only way to know what's in memory is to go and look inside memory at the numbers that are there. To know what's in the registers, you go and look at the numbers that are there. So don't put. Off. Starting to do this, and if you haven't done Lab 0 the second coming with the introduction to the emulator, get on that right away. Because you have to write your two programs the second. One you do 2 versions, you do a performance comparison. You're right about that in a report. All of these things take time beyond just figuring out how to make stuff happen. So don't wait, you will suffer if you do. And like for lab one, we will be doing automated testing. We will devise a set of. Test cases and run them through your code. You do not have access to the test cases in this particular case, so it's up to you to think of corner cases. We will never provide an incorrect output, so you don't have to write code that checks for bad inputs. So for instance. One of the two parts is to do something like the Fibonacci sequence, but it's not the Fibonacci sequence, but one of the inputs to it is. How many numbers into the sequence are you supposed to calculate? We're not going to give you a negative number. We're not going to give you an incorrect amount of memory space to store stuff in. We won't give you any invalid inputs, but it's up to you to check all of the corner cases. Does your program work for the base case? Does it work for large numbers? Whatever you have to think about them. And as always, you know you can get help in lab, you can get help on teams and so on. Any logistical questions about Lab 2? OK. All right. So I just wanted to touch. On this really briefly again before we move on PC relative addressing, we will see more examples of it in the lecture today, but the basic idea is that we use the location of the currently executing instruction as the base address to get to data that is stored someplace nearby. I've really enjoyed teaching this semester because you asked different questions and have been asked in the past, which has inspired new ideas for questions for the final exam. Like if data is someplace and my instructions someplace else, can I reach it with PC relative addressing? I've made a little note. There will be a question about that on the final. I'm just telling you, I'm giving you information. This is a freebie. I'm sorry. Yeah, sure. So the. Example that we did in. Class was to show that if your data is too far. Away from the instructions that are executing, you cannot use PC relative addressing to access it because PC relative addressing has a limited offset that can be provided about. 4. K bytes in One Direction or another. So the idea that I had, and I haven't written the final so this might not be how it materializes, but I could give a location of a variable that I want you to access and have you write a load instruction or a pair of load instructions that does it based on how far away it is. If it's more than 4K bytes away, you can't use PC relative addressing because we're limited to a 12 bit number to add to the program counter. We'll see today and you'll see as you start the code and you'll see if you look back at past exams, a lot of data that your program uses is actually stored very. Close to your instructions, the PC relative addressing works just fine. There's another way of accessing data that is very. Similar and it's. Stack pointer relative addressing when we start looking at subroutine. Calling or function calling, We'll see exactly how that works too. It's very important, the foundation of a lot of modern programming actually using the stack to save variables, and you can think about the difference between PC relative addressing and stack relative addressing like this. We use PC relative addressing for. Variables that are defined. Statically at compile time, meaning I name a variable somewhere in my code, the assembler knows exactly what memory address it is AT and therefore can calculate this displacement between the program counter and where the variable is stored. Yeah, the variable has been allocated statically. We. Use the stack. When we have dynamically allocated variables at runtime, an example of that would be if I used recursion to calculate a Fibonacci sequence. Have you done this before? Have you? Have you programmed with recursion? Every time you have a function call, you might declare a new variable inside that's the same name as the old variable from the previous function call again and again and again and again and again. You've got a million. Copies of the variable X at compile. Time. The assembler doesn't know how many copies of X you're going to need. They cannot just allocate memory for it. We have to allocate dynamically. We do that on the stack, and in that case the functions will use stack relative addressing to get at the copy of the value variable X that it's supposed to be manipulating. And again, we'll take a look at that in more detail when we look at subroutine. Calling OK before. We continue with this. I hadn't done any Let's ask ChatGPT the last couple of lectures, not because I didn't have interesting things to ask, but because I've been too busy to go through it. And I was inspired last night by our conversation toward the end of class last time. And so I had two questions that I asked ChatGPT. And, you know the midterm. Is just a handful of weeks away and you might be thinking about who you're going to study with. I highly recommend not studying with ChatGPT. So when we. Were looking at effective address calculation and different addressing modes. We had this sequence of four instructions, the first three of which are calculating the address for the load. And so I asked if ChatGPT can reduce this the way that we saw in class and the short answer is. Yes. And I was actually pleasantly surprised by this. I did not experiment much to see if I changed the order of the instructions or anything. I know that lecture notes for this class and a bunch of others are available online. Could possibly be in the training data, I don't know, but it got the right answer. But ChatGPT continues to bat about 500 because it really messes this one up. So at the end of class or toward the end of class we were talking about load multiple and I was asking how many clock cycles and how many memory accesses. And so I said specifically assume a standard ARM V7 pipeline and consider the following instruction. That's the one read out of lecture notes. 2 questions. How many memory accesses are required over the course of its execution? And assuming 1 clock cycle per memory access, how many clock cycles total does the instruction require to execute? Is this correct? It's not correct. What's the problem with it? It's not accounting for fetch. This is not an unreasonable error to make, and it's one that I suspect some of you will make when I ask a similar question on the exam. You just forget about instruction fetch. I in a follow up later I asked it. I told it you forgot about instruction fetch and then it was able to correct this. So maybe that's just down to not stating assumptions correctly. But you wouldn't want to ask it this question if you're studying because it'll tell you the wrong answer. For my class and personally I get annoyed when I need to baby ChatGPT through all the many assumptions that it might or might not make, but whatever. So partial credit, maybe half points. So then Part B, what's wrong with this answer? A number of things, incidentally. You spot any things, Ryan? Correct. And this is actually particularly insidious because when I saw this, it made me doubt my assumption. So I had to go and check. My assumption and yes ARM version 7, the ISA specifies a three stage pipeline, so. This is just. Out and out wrong. But even if we give it the. Benefit of the. Doubt is any of the rest of the reasoning correct. If it's a five stage pipeline I see head shaking. Correct, it is not right. It says that there's a one cycle overhead for the instruction itself. Actually every instruction takes 5 cycles to execute in A5 cycle pipeline. Although it does add some overhead for the memory, but it's also not thinking about that correctly either. Because if this were a five stage pipeline with an LDM with three memory accesses, we would fetch the code, execute and then we would be in memory memory. Memory right back 7, not 4. So I was. I was concerned by this one too, so this wouldn't get any points. Just so you know, and I have decided a couple of TAS are going to help me run my midterm through ChatGPT and we'll talk about that after you all have the midterm run through you. Yes, Lucy. I'm not understanding of what you said every three times and then it's going on to the right back seat. Why that we're like loading three different values from memory right back all at the same time? Yeah. So the assumption. Really doesn't work out at all. You're right, it doesn't make any sense. That we could do 3 memory stages and then a single write back. It works for ARM version 7 because. Well, it's a it's. An incoherence explanation. It doesn't make any sense. You. No, there's no sense being made here. In the context of ARM version 7 where we have a three stage pipeline and the execute memory and write back stages are collapsed into one, you can actually do a memory access and you can calculate an address. Perform a memory. Access and save it to the register file in a single clock cycle so we can do fetch, decode, execute, execute, execute and then we're done with our LDM instruction. That is the correct answer here. Again, assuming a three stage pipeline, but. This. Doesn't make any sense. It is an internally inconsistent explanation in a lot and basically every way possible. You pick two and any 2 facts here in the in the in the explanation and they aren't coherent. So don't use ChatGPT to study. Instead make use of Tasmania if you have questions. Make use of me if you have questions. The lecture channel is there to address all of this stuff if you ever have questions that come up while you're studying, and I recommend finding a friend, OK? Carrying on then. So we've seen enough at this point to start looking at some very simple programs before we do. That there are some additional instructions that we can give to the assembler. Kind of like when you write AC program or a Java program. You might include libraries, you might define some stuff. We can do a lot of the similar thing. We can do a lot of similar things in assembly. With what are called directives, there are two different formats for these directives. The GNU syntax puts a dot in front of them. I don't remember what the. Arm PEIL syntax does, but you'll in all of our examples you'll see the directives with a little dot in front. When you go to write your first program, you'll have to do dot global_start that identifies the entry point of the program. But global is just defining global variables to tell the assembler that things are defined when you see things like dot. Word. That's allocating memory. We can also do dots, bytes and dot shorts. I think is what they are. dot EQU is like setting a macro in C You can define the variable N to be equal to a particular number, like a constant that you define. The assembler will then go and replace it. You don't have to store N in memory necessarily, you can just set it as a variable that then just gets populated across every occurrence. Kind of like the C preprocessor will do or Java preprocessor will do. We can specify things like dot text to show where code is, dot data to show where data is for the labs. You will not have much use for these because unless you also specify a file that tells the assembler where every different section is the file, the assembler will say, I don't know what I'm supposed to do with these different sections, and then it'll just die. You don't have to use dot text or dot data and you shouldn't. You can end that. You can mark the end of your code or any other section with dot end and so on, and there are others. You can rename registers. We'll see that registers actually have different names too. They all have an R with a number name R is R1R0R15, but they have other names too, and you can also rename them if you want. If you want to use a particular register name to signify a particular variable that you're using or whatever, there's a lot of stuff that you can do for convenience. Then there's also some interesting pseudo instructions. Pseudo instruction means you write it. And it might be a load, and it might not be a load. But you don't have to decide. You can let the assembler decide. So in this particular case, let's say that we want to get a value into a register, so we can say LDR into our destination register equal value, where value is something that's been defined someplace else with one of our directives. So. If. Value the number assigned to value because I would do. Some place above that code I would have value; And then maybe. Eight, I've defined a constant. 8 is small. I can make this load instruction. A. Move instruction. If my value is small enough, I can just make it. I can just make 8 or in this case 32 the immediate value in the in a move instruction and I can get the value into Rd. that particular way if alternatively value is a. Large number. Then I can't save that number in the immediate field of an instruction. And so instead what I do or what the assembler does is it saves that value somewhere in memory and then it uses PC relative addressing to load it. So if my for example, down at the bottom there, that number is too big to be able to be stored in an immediate field. So instead it gets stored at address 4, which is down below the rest of the code that has been assembled. It's A1 instruction program. That program is saved at address 0, but the data for that one instruction is at address 4. You can see the content of address 4 is exactly the value that I'm trying to load into R0. So I use PC relative addressing to grab it out of memory and put it into R0. It's called a pseudo instruction because I specify it as a load and then the assembler decides can I do this with a move or do I need to do it with a load? Why would we always prefer to do it with a move? It's faster because I'm saving the memory access and memory access. These arms always just a single cycle. So you can specify a number in hex or decimal. You can also say equal to a label. Kind of like this over here if you actually say equal to a label. Well, we'll get to that in a second. We'll get to it right now, I guess. When we fully. Specify the number we are saying we want that number to be in the register. Alternatively, we can load into R0 and then provide the name N and CN is defined up there as a 32 bit word, the number 7 when we load. From N into R0 we get the value of N when we load equals MMM is not a thing that's. Defined in memory. It's defined with a directive that's an alias. M is equal to 12 in hex. So when we perform that memory, that memory access is actually a move. Because 12 and hex is small enough that it can be an immediate value in an instruction, we don't have to save M somewhere in memory. However, we also define as an alias. Wherever O appears in the code, OX1234 should appear. Unfortunately, that number is too big. The assembler will look at it and say no, we can't just put that value in in an immediate field. It will generate a PC relative. Access. That's the at the address C, and the data for that access is the next word beneath it these. Variables that I have to save close to my data, close to my code. Sorry. They will always go underneath your code in the examples that you do. If you're, if you have lots and lots of code, sometimes it has to figure out other places to put it. That's not something that we're going to worry too much about. The first instruction, the first load instruction is not a pseudo instruction. It's executed exactly as specified. But the next two could be either a move or a load, depending. And you don't have to figure it out, the assembler will figure it out for you. Maeve. So. For the in the context of this class with the length of programs that you will be writing, it is stored at the bottom of the code after all of it. That's under the assumption that PC relative addressing going 4K bytes in One Direction or another will allow me to get there. So if you. Write a program that is 1000 assembly instructions from top to bottom. Then you start to get into problems where the assembler would have to be more careful. And so if you have a, you know when you write a program in CR Java, you might write a bunch of different functions. So there's gaps between those functions where there's really nothing specified in your program. The assembler could insert data for keeping track of variables like that between your functions. If you have a really, really long function, like long enough that you can't do PC relative addressing from the middle of it to either the top or the bottom, then the assembler would have to be more creative. And maybe it actually breaks that function into two where you go. And then you have a gap here where you can store some of these variables and then you jump from there to the beginning of the next section. So it can partition long bits of code in order to find places to stick this stuff. But that's why having, you know ±2 to the 12, that's actually a really important number because that defines how big a function has to be or can be before they have to start breaking it up and slowing it down as a consequence. Does that answer your question? And then Santiago. So it's kind of like N. Specifies a memory address. Anytime you see a label over on the left, something: that specifies you're like naming a memory address. And So what the first load instruction is saying is load my effective address is N and so then it's going to do PC relative addressing. You see PC -12 PC -12 = n That's the address that we're loading from. And just because the number 7 is in there at assembly time doesn't mean that there isn't possibly an instruction later that stores something to north and then changes it. So in this case, like N is a variable, not a constant. You might be writing it as if it's a constant, but the assembler cannot assume that it's a constant. You load from the address. That's what the assembler is going to say to do. It's not going to assume that that number is never different. Does that answer your question? N: 7 does not work. And the reason is that 7 is small enough to be a byte. It could also be a short. It could also be an integer. And each of those look different in memory, and they also define what the largest number is that you could write back to N So when you say. Dot word you're saying allocate me? 4 bytes for everything that comes later, because we could do 7, 3, -12, and then it's allocating 4 bytes of space for each one of those numbers and then initializing those locations in memory to those particular numbers. But if I didn't specify the data type, then I don't know how much space to have between the consecutive numbers in the list. And if I don't specify a data type and then I write, if it's supposed to be a byte and I write back a word, then suddenly I'm overwriting my first instruction, or at least part of it. Because if I start a full word access from a byte just before my instructions, the assembler won't actually let you do this. But if it did, you would start to write over your software with your store, which is no good. Yeah, it's like allocating. It's like initializing the variable. It's. It's equivalent to saying X = 7 int X = 7; Like that's. In this case it's int n = 7, then the. Only and there's a variable and kind of. Yeah, so the when the program. Begins to run. Part of that process is to initialize memory, and so the memory location defined by N will have the number 7 saved into it before your main program starts to execute. Ryan, did you have a question? Same question, Mave. What's a nested function? So compilers are really conservative. So if you have multiple different functions that need to know the address of N for instance, it's just going to make a bunch of different copies. Because in general compilers do not do inter function optimization because the computational complexity of looking across function calls to perform optimization is really high. So compilers are. Compilers are safer than airplanes. They do literally the safest, most direct translation guaranteed to work all the time unless you specifically tell it to take chances, which might not be so safe. So if you compile with no optimizations, you get the. Slowest. Most. Accurate to what you wrote, translation of your program. And then there's levels of optimization that you can do where if you start to go into the higher levels of optimization, it is possible that the compiler will make a bad assumption and break your program. But for the first, for like Dash O0-O1, it's extraordinarily safe. The compiler will never break your code. And it does this by being super conservative. And then when it goes through and does optimization passes, it looks for things, it looks for overlap and redundancy and reuse and these sorts of stuff. And it starts to adjust your code in order to make it smaller, faster, whatever. But that's only in an optimization pass, and generally only when things can be proven to be safe to do. Does that answer your question, Muhammad? Why aren't we treating the word 7 as let me address like 7? Is the let me address. Well, the assembler only knows that the programmer wants the contents of the memory address at N into R0, and maybe N is an input parameter. Kind of like what you're going to do for your programs and maybe you when you do one run and A7 and another one, it's 9 and whatever. Like you change it, but the rest of the software doesn't need to change because it's just loading the value from that location in memory. It's not a constant in that case. But even if it were, I'm sure you've programmed with constants where then you've recompiled and and and whatever. The program logic hasn't changed, but some of the input numbers have. Yeah. So we define N as a memory location and we initialize its value to seven. But O is defined as an alias, so you, the programmers who cannot be troubled to understand the limitations of the instruction set, you just want O to be replaced with that value wherever it appears in your code, and then the assembler says. Well, when I. Compile for ARM version 7. I can't fit it in memory. Maybe when you recompile for ARM version 864 bits, maybe it can fit as an immediate value, but you don't have to worry about that. You just want portable code. You write it once and you compile it to both platforms. So then the assemblers job is to look at the size of O after that replacement has happened and say we can't do a move instruction, we need to do a load instruction because hex 1234 is 16 bits. That's bigger than my immediate field allows, and so I have to save that number somewhere in memory in what's called the literal pool. This time it's beneath the code and then we load from there. Does that answer your question? So when so that load that third sorry the second load instruction in the code when it is in the execute stage, what is the value of PC? William, it's PC Plus 8, which is what 2 down South PC for the instruction is C12PC plus 4 is 16. PC +8 is 2020 is the line after we see there, so -4 actually takes us to the address 16. And that's where the data is that we're trying to get into the register in ARM version 7. You always assume that when instruction executes PC is 8 more than the address of the instruction that is being executed. And that is true in your emulator Arda. Correct, which is 12 PC minus. 12 is 0 which is where the number 7 is. It's off by 1 error. It happens all the time to everybody. It happened to me last lecture. Don't sweat it. Off by 1 errors are the worst. You will not have fun debugging off by 1 errors in your lab two programs. OK, we're going to talk about. Branching. Now this is the make sure we talk about everything so that you can do lab two challenge at least Part 1. Part 1 does not have any function calls. If you have branching, that's enough. So I've we've talked about. Branching. In the past, branching, as far as your lab one was concerned, meant reading registers from the register file, performing some sort of comparison, and checking to see if the condition that was desired was true or false. ARM does not do it this way at all. Instead ARM when it sees a branch instruction, or rather any instruction at. All we'll check the condition code flags which are set by the ALU. They're the same ones that we've talked about NZC and V for -0 carry and overflow. They are found in the Current Program Status Register or CPSR, which I have. Across the top of the slide, they're not. All of the bits there are defined, they are all used. The middle ones just aren't interesting for this class. You will learn. About them if you take 444, as long as the slides haven't been changed from when I wrote them. I haven't taught that class in a little bit and I don't expect to teach it again anytime soon. But you'd learn about the middle bits and what they're used for in 444. They have to do with exception handling and interrupts, so the CPSR defines the condition code flags. Not going to talk about other stuff. The CPSR is not in the register file. It is the only named register that software can access that is not in the register file. There are special instructions for accessing it. You can read from it into a general purpose register. You can write from a general purpose register into it, but you have to use special instructions. To do that, then the branches that we support be all have these different kinds of names after them. So for lab. One, the assumption was that all of your comparisons were signed, but in ARM version 7, your comparisons could be signed or unsigned because the overflow. Condition is different in each case, right? The way that you determine greater than or less than. Is different. We use different condition codes flags for that. So you can do all the ones that you're used to branch equal, not equal, greater than, less than. But for signed for unsigned arithmetic we have weird names like branch, higher. So B high would be the the instruction for that. And you know, like naming things is hard. It's just some engineer needed to decide what to call that condition. If it's for unsigned arithmetic and we see the CPSR flags that are checked there. So the way that we write a branch instruction B with the condition that we want to check and then. The label that we are going to. We do not specify registers for our branch instruction. The assumption is that some. Earlier instruction has set the condition code. Flags and whatever the most recent instruction was that set the condition code flags. Those are the conditions that are used to determine whether or not we take our branch. So we can have a comparison instruction just before a branch instruction. Comparison instructions always sets the ALU flags in CPSR and then you can branch based on the result of that comparison and unconditional branch has the. Implicit AL suffix, so B with no, you can just say B, You don't have to say Bal for always. That's that always condition is there, and if no other condition is specified, that's the one that is assumed. Incidentally, the always the condition code for always there is. 1110. So if we look back at our instructions here. The first four bits of all those instructions 1110 because every instruction in on version 7 starts with four bits specifying the condition under which it executes branch instructions. Will have different codes related to these and we'll see that we can also put different codes for load and move or whatever else we want. You can write an ARM version 7 program that implements if else kinds of logic, but never uses a branch instruction, which is also kind of a fun thing to ask about on a final exam. We'll see some examples. Of how that works, branching and ARM version 7 works. The way that we've. Discussed. We do not use the branch delay slot, so the instructions after the branch will not be executed. If the branch is taken in the pipeline, they just get killed because by the time the branch is in execute, we've fetched and we've decoded 2 more instructions, but they did the results. The partial results for those just get thrown away OK. So to support branching, we need to be able to set the different bits that are used to calculate these different conditions. There are some instructions that explicitly do so. These are the test and compare instructions. The test instructions perform perform the logical operations that you see there. Compare perform subtraction. The inverse of compare performs addition. You could just use a subtract instruction, but the value of a compare instruction is that it doesn't save the result anywhere, so that frees up a register, which will make your program faster because you'll need to spill register values to the memory less frequently. These instructions always update the ALU flags. So we can write a simple program like this. We see we load a value X into R0. We want to compare R0 with three that performs subtraction and we branch if the result is less than down to else. If we look at our C code, that's exactly the behavior that we want. We're checking to see if X is greater than three. If it's less than or equal, we want to go down to else. So the fall. Through code, the branch not taken code corresponds to the if part. When you're translating the C code into assembly, you don't have to respect the order in which it's written in C, you could flip it, you just have to change the condition accordingly. At the end of the if chunk, just like we saw before, we have to branch over the ELF part, so we branch to end down at the bottom, where we then store the value of Y which is in register one. So compare here is doing the work of testing our condition inside of the parentheses. For. If, but we can make all. Sorts of different ALU operations update the ALU flags, and the way that we specify that is by putting an S prefix at the end of the instruction. Add S is not. Saying something about signed S for whatever reason means update the flags. I don't know what the mnemonic is to help you remember that, but the S means update the flags. If you think way back earlier, when we looked at the first instruction encoding format, there was an S. Bits. Near the OP. Code that has to do with this that has to do with updating the flags. Add S will set the condition codes in the CPSR. Add will not sub S and compare there. Are the same. They're both doing the same operation because the sub S means update the condition codes. Here though, we are saving our results, whereas for compare we aren't. Lots of little tricks emerge in terms of ways to save an instruction here or there by making clever use of. Opportunities to set. Condition codes and avoid inserting a new comparison instruction, for instance. Here's a version of our if else with no branches. Do you have a question, Muhammad? Why do we need to use add S or sub S if we have compare? Well, it could be that I actually need to use the result of that subtraction so I could perform the comparison to see to see what the difference is. But if I'm going to perform a subtraction anyway, I might as well perform the subtraction, save the result, and update the ALU flags, and maybe that saves me an instruction. And saving an instruction might not sound like a big deal, but most for loops are pretty short. So if I've got like 5 instructions or 10 instructions in a for loop and I can save one, that's a free 10% performance improvement. 10% performance improvement is a really big deal, incidentally. Yeah. In lab one, your branches worked different so that the branches themselves made the comparison and no AO. No other ALU operation could have flags that would be useful at all. It was only in the context of branching where your control logic would look at the ALU flags and decide to do something. Does that answer your question? So the ALU flags are what we save basically in the CPSR and in Lab 1, you didn't ever save them. You would only ever look at them as the result of a branch executing and it would only ever be determined used to determine whether or not that branch should be taken or not. Whereas here we will update the condition code flags anytime one of our tests or compare instruction executes or an ALU instruction executes with the S prefix suffix. And then it turns out that not only will branch instructions look at those flags, we can rewrite our if. Else code like this and the flags are being looked at any time we want them to. So this code is equivalent to that code in its execution. But not only is this shorter, it's also faster because I don't do a compare, I don't do a branch. The way that this works is that when the program gets to the first move instruction in the execute stage, we'll just check to see what the flags are, and if the condition greater than is not satisfied, this operation will not be performed. 7 will not be moved into. R1. Now since we have move GT and then move LE, that covers all possible cases. The comparison will either be greater than or less than or equal. That covers the entire probability space. So if the first one doesn't execute, the second one will performing the move of 13 into R1. No matter what happens when I execute this code, the whole if else block takes 5 instructions. I have to fetch, decode and maybe execute each one and maybe executing takes as much time as executing whereas back. Here I have to on the if path I do load compare, I have to execute the branched instruction whether or not I take it. If I don't take it, I then. Move branch to end and then store 6 instructions. If I take the other path load compare branch, this time I take it move store 5 instructions, one path, 6 instructions, other path, 5 instructions I have. The performance loss when I take a branch of losing the fetch and decode here. It is always at least as fast or faster. Yeah, Arda are B and Bal. Are B and. Bal the same instruction? I believe so, although I have never tested this. Do you ever? Write. Bal. I don't think there's a reason to write Bal when B works just fine, but it'd be A a simple thing to test in the simulator to see if it compiles. If it assembles to a different machine code, I don't think it would OK. Any questions about any of this stuff so. Far before we dive into a more lengthy example of an assembly language program. Yeah. We don't use. Correct if you use the sub S instruction. You. Don't have to then have a. Comparison instruction that makes the same comparison. But only if you do sub S, so. My recommendation for the first programming that you do in assembly is don't be cute. Perform a direct translation of C into assembly. Don't look for ways to optimize. Make a second pass just like a good compiler. If you want to optimize, write the obvious naive, poorly performing direct translation. 1st that's important to be able to do. That's what I'm going to expect. You to be able to do on the exams, unless I'm specifically asking you to perform some sort of optimization, don't be cute, you'll just cause headaches for yourself as you're also trying to learn how to do the debugging in this kind of environment. So write this. Don't write that. Use compare, don't use sub S But if you want to experiment and see how you can make your code faster, make a new file so you're experimenting there. You can actually. There's a lot of hand optimization of assembly that you can do that will improve performance. Fewer instructions executed, fewer memory accesses performed, so on and so on. But it's tricky. And it's tricky in part because it's so hard to debug and it's real easy for things to go sideways. Ask your question. OK. So. Now. What we're going to do is take a look at a relatively simple idea of a program just calculating the dot product of 2 vectors. We've got our C code here. I think this is the. Same example program that I give at the beginning of lab 2. The exact same code. The C code compiles if you want to see how it behaves, and we're going to walk step by step through the definition of the assembly for it. So in C, the first thing that we do this is like. Circa late 90s early 2000s C language programming, where all of our variables have to be declared before we do anything interesting to them, we have all of our variable. Declarations in C. We can do the same exact thing in assembly. We have our variable N which is specifying the length of our vectors. We specify that with dot word 6 and then we name vector A and vector B. Each label is declaring A an alias for a memory address that we will use to access the data there, just like in pointer talk. So vector A is 6 elements, vector B is 6 elements. Again, it's dot word and then you. Separate with a comma the different numbers that you want to go there. Incidentally, I discovered that if you put an extra after the last one, it'll allocate another. Word and initialize it to 0, which I didn't expect. It didn't complain about it like C or Java might complain by saying something's undefined, so be careful. I'll get to your question in just a second, Lucy. And then the the fourth line in our C is the int dot P. That's where the answer is going. We have not initialized it because we don't need to. There's no point. And So what the assembler does is it just allocates space for it in the number of bytes necessary. Dot space 4 says allocate 4 bytes at that label, so we have space. For an integer, because we're doing the dot product of integers, not half words, not characters. Lucy, your question, but Jack? Predict damn questions phrase in this way are always big endian formal. Little, little Indian. They're in the order that we specify, yes. But the values themselves. So the values themselves like 5/3 negative 16. And then -6 I mean, those numbers will be saved in memory, Little Indian. And then reading from left to right, N is at address 05, will be at address 4. Three at address 8 and so on. Memory gets allocated and sort of as you March along through the list. OK. All right. So we have our for loop, that little for loop. Becomes. All. Of that code in assembly. In part because C, Java and so on are rather. Expressive we can put a lot of. Operations on a single line. On that single line dot P plus equals we're doing a multiply accumulate. There we multiply the. Elements of vector a with the element of vector B and then when we add it to the running sum of dot P. That's what's happening in the C code. And we do this as many times as we have elements in our in our vectors. So in the assembly up above the loop label, that's where. All of our initialization is happening. We have not initialized dot P, but we do need to initialize a register to. Hold. That result. So that's what's happening at the top. We will accumulate our result in R3. We started off with 0. In the next two lines, we are loading the value of the label vector A into R0. We are getting a pointer to vector A. We want the base address of vector A. If we did LDR vector A without the =, that would just give us the 1st. Value there 5. But what we? Want is the memory address of vector. AR0 is a pointer. R1 is another pointer. They each hold memory addresses pointing to the location of our. Variables in the code. The third one load R2 NI. Want the value of N in R2 because that tells me how many times I need to count down in my for loop or how many times I need to count up and then do my comparison. So then we see R6 is getting zero. That's I and so I zero and more will be compared with NR 6 will be compared with R2 to decide when we are done with our loop. And if you see the first instruction after the loop label, it's that comparison we perform R 6 -, r two, and if the result is greater than or equal, meaning if in this particular case N is 6, once R6 is 6 they are equal, then we will branch down to the end and our loop will be done. Until that happens, however, we run through the rest of the code. We load from vector A. What does the comma #4 mean in that in LDRR 4R04? What does that mean? What does that do, Muhammad? That's right. We load from the address specified by R0 and then we add 4 to. It that the next time we come around, R0 is four more than it was before. We do the same thing when we load from vector B perform our load. It's like it's the pointer plus. Plus is what we're doing there. We use the pointer value to access memory and then we increment it by the size of our data type, which in this case is 4. Then we've got that multiply and accumulate instruction with four operands, R5 times R4 plus R3 back into R3 we increment. I and then we. Branch back up to the top the first interesting complete assembly language program that you've seen. Yes, Maeve. So it's always a little hard. To figure out how to explain this clearly because it kind of goes back to this. If I load R0NN specifies a memory address. That that replaces my effective address calculation. I get the value stored at N So if I did LDRR 0 vector A vector A the label defines the first memory address Vector a the label defines the first memory address for that array. If I do, if I load from. Vector AI get 5. So. If I load from the memory address defined by vector, AI get 5. If I want the memory address itself in a register, that's where I say equals. Give me the value equal. To whatever and put that in the register. So back here in our previous example, if I say if I say. Load N into R0, I get the number 7. If I say load. Equals N into R0I get the memory address of N. It gives me the value of the label that is specified. So in this case equal MI want the value of the label. The value of M is hex 12. The value of O is hex. 1234 so the = means give me the value of the thing that I'm specifying, not the thing that's there. If it's a memory address that answer your question, Arda. Yeah, every label is a memory address. And if you want the value of it, you can think of the & or deep referencing a a pointer kind of a thing. You want the address of the value of a label. Because when we say loop there we when you say ends there and when we say we don't have the_start listed here, a label. You can have a label on every single line of your program. The label is just the memory address of the next thing that is defined. So loop is You could actually put loop. It's the same line as CMP, the value of loop. Is the address of the CMP instruction the value? Of vector a is the address of the number 5. The value of vector B is the address of the number two. Yeah. So if you don't have the equal. Sign. You use the. Label as an effective address and if I tried to do M without the equals I would have a compilation error because I have not defined a label. MMM, in this case is an alias I can load from N. Because it is a, it is a. Label it is a location in memory. M does not get a memory address. Here M is not defined in memory. M is like found define M. 0X12. How do you? Do preprocessor directives in Java? I don't remember I all I remember is C where in CI would say pound define, give a name, give a value and then what the compiler does is everywhere it sees that name it just copy paste the value. That number, never the number never gets a spot in memory, it's just a copy paste. So dot EQ you copy paste every place M appears, that number goes instead. Lucy using load operations, we have to first load it into a register. So if you want to use N as a starting point and sort of move around in memory nearby, you would want to load the address of N into a register and then you manipulate the register. N is well. So for the for the purposes of your program, for the purposes of the assembler, N is a fixed. Location in memory. It is the. Location in memory where the number six I'm going forwards instead of backwards where the number six is stored. The assembler knows where N is and it is a constant. Location does not change, but you can load it as an address and work with it. That's how arrays work, right? We start by loading the base address into a register, and then we can iterate through the elements by performing arithmetic on that address. So this is version. One of our program. This is the most straightforward naive direct translation. That means that it's inefficient. So if we change, if we change from a for loop to a while loop. And remember from our previous conversation, according to Professor Dubach, because I never took an undergraduate compilers class, I just took a graduate optimizing compilers class where all we did was just write optimization passes. I don't actually know how parsing works and all that other stuff. There's a great undergraduate compilers class in the computer science department, if that's of any interest to you. Professor Dubach says all four loops become while loops in compilers because they can be translated into assembly more efficiently, and we can see that here. So we do we have a do while loop and we. Use the same basic logic. But our loop is actually substantially shorter. So our loop code. Here is compare branch load, load, multiply, accumulate, add branch 7 instructions 7 instructions that have to be executed. Every single time we go through the loop body, we count a branch being executed even if it's not taken. Because we have to do the work to check to see if it's taken, it counts as it being executed. Here our loop. Body is 5 instructions instead of seven. We still do our load load multiply, accumulate. And then we have. Sub S Instead of compare here, we have to add something to I and then jump back to the top and we do a comparison to see if we've met our boundary condition here that's being collapsed into a single operation and. The program has also. Been rewritten to eliminate one of the two branch instructions. The for loop has a comparison and then they jump over it to the end with a unconditional branch at the bottom. Whereas here, since it's due while we go through the loop body and if we're not done yet, we branch back up to the top, but if we're done we just fall off the. Bottom Ryan. Yeah. The end. It's true that if if you're writing code where you want high performance for very short vectors, you might think about this differently, because to have do while you have to check that you have at least. 1. Whereas the for loop will work. Even if there's zero but if you. Have. 10100 thousand 100,000 elements, then the performance advantage is clear and so. All. Software is written in context. If you're writing this, you have some idea about what it's being used for, and maybe you have to. In order to protect against the base case, you have to have a little. Code that checks do I have at. Least one element, I mean all. Software. The first thing that happens inside of a function should be to check to see if the values being passed to that function. Are appropriate. That's just good software engineering. I'm not a software engineer. That's good software engineering practice. You want to check to see that your function calls actually valid. Otherwise, you want to have an error message of some kind. Any other questions about this program? Is that a question Tyler or just stretching? OK, All right, So I. Highly recommend. That when you are starting Lab 2 that you actually go through the trouble of taking the assembly that I've given you in the Lab 2 spec for this program. I don't remember which. Version it is. Doesn't matter though. Copy, paste, put it in the simulator, step through it, look at how memory changes. It will eventually change because we store the results in a location. Look how the. Register values are changing. It's a known program, you could calculate the output. On your own. The emulator by default is just going to show you everything in. Hex explore it. You can manipulate that. You can change it so it shows register values and memory locations in signed or unsigned decimal. You can change how many words of memory show up on a single. Row Explore this with a known. Program so that you're not doing it the first time. When your code doesn't work. Because when your code doesn't work, you won't know what you're looking. For and it'll be a lot. Harder to figure out what's going on. Spending a little bit of time just to familiarize yourself in the context of something that's working in a predictable way is worth your effort. OK, so the. The last little bit of our C program is this printing stuff and. We're not going to look at the assembly that would be required for that. The main reason is that printf is actually if you when you call printf. What then happens is an incredible. Amount of software execution. If you were to compile this C program without printf. And with printf and then compare the sizes, you will be astonished at how much bigger the program is just with that simple function call that. The problem is that it's really not a simple function call. There's lots and lots of layers of complexity in printf that has to interact with the operating system and all. Sorts of stuff. That's the beauty of libraries. You sort of. Have a function. Call in standard C. And then all. Of the details are abstracted away by lab. 4 You could actually. Implement something like printf on your own. Because the emulator has a VGA screen and part of lab. 4 You will be printing stuff on that VGA screen. It's possible to print characters on it, but you'll spend the entire semester developing the expertise required in order to do printf debugging, so it'll be good to lean into register and memory debugging, at least for a little while. And we'll talk about IO in a little while. The IO stuff is the first step that won't be covered by the midterm. We will get to it just before the midterm essentially. And so here's the whole thing. The only thing that we didn't look at in particular is the_start directive that basically defines the beginning of main a. QUESTION that we haven't talked about yet is how does the CPU KNOW what PC SHOULD be to start your program for? Lab one PC WAS always started off at 0, but here PC WILL just be set to whatever the. First instruction is after start. Start defines a memory address. That value gets moved into PC. And then your program begins to run. So if you think about the things that we've talked about, when your program is going to start to run in a normal computer like your laptop or your iPad, when you begin to execute the program, the first thing that it does actually is copy all of your data into the specified locations to initialize variables. Once in all the variables have been initialized, it will then. Save to PC the value. Indicated by starts. Once that happens, the next instruction to be fetched will be move R3 because anytime you change PC, you change the next instruction that's being fetched. So when you write a program and define main, you might say what I write right underneath main is the first thing that happens. That's actually not the case. A lot of other stuff happens to prepare the program to run before that first instruction after main. All of that stuff. Is taken care of for you by the compiler. It automatically generates all of the code to do that initialization for you. The assembler has an easier job, but it does basically the same thing. It copies this stuff into memory. And then it sets. PC to the appropriate value ARDA. Yes. So the question is, what's the point of dot? P and you just allocate space. You just allocate space and memory for your final result and I think. Maybe this is a bit too computer sciency for us, but in computing the only state that matters is the state of memory. If you have saved a result in a register, that's not really saving a result because the next program that. Executes is going to write over it, it goes away memory. Is the computer is where the computer's interaction. With the outside. World. Manifests. So if I have a program that produces a result, it has to save it in memory, otherwise it didn't happen. So what's happened? All we do there we declare space. We declare a single word and right before the program ends. We save the value there and we're done. Now, that's kind of different from the way that you write a lot of C programs and Java programs when you're learning how to. Program. Because. Your. Output might be just to print some stuff to the screen which you then save and then that's what you hand in, because that's like proof that it did a thing. But in in real computing we modify files which are mapped into memory. We write to robotic actuators which are just values in memory. Memory is the. Place. Where the changes that the CPU made are manifest and if memory doesn't change, the program didn't do anything. Could we store the? Value could we store? The value without allocating space for it. Let's say I did not allocate space for it, but I provided the label. What memory is at dot P if I don't do dot space? For something else What the move instruction? If I don't allocate memory for it, something else is already there, the move instruction because the label is the address of the next thing in memory that comes. After it. So if I get rid of dot space for, the address of dot P is the same as_start which is The move instruction. And so yes, in this class you can write self modifying software, you can write programs that write over programs, which is actually an interesting thing to look out for. If you've got an off by 1 error, you might be messing with your instructions and you can go and check. You can go and look into memory and see Hey y'all Taylor Swift Friday night, Thursday night, I guess. Actually my marathon is on Sunday. It's a big weekend. Enjoy the new music. See you later.

Seek back 10 seconds

Pause

Seek forward 30 seconds

Mute
Current Time 
0:02
/
Duration 
1:19:54
 
1x
Playback Rate

Captions

Fullscreen

Picture-in-Picture
