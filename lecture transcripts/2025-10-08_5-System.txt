
2025-FALL / ECSE-324-001
Captions
Search current recording by keyword
Brett Meyer, Prof: Good morning! Don't make me shout, because I'll break the ears of whoever's listening to the lecture recording. Thank you! Alright. So, we have a… One-off change, of course, in the lectures today. We're going to be covering system software. We're done talking about ISA stuff. Today is also the last lecture where I will present material that is covered on the midterm. So when we get back from… when we get back from the reading break, there's a couple more lectures before the midterm, I think. Cause we're 2 weeks out. Come next Monday? And that lecture material is important for the upcoming labs, and it will be covered on the final, but it's not part of the midterm. So after today, you've seen all the material, you should be able to go and do Last year's midterm, previous year's midterm. Without any issue. Now, if you go back far enough in the midterms. because of the recent addition of the… of Lab 1, Lab 1 used to be what is now Lab 2. We did cover some I.O. stuff before the midterm in the past, but the processor design stuff has sort of rearranged the schedule, so if you look at very distant past midterms, you'll find stuff that is not covered on your midterm. So just know that if you find I.O. stuff that you don't understand, that's reasonable. Also, the finals are all cumulative, so if you're looking for more problems to do. definitely go check out the finals, and again, find stuff that you think you can do. If you have questions about what you should or should not be able to know. There's plenty of problems there to work on. Okay. So, today, we're going to be talking about system software. And what is meant by that Is all the software that needs to exist in order for you to write software that does something. So if you sit down and you do a little programming assignment, you write your stuff in C or Java or Python or whatever, you hit compile. There's a compiler and then an assembler that builds an executable. But that's not the end of the story for any of the computers that you're looking at right now, because they all have operating systems that those executables need to then coordinate with in order to be actually to run. We will talk about all those different building blocks today. In this class, you will learn about some of the functions of operating systems, not only this lecture, but later on when we're talking about virtual memory. But for your programming assignments, there is no operating system, which removes, sort of, one layer of Messy indirection that we otherwise have to deal with. But the… sort of the magical, beautiful, wonderful thing about being an engineer today is that you don't need to know how to write an operating system, you don't need to know how to write an assembler or a compiler, you don't need to know how to write graphics drivers or any of this stuff, you just have Millions and millions of lines of code available to you to lean on in the form of libraries, carefully defined interfaces. As long as you follow the rules when you're programming, everything just sort of works. Usually. And if it doesn't, maybe it's not your fault. So we're going to be looking at the different… a high-level view of some of the different building blocks that make that all happen today. In our slide here, we have a C file on the left. The compiler's job is to look at that text. and turn it into assembly language commands, like what you're going to be doing. You'll be writing those for Lab 2. For Lab 2, I give you C code, and you turn it into assembly. And fortunately, we have software for you so that you don't have to produce the ones and zeros on the writes. You call the assembler to do that for you. The assembler takes the assembly file and turns it into an object file, the object file being binary, whereas the assembly file is still human readable. Once you're comfortable in an assembly language, you can look at the code in the middle and understand what's going on. That is one of your goals before the midterm, to be able to look at assembly and understand what's going on, to be able to look at C and turn it into assembly. Those are some learning outcomes that we're looking for. If we step back, Most programs are not so simple. We often have more than one object file that we are compiling. And those object files have to work together. They might be all written by you, or they might include libraries not written by you. And so there's another piece of the puzzle called the linker. The linker takes all of those disparate object files. And build them into a single binary. So we have functions that you wrote in file 1.0, functions that your project partner wrote in file 2.0, and then functions that someone that you'll never meet in open source library, for instance, wrote those functions in file 3.0, and, Each of the .0 files are assembly language snippets, essentially, that's been compiled, so you have all of your instructions, function calls, branches, data's defined. And then the job of the linker is to put them all together into a single file, and make sure that all the different parts that need to talk to each other among those files can do so. If you have a function call in file 2 to file 1, Well, some piece of software has to figure out what the address is. To send the program execution to in order to execute that function call. That's what the linker does. For the purposes of 324, that's sort of where things stop, because we don't have an operating system. all the laptops and phones and tablets in this room, though, are running an operating system, and then the operating system has a program called the loader, and the loader has the job of taking that executable, which is a file in a file system, copying its contents into memory, and setting up the CPU to be able to actually run it. Embedded systems, when you turn them on, PC is set at the appropriate place for the program to start running. But if you have a… if you have an operating system, we have an additional program that has to run to say, put this thing in memory, and then begin execution. The way that that works… is that… The loader is a program that someone wrote that reads, from an I.O. device. Your program that you wrote, and copies it, word by word, into memory. and then set PC to be whatever the insertion point is for your program. And then your program, it might run, initializing some data before it finally sets PC to be main, where it actually starts doing its work. So, but everything that's happening on the CPU is copying stuff into memory and then changing PC. Copying stuff into memory, changing PC, running the program, and then we have to… Clear stuff out. The loader handles the winding down of execution 2, because we want to give that memory back to the operating system after your program is done executing. Let's take a look at the assembler. So we have an assembly file there in the middle. And the assembler… You can think of it as being kind of like a compiler. They do similar things. One of the first things that the assembler has to do is Parse the text that you wrote. So the assembler, first and foremost, is a… String Reader. Every single line in your program is a string, and it has to check to see if you are following appropriate syntax. You can experiment with this with the emulator. You could try to go give a natural language description of your program and see what the assembler does with it. It'll just die after the first line, as you'd expect it. It's not a chatbot. So the… The assembler will read your file, line by line. Identifying valid and invalid syntax, and as long as all of your syntax is valid, it will produce machine code over on the right. And producing machine code over on the right means identifying all the data and instructions, producing the binary for them, and deciding on the order in which they appear in memory. That last part, deciding on the order in which they appear in memory, is actually usually very simple. Because PC equals PC plus 4 over and over and over again until we hit a branch, right? So if I have… Load, move, move, compare. Those four instructions need to be one after the next in memory. The assembler starts at the top. It says there's a label N for a 4-byte integer that should be initialized to the number 3. Put that in memory. Next. Load, put that in memory, next, move, put that in memory, and so on and so on. In general, it's a straightforward process. Lucy. Compilers often do this. Assemblers… Maybe? But when we talk about… Reorganizing code, That tends to happen… In the compiler, before it produces assembly. Because what the compiler will do, and we won't talk about this very much later on, but we will take a look briefly, the compiler basically turns your text file into a graph. Were each of the nodes our operations or data sources? And once it's in the form of a graph, there's all sorts of interesting stuff that can be done to manipulate that graph without actually changing the final result of the computation. So there's Have you ever wondered why graphs matter? Well, compilers are built on graph manipulation, for one thing. But you could… It sort of depends on the particular hardware platform that you're trying to assemble for. I think we could… I could imagine, although I don't know, that if you were going to assemble for a processor that uses a branch delay slot. That the assembler might move some instructions around. But that would require that the assembler know something about the dependencies between instructions. And the compiler definitely does, because the compiler has to build that graph. So I don't know if assemblers go through the trouble of building the graph to be able to identify dependencies and be able to make those sorts of decisions. That'd be a great question for Professor Dubak. This is outside of my expertise. Does that answer your question? Probably then, and more. Okay. I think something that's worth noting here, The assembler will recognize directives, Like.global. and…word, and .equ. But not all of those directives become things in the object file. EQU, if you remember from a couple lectures ago, it allows you to set an alias. You can say .equm, and then give it a value. M doesn't appear in memory. EQU does not allocate memory, The assembler, in seeing that line, will not put anything in memory. But when it sees an instruction, or when it sees .word, or whatever, it's gonna allocate space, and then fill that space with something. The last bullet here… says… Building a symbol table. And, the symbol table is a record of all of the named things in your file. So, when you provide a label. The label N specifies an address where that word is. The label loop specifies an address where that instruction is. the add. The label end specifies an address where whatever the next instruction is. Those names go into a table so that if any other object file Says that they want to branch and link to loop, or whatever, then there's a memory address associated with that location in this file. So let's see how this works. We're gonna use the same assembly program. The assembler goes line by line, it sees the label N, And it puts an entry in the symbol table. And then we see that there's a directive that follows.word. 3, so we have a 4-byte word that we need to allocate space for, and it's supposed to be initialized to the value 3. So our symbol table has n and an address, 0, and then our object program memory map at address 0 has the data 3. Moving on. We have a load instruction now. We have a load instruction that is referring to the name N. Well, we happen to know what N is, because we have already seen it. It is in our symbol table. But to figure out what to put in memory, we have to refer to the instruction set architecture for ARM version 7. If you go and look, you can find a detailed description of what the machine code is supposed to be for a load instruction. Like usual, we've got the condition code at the start. The 010 specifies that this is a load, P, I think, it's either P or U. I don't remember which. That specifies whether or not we're doing plus the immediate value, or minus. Remember, for the load instruction, the immediate value is not signed. So we have a bit in the opcode that determines whether or not we're doing addition or subtraction, and then so on. So with that information, if we wanted to by hand, we could figure out that E51F000C, is the correct machine code for our loadR0N. Do we have? We don't. So… You see the disassembled machine code there? Remember, on the right here, load R0N, N is the effective address. We're replacing the value of the address N in there to give us the effective address that we want to load from. But we're gonna use PC Indra… PCI Indirect… or PC offset, PC relative addressing in order to actually get it. We know that N is at 0, and when the load instruction is executing, PC is not 4, it's not 8, it's actually C, So, PC minus C… You can see C in the last byte of the actual instruction there. That's what gives us the actual address that we want to be loading from. Ryan. It would have to, right? So the… when the assembler sees a reference to N, it knows what the address of N is, because we have it in the symbol table, and then it can say… and it knows where the instruction is, it knows that the instruction is at address 4, it can do PC plus 8 to give it address 12, and it can say. is 12 minus 0 less than 4096? Because if it is, then we can do PC relative addressing, because my range, my maximum range with a 12-bit immediate value is 4096 bytes. So it has to do that calculation. And if N is too far away, then it would have to put in either a different instruction, or it might just complain and say, I can't fix this for you, you need to rewrite your assembly. Does that answer your question? Ed? Thank you. Yes. So it is in the… it is in the executable. And it is also a structure in the program that the assembler uses to do this. So. I don't think, but I'm not sure, that the assembler sort of builds the object, object file word by word as it's going, and then has to read from it in order to do this math. More likely, it's creating… it has a symbol table class. That it then populates with this stuff, that at the end. becomes the binary output that would go into the object file. But we'll take it… we'll actually take a look at some object files We will disassemble them in class so you can see that, yes, we can actually read the symbol table out of these things. And that's necessary because when you do the linking step in compilation, the linker has to go and read all the object files. It's not reading the source code. He has to read all the object files to find the locations of different things. So the assembler has it, and the ultimate binary also has it. Does that answer your question? Rachel. Well… Yes. So, ARM version 7 specifically says that when our instruction is executing, PC is pointing to PC plus 8 relative to the address of our instruction. So PC is 12 when that instruction is executing, and so then to get back to it, minus 12. Okay, next instruction is a move instruction. And in this case, again, we could go and look at the, ISA to see what the… Format ought to be. You can see again, because of operand 2, the immediate value 1 is visible in the last byte there. And I also want to draw your attention to the first 4 bits of each of these instructions. It's E, that's the always execute condition. Once we run into a branch, we'll see that it's not E if it's a conditional branch, because it's a different condition under which the instruction executes. Another move instruction? A compare instruction, And then we have a branch instruction. Branch less than or equal to END. The assembler goes and looks in the symbol table. End is not defined. It is a forward reference, and is further along in the file. The assembler has not gotten there yet, because it's reading line by line. We don't know the value of end at this point. So… We can only partially assemble that instruction. We know that the condition is supposed to be D, and that the rest of the opcode gives us A. Again, that's just based on looking at the ISA. But the 24 bits… relative offset, the displacement for the branch instruction, we don't know. And in fact, at this point, it's possible that end is not defined in this file. In which case, we might have an assembly error. Because you're trying to branch to a symbol that doesn't exist. So we create an entry in the symbol table, but it's undefined, and we can't fully emit the instruction because the target is undefined, too. We run into loop. So now we have another entry in our symbol table. We have an add instruction. There it goes. Another one. There it goes. So we have two ad instructions. One is a 3 register ad, and another one is a 2 register with an immediate add. You can see that there's a couple of bits different, in the first byte there, the I bit in the machine code. The other differences are because the operands are different. Another compare instruction. And then we have a branch instruction. In this particular case, loop is in our symbol table. We know where loop is, we know what the address of this branch instruction is, and so we can look here, and then we can calculate how far away the target is. The thing I want to remind you of on this slide… Is the fact that when we perform the encoding of the displacement. that gets added to the PC, We are NOT… encoding the number of bytes that PC is supposed to move, but the number of words. So the encoding that we care about is encoding A1. The T encodings all refer to different thumb encodings. Those are narrower bit-width encodings of instructions, like 16 bits. So encoding A1 says multiples of 4 in that range. So, immediate 24, 23 down to 0. Is how many instructions are we adding or subtracting from PC to get to our destination? Which means that this immediate value will be read out of the instruction register. Shifted left twice. To change it from words to bytes. And then, added to the program counter. So that means, in this case, the displacement is… F, and then a B. Do you want to do the math to prove that that's the right answer? Or do you… we can do that right now, or you can do it on your own, but I always ask a question about branch displacement on either the midterm or the final. Oftentimes asking you to tell me what the 24-bit number is that's supposed to go into that instruction. Do it now. I applaud you for advocating for yourself. Okay, so let's figure out There's two different ways to do this. One is to figure out what all those Fs and a B is. Or, we can figure out what the correct answer is, and then find out what the hex is. Let's do it that way first. So… the address… For our branch instruction, is HEX24. So we are at… PEX24. And when that branch instruction is executing, what is the program counter? Santiago. That's right. So our branch instruction is here. But the… but PC is here. Okay, so now we need to know… How far away is our target? So, loop… Because we're going back to loop. Loop is at hex 18. PC is here. We want to go back to HEX18. And so… What's the difference between these two? We could either do hexadecimal math. And then shift, or we can just count instructions. So if we're at 2C, We have to go back 1 to get to 2 eighths. Go back another to get to 2.4, go back another to get to 2-0, 1C18. We need to go backwards. Five words. And if I have done this correctly… When we… when we change the number, into… whose complement, we'll be fine. So we have a 24-bit number that we're supposed to come up with. And we're trying to convert 5. into a negative number, because we're going to be adding a negative number. We want to go negative 5. So we do… This is lots of zeros… So we have lots of 1s… 1, 0, 1, 0 plus 1… gives us… a 1 here. And so, the good news is that That is beef. And it's a negative number, so all the rest of them are F. How many Fs? 1, 2, 3, 4. We have 24 bits that we need, so we need, 6? That is the displacement that we should be putting into our instruction, and that's what we have there. So, I'll note for you that the disassembly is not telling you how this works. The disassembly says BLE, and then has the absolute address that it's supposed to go to. It's not showing you the PC relative mathematics that are happening behind the scenes. 0x18 is not what's encoded in the branch displacement. What's encoded in the branch displacement is negative 5, because we need to go backwards 5 instructions. And then the computer will shift it left twice so that you're going back 20 bytes instead of 5 words. Santiago. Thank you. For a load instruction only, Only load instructions work that way. That's correct. And for a branch, you have 24 bits, it's N2's complement. The load instruction is weird. I don't know of any other one where they use a bit to specify addition or subtraction. Every other place that I have seen, which is certainly not everything, because I have not read the manual, nor do I ever intend to. But every other place. The operand, operand 2, or whatever immediate value, is a signed number in 2's complement, but not for loads. Because… efficiency? I guess? Remember that computer organization and computer architecture is all about having a general design principle. If you take computer architecture with me at some point, that general principle is make the common case fast. But sometimes you break rules in order to try to do that. You can have something that's the case for 99% of the time, and you break the rule in order to catch a little bit extra performance. And it's useful to have some idea about where some of these exceptions are, but I'm not going to expect you to regurgitate that kind of stuff on exams. Okay, so is everyone comfortable with how we calculate the branch displacement here? Carrying on. So, the next line that the assembler gets to is where end is. And so, it can… the assembler can update the symbol table. And we have the address of end there. So… The assembler, at least the way that they tend to be architected, it doesn't go back and then fill in the gaps. Instead, the assembler will just make a whole second pass. To clean things up. In theory, you only ever need two passes, because on your first forward pass, you should see all of the named memory locations defined. And it can do other little stuff, too, on that first pass. And then in the second pass. It can go in and fill in all the gaps. Like, where END is. So we can do our second pass, Can put end in. And at that point. If… after your second pass, if there's anything that's still not defined, then there might be a problem. At that point, the assembler might throw an error because it doesn't know how to find what it's supposed to find, or maybe It's just, like, an external function call, in which case it's okay for the assembler to not know where the file is, but then the linker, if it can't sort it out, it would throw an error of some kind. So, second pass, you can see the displacement there, it's 3. And we can sort of just quickly perform a visual inspection to make sure that that makes sense. End is at hex28. PC, when we're executing that branch, is going to be 1C. From 1C to 28, we go to 2024283 is the correct number of instructions we want to have the displacement to be. Questions? Ed. Yes. The PC is always in ARM version 7. It's different from Lab 1, because in Lab 1, it was always pointing PC plus 1, because you had 16-bit instructions and a 16-bit memory word, so it was always one instruction ahead there, but because of the three-stage pipeline that's assumed for ARM version 7, it's plus 8. The three-stage pipeline plus byte-addressable instructions are byte-addressable memory, and four-byte instructions. So, in theory. I haven't asked a question like this on the midterm, but I could ask a question, say. What if there was a different pipeline, and when you're in the execute stage, you're actually 5 instructions ahead, and instructions are 3 bytes. So PC is what in that case? And you should be able to figure it out, because every time you fetch an additional instruction, PC's a little bit farther ahead. And then you have a difference Relative offsets that has to be worked with. I didn't ask a question about that on the midterm. But I might want to write that down, because it's an interesting idea for a question. Okay. So that's the assembler. After all of your files are assembled in 2.0, It's the linker that has the job of combining them into a single coherent binary. So, here we've got a bunch of different files, some of which might be libraries, and how does Linker do this? You have different, distinct files, And each time the assembler is assembling these files. The assembler makes the assumption That everything is just gonna start off at address zero. But obviously, when you're combining four object files together, each of which might have functions and whatever in them, they can't all start at zero. That wouldn't work. It's not possible. Some of them have to start at other addresses, like you can see over here on the right. And it's the linker's job to figure out how to make that all work. So what are the different kinds of things that it has to fix? So, for one. The data and instructions for sound.0 are ending up at memory addresses different from what the assembler initially assumed when it was putting together that object file. That's okay if we never use absolute addresses. If we're always using PC relative addressing. For our branches, for accessing constants, it's fine. It doesn't matter what address my instructions are at, because the data that they access is always going to be just as far away as it was when everything was located at address 0. PC relative addressing makes linking easier. If… If we actually use absolute addresses, there is a way to fix that up, but then you have to end up I'm assuming… I'm not a compiler guy, I'm assuming that you end up needing to modify the object files in the creation of the big binary. Because you'd have to put data in locations and then tell the rest of the program that's using that data where to find it. Because it's a different address than what was assumed before. Another issue that can come up is that If main… is calling a function in sound, or in graphics. When we assemble main, the assembler doesn't know the memory address for those functions. Because the assembler only considers one assembly file at a time. And so then the linker… We'll have to figure out Which symbols are undefined in main? And find those symbols in other object files. Grab the address for them, and then modify the branch instructions. in Maine, for instance, so that they branch to the right place. So, for example. Here we have a different assembly language snippet, and we have a branch and link to an external function. The external function is in some other file. So, when we… Go through and do our assembly. We build our symbol table. And we have another symbol, external fun, which, by the time we get to the end of our assembly file, we have not found a definition for. And so, in the object file, it will remain undefined. Until we go and do linking. And then here. Main has an external symbol, external function, external fun, and then other file has in its symbol table, external fun, and then the link… then the linker can figure that out. When the linker puts together the two files in a single binary, it also then knows the starting point of each of those subparts. It knows how far into other File.0 external fun is, and it can therefore do the calculation of the branch displacement. And so then our… Our assembly goes from question marks. at address 10 to FA, at address 10 for the displacement. Okay. So, courtesy Professor Dubak, we actually have a simple… demo, where we can sort of see this in action. Is that the right one? It is. Okay. Though we can… Compile… foo.c. And now we have foo.o. And… We can take a look at… what is in this… oops, I was supposed to do a different one first. Okay. So let's take a look at what's in this first one. So… Bar.c just defines a function, and all that function does is return 3. And we can see… what's… Is in the object file. So when we disassemble, "-s on my computer does disassembly of the object file. We have… and because I did dash g, debugging information has been inlined with the assembly. We can see the source, the C source that is being implemented here. We were performing a move of the value 3 into a register, and then returning. That's all this particular file does. We can also take a look at the symbol table. So here's the exported symbol table. And it defines the location of the function bar at address 0. I don't know what these are. And we… there's other ways to, just see the exported symbols, too. And again, there's bar defined at address 0 in this file. So I've already compiled foo.c, Boo. Calls bar. So we can do an object dump, of… Foo. And we can see… That we have some more assembly here. And we have a branch and link. But it is not well-defined here. Which we will also see if we… Look at the symbol table. So, we don't know where Barr is. We still have to specify an address, because that's the structure of the table. And we can see that we're branching and linking to 1C, which is just… Exactly where we are. not very useful. We can resolve this by linking the two files together. So now, oops. Let's actually name this properly. So now, if we go and look at… That's nuts. Hold on a second. What I wanted to do… was this. Ugh, what did I do wrong? Okay. So… So this… this is actually… this is… this is correct. I don't know what was going on the first time. So, when we looked back, when we… when we look at the object file for just foo. We have LTEMP. It's unresolved. When we look at the one for combined, it's actually defined to be FU, Foo plus that, because we're calling bar from foo, and here it is down there. And we could do the math where it's… we need to be adding a certain amount in order to get down there. And we won't trouble ourselves with that right now, but the undefined symbol isn't there anymore. It's been resolved. And… I don't know why it's not showing the source code anymore, but I think I must have missed a linker flag when I was doing that. One thing that I will note is that these files are not intended, really, to be human-readable. Because, for the most part, humans don't do this… these steps anymore. Oh, I put it down here. It's all… automated. So the linker is able to… Read the symbol table out of the object file. Build an internal data structure, and then use that data structure in order to resolve these different things. Any questions? This is funny to me, because when Kristoff teaches this class. He trims out the more hardcore computer engineering stuff, like the transistor level layout of a NAND gate, because he doesn't feel confident in explaining it. And it makes me think that some of this compiler stuff, maybe I should just… delete the slides, but I struggled through it for you. I never took a compiler's class. But they do a lot of cool stuff. It's worth taking if you have space in your program. Computer Science offers it. Yes, Lucy? I can tell you exactly the kinds of questions I have asked in the past about this stuff, and it's… Build me the symbol table for this assembly code. So, that's straightforward, at least. All you need to do is do what we've done in this example, which is basically go line by line. Find the symbols, Calculate the address that they're supposed to be, stuff like that. I also ask you to calculate branch displacements. Those are the sorts of typical things I would ask about this stuff. Rachel? It's, like, on… slide. doing that calculation. Yep. Where was that? What slide number is that on? It says 21 in the bottom corner, or it says… okay. There we go. So, FA, That comes from… something very similar to what we did here, except that's in bytes. So if you take the address of external fun, which is… Hex, 0X, and then 400. And we know the address of our branch instruction, which is hex010 plus 8. when we're… if I subtract the location of external fun. minus the location of PC, and then I shift right twice, I get the difference in words. And that's how we do that encoding for the branch displacement, and then we reverse that process. We ship left by 2, and then add to PC, and then that's how we actually execute the branch instruction. Okay. So… The little demo, and all this other stuff. We haven't seen Maine yet. If you actually want an executable instead of just a library, you have to define main. I'm assuming at some point, you've been doing a programming assignment where you did not define main, and you tried to go to compile, and it says, like, sorry, where's main? We, you know, like, we can't turn this into an executable without main. the way that we define that in ARM version 7 assembly is we define a global variable start, and then you… You have to say this is a global that allows every other assembly file, every other object file, to know that start has been defined someplace. And then we have to actually create a label in one of our object files, that is that same label, underscore start, and then that's what the PC value will be set to when your program actually starts to run. The loader, after copying your program into memory, we'll execute… something that eventually gets your PC value to be underscore start. This is another slide that's really over my head. I have struggled with linking against dynamic libraries my entire professional career. I don't know how it works. I can't seem to make it work. I understand, in theory, what it's supposed to do, and so that's what we're going to talk about. when we do… Static linking. We take the object file for every library that your program might use, and we build it into our binary. What that means… Especially… in the context of our massively multi-programmed laptops and stuff, is that if every program, for instance, is compiling and linking with printf. It means that I have, perhaps. 100 programs, processes running on my laptop, and maybe all of them have print apps somewhere in memory. 100 copies of printf in memory, because when I begin to execute my program, I take the entire binary, and I copy it into memory, and then I set PC and whatever. And if they all have printf. I have 99 copies of Print Up in Memory just wasting space. Because if you write a program that uses printf, and I write a program that uses printf, then we only need one copy of printf in memory. That's the idea of shared libraries. So, graphics drivers and sound drivers work the same way. Your programs that use sound or graphics, they don't all need to have all of the object files for graphics and sound in their executable. Because if they're loaded somewhere in memory, then the program just needs to be told Somehow, by the operating system, what the addresses are for those functions that are being shared across multiple programs. There is a way to tell compilers to do this, I've never had much luck. But it works, because anytime you do anything in a computer with a graphical user interface. There are libraries running in the background that make it possible to display stuff on screen, and they aren't being linked with all the executables in the system. The library is sitting somewhere in memory, program A and program B are… don't have them included, and it means that you save size in terms of the binary, and you also save memory because you don't have multiple copies. Because on the right-hand side, we would have multiple copies of the same library if we weren't dynamically linking. But dynamic linking means that each time you run your program, program A, the library for Lib Sound might be in a different address. So there's something negotiated through the operating system. That tells the program where the function is. So that the appropriate branch instruction can be executed. That, to me, seems like magic. I guess to other people, transistor-level design seems like magic, but I don't know how this works. I've never asked a question about this on an exam, either. And honestly. I don't think my operating systems class talked about this at all, but I have no idea whether or not yours does. And you haven't taken it yet, because I think 324 is a prerequisite. But if you take a compiler's class, in the class, you'll write a compiler. Take the operating systems class. In the class, you will write an operating system. Probably not with this part, but… A lot of the basic building blocks. Quickens? Okay? The loader. So… If… If you are C. Dubac on your Linux laptop. and you want to run Hello World, You've got your terminal open. You give this command to the terminal. the terminal is going to interface with the operating system to call the loader that will take the location of Hello World in the file system. and then copy it into memory so that it can actually execute. Because when… before you hit enter here. in a terminal, the program that you're trying to run isn't in memory. You cannot change PC to a value in order to start to run it. It's a file. So, what the loader has to do, first of all, it has to identify a memory address in which to copy the thing. Needs to then actually do that. And then it has to set the PC to be the first instruction of that program. And incidentally, the first instruction of Hello World is not the first command in main. Necessarily. Because if Hello World initializes data, that's an additional step that has to happen before main can start. So the loader copies it into memory. The program might then do some additional copying in memory before main actually starts. Ben… Once the program returns, once Hello World is done, at the… even if you have void main that doesn't return a value, there's still a point at which it ends and it's supposed to return, then the loader will free up the allocated memory. Because on your laptop, you have 4, 8, 12, 16 gigabytes of RAM. When your program is done executing, that space that was given over to the program Well, the operating system wants to keep track of it to be able to allocate it to something else again. So it sets up, runs your program, and then it tears down. So, we have our program gear. Assuming… it's assuming that its, instructions are starting from address 0, But that's not actually what happens in memory, because address 0 might be busy doing something else. It goes into a different location. and then we set up PC, and then your program executes. And then we… Deallocating, we don't actually have to do anything to memory when we deallocate. The data can stay there. But the operating system just needs to update, the data structure that's keeping track of which memory is used or not. Which is interesting, Because there's a security privacy risk here. A lot of the really interesting security, privacy things that have come up in Intel architectures recently have been because of data that wasn't erased, because it's not a thing we do because it's slow. You do some data processing, some of that information stays in places in memory or in registers. We don't go and zero it out. We just… Say that the space can be reused. But it does mean that if you have a… if you're a clever programmer, it's possible to get at some of those values. perhaps… Private keys for decryption, and other various different things. The allocation is just saying that those memory locations aren't being used anymore, and they won't be overridden until it's allocated to some other program. Okay. Compilation. So… Whereas the assembler… yes, Maeve. That is an oversight in the construction of this slide. would you send me a note in Teams to remind me to update that, in case I forget? Because that's a really good point. The PC should be whatever the last value would be for the program, at least something other than the initial value. Fair point. So, assembly, in general, is a very straightforward process. Systematically go through the file twice, Compilation? At least naive compilation can be equally systematic, but that's not how today's compilers work. They do lots and lots of optimization. one thing that I think can be really interesting, the next time you're writing a program, maybe not necessarily for this class, because we're not working with C or Java here. If you have control over compilation, you can control the level of optimization that's being used. If you do not say to optimize, no optimization is performed, and your code will be 2, 4 times longer than if you turn on the smallest amount of optimization. So it's interesting to look at file size, it's interesting now that you know some assembly language programming, it's interesting to look at Just the number of instructions that get written for simple functions. Some of the examples that we've looked at before. you have, like, a variable in memory, and let's say we update X. We might read X into a register, do our manipulation, write X back to memory, and in the next line, we're reading X from memory again, updating it, doing some data processing, and writing it back to memory. None of those intermediate stores and loads are necessary. We only need the first access of X, and the last store to it. But the compiler… without optimization does the same sort of literal translation that an assembler does in an effort to produce always 100% correctly executing code relative to what your specification was. Correct as far as the compiler's concerned, maybe not correct as far as you're concerned, if your program doesn't work the way that you want it to. So, a lot of work is done in that optimization step in the middle. To get there, first we have parsing. That's looking at the text of your source code, just to make sure that there aren't syntax errors. And if there aren't any syntax errors. then in the process of parsing, it builds an intermediate representation. That's the graph that I've talked about. Once we have a graph representation of your code, it's real easy to identify parts of it that are never expected to run. If you define a function, That's never called. And you have optimizations turned on, it's not gonna make it into the final binary. If you save intermediate values. in your program that are never used, and you have optimizations on, that… those calculations are not going to make it into the final binary. It's easy to look at the graph and see that there's a node that is not consumed any place. And you just delete everything above it. Once we've done optimization. Dead code elimination, there's constant propagation, there's, common sub-expression elimination, lots of different things that can be done, looking at graphs, finding things that are the same, finding things that aren't being used, manipulating them. Then we actually need to take a step of figuring out Which operations are gonna have values end up in which registers? Because if I need more registers than I have, I have to change my graph to be storing some values to memory in order to free up registers, and then loading them back later on, and so on. And then once I've done register allocation, we can actually do code generation, and it's code generation that produces the assembly on the right. Ryan. Yep. So, it varies from programming language to programming language. But in C, if you want a function to be externally visible, you need to say so. You have to export the symbol. And if you don't do that, then the assumption is that it's private, and if it's private and it's not used, then… It doesn't appear. Now, with object-oriented programming and classes and member functions and stuff like this, then, like, it's not… just because you don't call a function, like, if you have a public function, it's going to be exported and whatever. But then the public functions have to make calls to the private ones, otherwise the private ones aren't needed, and then they might not be… emitted in the assembly. And if they… and if they're… and that's fine, because… If it's a private function that isn't called by a public function, there's no way to actually call it. Does that answer your question? But this is why we have to do things like global extern blah blah blah blah blah in order to identify a variable that is accessible in another file, because you're cluing the assembler in, and you're cluing the compiler in first, hey, this matters, someone else is going to ask about it, don't delete this. But it actually makes debugging interesting, because if you have optimizations turned on, and you're saving a value in a temporary variable that never gets used anyplace else, and you want to do debugging to see what the value of that variable is. We're not printing it, we're just watching the program execute, and we want to inspect that variable. With optimizations on, it might not exist. Because it's not used anywhere. Which is why print debugging always works, because you consume the temporary values. But it's also why you should debug without optimizations. There's also debugging safe optimizations that you can turn on, that's dash O… G… in the GCC world. It will perform some optimizations, but not ones that make debugging harder. Ed. There are absolutely situations where optimizations can break the program. I've had this experience personally. in GCC, you… the way that you specify an optimization level is with dash capital O, and then a number, or a character indicating. dash O0 is… very minimal optimization or no optimization. Dash 01 is straightforward, safe optimization, but you can go up to, like, "-03. Each one of these different settings basically turn on a suite of optimization passes, things that happen in that optimization step. And I have had code go from functional to non-functional, going from "-01 to "-02, or going from "-02 to "-03. And I don't know why. GCC is an open source project. It is an excellent compiler, but the more optimization you do, the more chances there are that something gets broken, because you made different assumptions as a programmer than the compiler is making in terms of optimization. So… It's all, again, when you're doing development. You don't develop with optimizations on. And then you can go and play around with your… to your heart's content, once you actually know you have something that works. Does that answer your question? But yeah, I had that happen to me while I was a graduate student, and I didn't know why my program didn't work, and I couldn't figure it out during debugging, and I just turned off optimizations, and suddenly everything worked again. So I was just… I was more careful after that. So, it was Grace Hopper's name that I couldn't remember back in, the Computer Technology and Abstractions lecture. G wrote the first compiler while in the Navy. Back in 1952. And, she has a line of NVIDIA GPUs named after her now. The hopper architecture, I think, is what it is. Debugger… okay. Have you ever done anything other than… Print FDebugging. Have you used a debugger? Do you know what I even… what I'm talking about when I say debugger? So in this class, we don't have printf debugging. So you will have to do… more conventional debugging. We should absolutely learn this as a skill, because print app debugging is awful. It works fine when you have small programs, but the moment that you're dealing with anything real, it's useless. So I did all printf debugging when I was an undergrad, and the moment I became a graduate student, that was not the solution anymore. And then I became a friend of GDB, like a new debugger. We're gonna talk about rubber duck debugging, I guess, first. Have you ever done rubber duck debugging? Is this something… so… Did you have… Your intro to Software Engineering with Marwan? Or with Gunter? I don't know who teaches these classes, yeah. Do they talk about rubber duck debugging? No. Rubber duck debugging is basically, you just… Talk about what your thing is supposed to be doing, and in the process of talking about it, you figure out what's wrong. And it is a real thing. I absolutely cannot recommend it more. The number of times when I was in, graduate school where There were 4 of us sitting in an office together, and… We were working on similar projects, but never in… never collaborating closely enough where we could usually actually provide help. The simple act of writing something out on the whiteboard, trying to talk through it, I could just sit there and be quiet, and then the… my lab mates would just sort of figure out what was wrong. Because when you're sitting and thinking, you don't necessarily have to take the same linear approach to explanation that you are forced to if you want to explain it to somebody, and you can figure out, oh, all my bad assumptions. I can't explain this to you in a way that makes sense, so then you realize what the issue is. So, rubber duck debugging is amazing. definitely make use of it. Try to explain your code to other people. Other good things, unit tests, you can do unit tests in this class. You don't get to use print statements in order to help you, but, the… each of the two programs that you're supposed to write are going to be over 100 lines of assembly before you're done. Don't try to write the whole thing before you do testing. That's a terrible idea. Break it up into bits. You can manipulate register values, locations in memory, try to run little parts of your code. And see if it behaves the way that it's supposed to. Have you ever programmed with assertions? Some of you are saying yes. Have you heard of assertions? If you haven't heard of assertions, you can… There's a library called Assert in C. I think Java has built-in functionality for this. You say, in your code, assert that X is greater than 0. And wherever you say that, if it's not, then your program dies. And it tells you, I died because X was not greater than zero. So if you have a bunch of conditions in your program in different places that are supposed to be true for the well-functioning of your programming, you can use assertions to say. Check that this is true, check that this is false, check that this has this relationship with that, It's a real easy way to check the conditions on variables Before you start working on them in functions and stuff? Yes, Lucy? It exists in assembly if you write a library to do it. But in assembly, with our emulator, you can essentially do that yourself. You can put breakpoints at the functions that you write, or at different locations, and you can go and look and see. If you want to, say, assert that register 0 is greater than 3, you can find every place where register 0 is used, and you can do this checking on your own. But you don't benefit from libraries in this class, unfortunately. All the code that you will use, at least For now, is gonna be completely grown by you. For the later labs, we will start to give you some stuff, just to make your life a little bit easier. Let's see… So, I have a question. Actually, I… We don't really have time to do a demo of the debugger if we're gonna finish this stuff, so I'm just gonna skip it. And this class. you will learn assembly language debugging, but I would encourage you all to spend the time to figure out how to use the debugger, GDB or LLDB, depending upon the platform that you're working on. Because what I have… because, for instance, for instance, your program segfaults. Or you have, a weird Java exception. When you run in the debugger, the program will execute all the way until the instruction that causes the segfault. Or causes the exception. And it'll just pause there. It'll pause there, and you can look and see what the value of the variables are. It'll pause there, and you can look and see what… if you want, you can look and see what's in the registers. It is the easiest way to figure out where your program is segalting, is to use the debugger. If you never use it for anything else, I highly recommend learning how to use it for that, because you will never, ever have to write printfs, I got here, I got here, I got here, I got here, to figure out where your program is crashing if you use a debugger. And maybe… Next time, I'll show a brief, demo of it. Not feeling like talking about that today. Operating system. So… Most computers in the world don't have operating systems. Because most computers in the world are, like, in microwaves. And dishwashers, or toothbrushes. And… they don't need an operating system, and an operating system would be extra software and extra delay that don't make any sense, because the main role of an operating system is to coordinate the execution of different programs. If I have a lot of different programs that are all supposed to share main memory, the easiest way to do this For general-purpose computing environments is with an operating system. And the reason why it is so useful is that If I don't have an operating system, I can't do this here. where I change my program to be executing at a different address. If I don't have an operating system, every time I compile a program, the addresses that it uses have to be exactly the locations where they go in memory. But with an operating system. We can actually make it so that every program On the computer, thinks that it's running by itself. And has access to whatever addresses it wants. The operating system provides a level of indirection to facilitate this through virtual memory, which we will talk about when we start looking at memory hierarchy. The operating system also can make sure that your program Doesn't get access to data from someone else's program that's also running. Do you get security through the use of an operating system? If I don't have an operating system, I could write a program to just read out the contents of memory, and… Send it to whoever I want. Read all of your public keys and your passwords, and then just… Shoot them off over the network to somebody else. But an operating system prevents that from happening by making it possible… making it impossible for your program to access another program's data. It does this by standing in between your program and input-output devices. Any requests that your program wants to make to access an input-output device has to be approved by the operating system. So whenever your iPhone says, do you want to give this program access to your microphone? Do you want to give this program access to your camera? That's the operating system asking you to be involved in the setting of permissions for user-written software. Which is a great feature that has only recently been deployed in operating systems, which is crazy! Thinking about all of the cameras and microphones that have been deployed in computer systems where it might be possible to just Listen to you all the time. Or watch you all the time, and send your data to whoever they want. Anyway… When you take… if you're a computer engineer, you'll… do software engineers take operating systems, too? Or no? Yes? So I guess electrical engineers are off the hook unless you want to. Computer engineers and software engineers will have to take operating systems. You learn about all of these different interfaces to, do different things. Operating systems… provide the interface with I.O. devices, because as we'll see in the next set of lecture notes, anytime I want to access an I.O. device, ultimately I need to be accessing a memory location, because all the CPU knows to do is load from memory, or store to memory. Every single interaction with the outside world is through a memory access. And so things like, for file management, open, close, read, and write, these are functions that turn the interface with your hard drive into operations with memory. We call these functions… and now the program can access memory locations in RAM, And then that stuff ends up writing things to files, reading things from files, and so on. The operating system also can help coordinating between multiple, running programs. So… Sometimes our programs end up waiting for different I.O. devices, like the disk. If I have multiple programs running, while one of them is waiting for something to happen on the disk, another one can run. If you want to get maximum use out of your CPU, an operating system is really the only easy way to manage that. And… We're done! So this is the last lecture before Reading Week. When we come back, we will be talking about I.O, We have now finished all the material that's covered by the midterm. I encourage you to start thinking about what you're gonna do to study for it. Get together with friends! Practice problems, and good luck with Lab 2. We will be keeping tabs on Teams if you're working on it over reading break, although you've been given enough time to do it without working on it over reading week. As long as you've already started.

Seek back 10 seconds

Pause

Seek forward 30 seconds

Mute
Current Time 
0:20
/
Duration 
1:19:24
 
1x
Playback Rate

Captions

Fullscreen

Picture-in-Picture
