
2025-FALL / ECSE-324-001
Captions
Search current recording by keyword
Brett Meyer, Prof: I really don't want to have to talk that loud today. I think my son… is giving me a cold, and I have a marathon in two and a half weeks, so I want to take care of myself. Please help me take care of myself. By enabling me to not talk too loud today. We are coming to the end of this set of lecture notes on processor design. We'll have a one-shot lecture on Monday on pipelining, and then after that, we'll get into assembly language programming. After today, you should know basically everything that you need to know in order to finish Lab 1. There were people that finished Lab 1 before we started this set of lecture notes, so in theory, 222 also gives you everything that you need to know in order to finish Lab 1. But, the review and the explication here… In Canada, there's this word, keener. This is not a word that I ever heard as an American, but there are some really enthusiastic computer engineers in this class that have finished Lab 1 already and have been done with it for a week or so. But we'll be finishing up the material that you need to be able to do that yourself, if you haven't already, today. la- last time? Finish talking about the arithmetic and logic unit. And we finished talking about memory and interactions with it. The final piece, is control. Control being the big, finite state machine that orchestrates all the different things happening in the data path. I say big finite state machine, when actually it's… Not super big. For your purposes in this class, it's just 5 states. And, again. The way that we're able to do that, and to support such complexity, is that all of the complexity of The task of the computer is essentially offloaded to software. The state machine is software. Because what the computer does, cycle after cycle, is actually pretty straightforward in comparison. So, what we looked at last time, You know, we… For example, for an ad instruction, we had this four-state State machine? Where we decode, execute, perform memory operations optionally, and then write back or update the register file. The control bit here isn't really… Pictured, because we have a new first state that we need. Where we actually go and get the instruction that we're supposed to execute from memory. And the way that that's facilitated, again, is with a special register called the program counter. We've talked about the register file, In some computers. The program counter is in the register file. That's what ARM does. In other computers, the program counter is NOT in the register file. That's, like, what PowerPC and Intel, AMD do. It's a special purpose register, it's not directly accessible. In ARM, We'll get… we'll be looking at that in great detail soon. In ARM, you can do instructions on the program counter. This is not advisable. But it's there in the register file for you to be able to manipulate it like that. The instruction register is not in the register file in any implementation that I've ever seen before. That's another special purpose register. The instruction register is not accessible by software, but it… stores the instruction that we are currently trying to execute. So we use the PC, To index into memory, to get the instruction that we're supposed to execute, and that instruction goes into the instruction register. After that step is done, and we've done the work of the instruction. The program counter is incremented at some point in there to point to the next one. And remember, unless we intervene with a branch instruction, it's always one instruction after the next. 4 bytes after 4 bytes after 4 bytes. Unless something else is going on. In computer engineering, in computer… in computer organization, it's always, we usually do this unless we don't. There are no rules, except for shareholder value. Which translates to metrics like performance or energy efficiency or whatever. Computer engineers are a clever lot. So we have some basic guidelines in place, things that work in general, but then there's nothing that hasn't been done differently before for some particular use case. Yes, Ryan. Can you give me some context for your question? Yeah. So the question has to do with the notion that there can be a mismatch between the definition of a word for a processor and the definition of a word for memory, and I've got bad news. I will attempt to keep things relatively straightforward and fail to do so in this class. Because, again, computer engineering is all about heuristics, and I'll define that word in a second, but… From the view of the processor, from the view of our 32-bit processor. If we say someplace that the 32-bit processor has a byte-addressable view of memory. That's the way that ARM operates. It means that the processor itself operates on 4-byte instructions, and generally operates on 4 bytes of data at a time, but you can individually address single bytes. That is the comp… that is the CPU's view. But the memory might only be addressable in terms of 128 bytes at a time, or 256 bytes at a time, or 4 bytes at a time? And so then, you have something sitting in between the CPU and the memory that enforces the CPU's view. If it says it wants a bite. It will take 128 from memory and deliver a byte. It's kind of like, you order chocolate ice cream, but the truck shows up with all the options, and then just gives you what you asked for. It's all there. But as far as the CPU is concerned, it only gets exactly what it asked for. So… In your Lab 1, yeah, your memory gives you 16 bits at a time, that's the smallest addressable thing. In other computer designs, 128 bytes, or 256, or 512 bytes might be the smallest addressable thing in memory. the CPU still only ever asks for a byte, or 2, or 4, or 8. And then something else… Sorts it out in the, in the, in the middle. Does that answer your question? Yeah. So, it's important… Like, when you do computer system design, oftentimes we take an off-the-shelf processor. And then we interface it with a bunch of other stuff. And so, as the computer engineer, it would be your job to make sure that you understand how much data is coming from memory, how much data is the processor asking for, how do I make those things line up so the expectations match. And you tend to do that with the interconnection network, which we haven't talked about at all yet, but that's the part that sits in between the processor and the memory that does this negotiation. In your case, for Lab 1, there isn't really an interconnection network. You have a direct connection between the instruction memory and the data memory and the parts of the processor that are interacting with it. And so you just have to wire it up in the way that's specified. But, The physical reality in real systems is more complicated. Okay. So that brings us to… Our instruction format. So we've been talking about this word decoding, and the opposite of that is encoding. And I've said last time that the process of decoding Takes an instruction, and then derives the appropriate control signals in each of the steps of execution of the instruction. The encoding tends to be relatively straightforward, to the extent that even for something like ARM, you will see in Lab 2, should you desire, you can actually see how the different operands of your instructions Appear in the bytes of the instruction. As it's encoded in machine language. On the left-hand side, We have the op code. That's a generic catch-all field that says… this specifies what the instruction is supposed to do. So the opcode for an add instruction is going to be different from that for a load instruction, or for a store instruction, and there are other variations that we will also talk about today and later on. After the opcode, Like, the opcode captures… oh, what's an example? The opcode for the add instructions will be the same, the opcode for a load instruction will be different. But after the opcode, the rest of the information there, is encoding operands. So, RD. D is for destination. So, in bytes 15 down to 12, That encodes a 4-bit address in the register file that is used directly as address C in our data path. Do you remember address C? How far back do we have to flip? Right here. So address C is the address in the register file that specifies where the result of the instruction goes. RD, in the instruction, specifies it directly. If I have 4 bits, of RD, How many registers do I have available to me? 16. So, if I have… If I have 4 bits. For RD, it means I can choose one among 16 different registers in the register file. If I want to have a processor with 32-bit registers in the register file, I need 5 bits. I need a bigger instruction. When I go from 32 to 64 bits for an instruction, I have a lot of options for the sorts of information I can encode there, including being able to address a much wider variety of registers. For instance. RN is similar, it is a source register. It goes to address A, 4 bits, encoding a selection of 1 of 16 registers in the register file. And then we've got this funny operand 2. That's an invention of ARM version 7. And… If… We just have a second source register. The most significant bits there, for instance, 11 down to 8, that goes directly to address B. So we have address A, we have address B, and address C. We have a 3-register instruction. We can see directly encoded those registers in the instruction. But operand 2 in ARM version 7 is a flexible field, meaning it can encode or register, or it can encode an immediate value. What's an immediate value again? It's like a constant. It's a constant that I encode in the instruction. If I want to add 7, I can put the number 7 in operand 2. If I want to add negative 4, operand 2. I don't have to first load negative 4 into a register, and then use a register to store it, and use an address or register to get that value. I can put the number in operand 2. Without loss of generality, and for the purposes today, Operand 2 is 12 bits. That means that I can't represent every possible constant. I can represent every possible constant up to… what number? 2 to the 12th, which is… Which is big. Thank you. So it's 2,000 to negative 2000s, and then up to 4 thousand, depending upon whether or not I'm working with a signed or an unsigned integer in that spot. Now, if operand 2 is supposed to be an immediate value, then I've got this i bit there. That needs to be set, and you can see the notation there says that's the value that's passed to IMUX select. I must select… Is what determines whether or not we read from Temporary register RB. Or, if we take the immediate value from the instruction register. And the reason why that's important? is, again, If I'm trying to encode negative 7, The most significant bits of opera N2 are all going to be 1s. This is a negative number. And, therefore, address B is gonna be Register 15. If I want to add negative 7, register 15 is coming out of the register file on output B, and going into RB, where it will be saved, and going into the IMUX. At input zero, But I don't want register 15, I want negative 7. Both options are there at the multiplexer. The IMUX select bit from the instruction makes sure that we get the right value. The one coming out of the instruction register As opposed to the one in the register file that I did not intend to read, but I read anyway for the sake of high-performance hardware. Remember, your processor does everything all at once, everywhere. And then picks the one result that it likes. That's a movie I need to see again. Did you see it? I didn't get the title exactly right. No? Did I get it? I was close, though. Yeah, you got it. One person understood me, I'll take it. It's a great movie. I have, but only… but I feel like I need to see it again, because there's… yeah, it's just one of those… it's like… Fight Club is sort of another interesting movie, very politically accurate for the moment that we're in today. It's another one that you need to see more than once in order to understand what's going on. Anyway. Last thing I'll say here, before we do an example. Again, we've talked about sign extension just really briefly. If what we want to encode in operand 2 is negative 7, It won't work unless I do a sign extension, because I will have 12-bit negative 7, If I just copy that into a 32-bit adder's input with the rest are zero, I'm not going to have negative 7 anymore. I'm going to have a relatively large positive number. So I need to look at the most significant bit in operand 2, And copy that to fill out the space. So that if I'm adding negative 7 to another register value, I actually do that math correctly. Adding negative 7 and 32 bits, even though my representation here just gives me 12. Santiago. The rest of operand 2? So… That's a good question, and I think yes. We could look at the output of an ARM assembler and see, but it need not be zero. Because they're basically don't cares. if IMUX select, If the i bit in the instruction is a zero. then that means I'm going to be using the four most significant bits of operand 2 as address B, and the rest of the bits don't matter, which is interesting. Because… Where we spend energy in a processor is in bit flips. If I have a capacitor that is VDD, and then in the next cycle it's ground, and then the next cycle it's VDD, that's like worst-case energy discharge. So there are researchers that have looked at instruction encodings to try to identify the don't care things to say, if I just change some of these bits. Since the instructions are executing in this known order, then I can reduce the number of transitions on my capacitors and save energy. That's another thing that you can do with don't Cares. But most likely, the ARM version 7 assembler out of the box, would just make them zero. Okay. So, let's… Just to make sure that this is clear, go through an example. We have 3 instructions that we're going to assemble… ish. We don't actually have enough information to fully do this, but we will do our best. We have two add instructions and then a load. And I'm just gonna write them down real quick here. Add… R2, R3… are for… add… R2, R3… Negative 3, and load… R2… R3. Okay. So, the information that we don't have is we don't know what the op code is for our add or our load instruction. So we're not going to try to fill out that part of it. We do see here… that our mmux select bit is bit 24, and our ALU function is 23 down to 21, so we can at least do that. I think add is zeros. So, we have… For the first one, we still have some opcode instructions… opcode bits. That I can't specify, because… We don't know. And then the MMUX select, that's the next bit. So we'll say that this is… Instruction 1, 2, 3, so we'll do one. What is the value for MUX select? What did I just have in my hand? That's disgusting. Anyone have a paper towel that I can use? There was something gross on the chalkboard there. Yeah, that's fine, I'm not gonna come and steal your paper towel. That's very… Thank you very much, I appreciate that. You can always count on the first row. Okay. And Muck Select. We have an add instruction. If we have an add instruction, what is muck select supposed to be? We have an add instruction. Where is our data coming from that we're saving in the register file? William? It's zero, because we want to take the output of the ALU. That is right. So we have a zero. And the next three bits the, the, ALU operation, which I probably need to flip back really far to see. There we go. The ALU function is 0 for performing addition. Okay, so we can… Come back here to our… thing now? So we have… Yeah, I'd be careful. So then we have 000 for our ALU function. The next field… is IMUX Select. For our first instruction, what is IMUX select? Zero, because we are choosing R4, instead of an immediate value, And then… RN, is… N is the address of our first source operand. Yes, we want to access R3, and what do we encode in our instruction in order to do that? 0011. And then the next one is RD, our destination register. Which is… And we encode that, 010… And then, finally, our operand 2 is… What? Pier 10001… it's what? 0, 1, 0, 0, and then we have 8 more zeros. 1, 2, 3, 4, 1, 2, 3, 4. There is our first instruction. The only thing that we don't know is the op code. Op codes are often selected arbitrarily. We'll see a bit more about how it's structured later on. Any questions about that first one? Yes. Remind me your name again? Yeon. Yeon Noon. Okay. Nope. certified extension. Did you… Or, when we do sign extension for the second ad instruction. For the next instruction, or for this instruction? What's excellent, I guess. So we'll get there. Okay. Second instruction, I'm going to start a little bit more over to the left. Again, we've got the op code. And then we have MMUX Select, which is… 0, because it's not a memory access instruction. And then we have the ALU function, which is also the same, because it's still an add. And then we have IMUX select, which is… One in this case, so we are not selecting, RB… address RB from here, we're using it as a intermediate… as an immediate value. Then we have RN. Which is the first source register? Which is the same as before. 0011. And then we have the destination register. Which is also the same as before. And then… We have operand 2. So, operand 2… is negative 3, 3 is 0. It's like that. So what we need is… That plus one. And then we have… That is 12-bit negative 3. So, since it's a 12-bit immediate field, we put our least significant bits over on the right, and then we assign extend to the left. Does that answer your question? Fabulous. So that's, 11111111… 1101. Questions about that one? Instruction number 3. Has a different opcode. MMUX select. What is it in this case? It's 1. We have a load instruction. The MUX is right before the temporary register that saves the result that goes back into the register file. We want to select the data coming from memory, not the data coming out of the ALU. What data is coming out of the ALU when we do a load instruction? Because something's always coming out. It's not unknown. In fact, I could ask you this on an exam. What is coming out of the ALU on a load instruction? The address is… Because in the load instruction, we use the ALU to calculate the address that goes to memory to get the data that comes back that we're selecting to go into the register file. The output of the ALU is known. And sometimes, interesting to keep. ARM version 7 allows us to do a load Where we add a number to a register to calculate the address, and then update the register to that new value. Some computer architectures want to keep both the data coming from memory and the data coming from the address calculation. Both of them. A real useful exercise? is to… For different kinds of instructions. Figure out what the contents are for these different temporary registers. You can see past exam questions that will ask you to do just that. Okay. So, mmux is 1. What is the AOU function for our load instruction? Natasha. Oh, you have a question? Okay. So when we have a load instruction. In our simple load instruction, we're just using a single register, R3, But it could be R3 plus 4, it could be R3 plus R4, Not exactly in this… actually, in this architecture, we could do that. So, the implicit thing here that we're doing is R3 plus 0. R3 is coming out of output A of the register file, going into the ALU. In our example here, since we're adding 0, That's going to be coming from the instruction register as an immediate value. So the ALU is doing R3, plus zero, and that value gets saved in temporary register RZ, which is the address that then gets sent to the processor memory interface. So, I have every… for the last few years since we've had this material where we do, you can expect a question either on the midterm or the final, where I ask you, what are the control signals at different steps of the execution of instructions from a real program that I give you. like the assembly for the Fibonacci sequence. Just go look in the past exams. They're all publicly available. We don't hold anything back from y'all, and then we just rewrite them to keep you on your toes. So, you need to be able to understand how to set the control signals and what the contents are of the different temporary registers as different instructions make their way through. For instance, what's in RZ after the load instructions execute stage? And the answer is, it's whatever was in R3. In this particular case. It's R3 plus 0. Rachel. When you're adding this. forward to the Valiant Arts. So that depends on the assembly language. In ARM, we would do… like, comma. But we would put this in brackets. For ARM. So every different language has a different syntax. In, like, MIPS RISC-V, it's in parentheses. In ARM, we use square brackets, and so on. So this is how we would indicate we wanted to do R3 plus 4, for instance. But what we have here… That is basically an implied Square bracket, comma, Zero. Okay, so we have… MMUX select, we haven't answered this question yet. What is the ALU function? When we are performing our load instruction. It's not subtract, it's not AND, it's not XOR, It's ads. So it's the same. So, the ALU function in our instruction format, it does not specify the operation, right? We have the op code to specify the operation, but lots of different instructions might use add. Store instructions use add. Load instructions use ADD. Add instructions, use ADD? Next is IMUX Select. And since we have this implied plus zero, we need to select an immediate value. Our first source register is R3, again. That is the first source register for the ALU. We're adding R3 and 0. Our destination register is still… R2… And now, our… Operand 2, because we're doing R3 plus 0, It's just zeros. Lucy. the address, spend time by inputting, Is it possible to load from an address and increment at the same time? Yes, but not with… Not with our simple processor here. So… But, like, theoretically. Media value. So… Let's take a step back. There are lots of ways to design processors. This is a very simple one for the purposes of this class. There are ones that are this simple. The ARM Cortex-M0 is a ridiculously simple processor. It is small enough that you could literally build it at the gate level in this class or in ECSE 425. It only executes a handful of different instructions. More complex ones… Can do cooler stuff. Like, allow us to load from an address, and increment A register that we're using for addressing in the same instruction. Why can't I do that here? It is impossible. in this diagram. Charles Edward. Because there's only RW! An instruction that wants to load from memory and increments an address register needs to change two values in the register file. I can only save one of them temporarily here, and on top of that, I can only write one location in the register file at a time. So to be able to do a load instruction, where I increment an address register, I need more ports on my register file, which is exactly what ARM version 7 does. Because it supports these kinds of operations, but it means more complex hardware. And when we add more ports to the register file. We're not adding more registers, but we're adding a bunch more wires. Let's see… So here… You can see the wiring to go from the registers to the outputs. And we only have this input C coming in on the left. If we want to be able to write two different registers at the same time, then we need to have More complex registers that can possibly be written from two different locations, somehow with a DMUX, or whatever. More wiring. You add more wiring, and your circuit grows, because you can't have wires over top of transistors at the level of small modules, like what we're talking about here. Wiring tracks become the limiting resource, makes your design larger, it makes it cost more. Trade-offs. Modern, high-performance computers. Can read 6, or 8, or 10, or 12 registers at the same time, and write 2, 3, 4 locations at the same time. Not necessarily more registers, but a lot more complex interface and wiring, more energy, more costs. In the pursuit of performance. Ryan. That is correct, and why is that the way that things work? And why are… and how are sequential circuits designed? Like, what is… what is the signal? the clock edge. Everything happens on a rising clock edge. So… At the end… Of the fetch stage, we have a rising clock edge, at which point our instruction register Has the instruction that we just read from memory. And its contents can therefore be used to start to set the control signals for the register file. It takes time. For data to… for those signals to, Adjust which registers are appearing at the outputs, and it takes time for that information to arrive at the inputs of the RA and RB flip-flops. And then we have the rising edge, which… Saves it. You talked about timing in 222. The reason why clock periods are the length that they are is because we have to wait a certain amount of time for the combinational logic delay once Our information is available at the start of whatever thing we're doing, whether it's decode, or execute, or whatever. And on top of this, Looking at this picture here. There isn't a lot that's happening in the right backstage. it's less than what happens in the decode stage. In the write-back stage, we're just updating the register file. In the decode stage, we have to read from the instruction register, combinational logic, some of the control signals, and then we can read from the register file We have to always take the step that's longer to help set our clock period. Our clock period length doesn't change based on what's happening. And then the ALU is a real problem. Especially for doing multiplication, because multiplication is extraordinarily time-consuming compared to everything else. The length of period of time for multiplication might set the clock period for the entire processor. Memories can do that, too. If memory is slow. it can set the clock period for the entire processor, making everything slow. Charles Edward. Like… I can't think of you. Patient safety. Yes! They do, for exactly this reason. Multiplications take up multiple clock cycles because I don't want everything to be slow, because multiplies are slow when only 1 out of 20 instructions might be a multiply. For doing machine learning stuff. most instructions are multiplies, but for general purpose software, it's not the case. So we cut up the multiply hardware. into stages, and we pipeline it, which we'll be talking about on Monday. In order to not make processor performance dependent upon a single operation. Does that answer your question? Okay. So, we have a new picture. It's the same picture, except with fetch in there, too. Adding this control stuff around instructions. Gives us our first actual pipeline stage, the fetch stage. And this is almost a complete picture of what the finite state machine looks like for your Lab 1 processor. Almost. The one thing that's missing here is that… All we've considered so far is PC equals PC plus 4, over and over and over again. If your program has no if-else statements, and only for loops with fully defined bounds. This is okay, because we can take your for loop from i equals 0 to 100, and we can unroll it by making 100 copies of the loop body, and we can make a program that only ever just goes to the next instruction forever, and that's fine. But the moment you have any if-else or a while loop. this isn't good enough anymore. We need to have branch instructions. Putin, do you have a question, or are you just… okay. Okay. So what if we have control flow? For instance, What if we wanted to perform a data-dependent operation? We want to implement the max function, we want our result to be A if A is greater than B, otherwise we want it to be B. The two instructions that are doing the work here are the add instructions at the bottom. We want to take, for instance, R0 plus 0 goes into R2, If that's where A is stored. Or we want to do R1 plus 0 goes into R2, if that's where B is stored. And then we need some help figuring out which one of those we're going to execute, and we definitely don't want to execute both. So, it's a branch operation that does this for us. Branch instruction, Always starts with the letter B. And… I'm sorry about this. But one of the really cool things about ARM is that they don't do branched instructions the way that anybody else does. The whole rest of the world doesn't like what I'm going to describe on this slide. And then… In a couple weeks. I'm going to tell you how this is not what ARM version 7 does, and therefore how… not how you're going to write any assembly language programs all semester. So consider this a conceptual introduction. As opposed to a technical one. We structure branch instructions, B, the next two letters, B, G, E, indicate the condition that we're checking. Branch. if… The result of my comparison is… greater than or equal, if that's true. So we have RD and Rn. We want to compare RD and Rn, and see if RD is greater than or equal to Rn, then take the branch. And taking the branch means… You take the relative address, and add it to PC. That allows us to jump forward a few instructions, or jump backward a few instructions. It does not specify a complete address, because we can't. We only have 12 bits here. We can't specify a complete address for the program counter with just 12 bits. So instead, we specify a relative address. Go forward a certain amount, or go backwards a certain amount. So basically what this instruction says is that if the condition I'm testing is true, PC equals PC plus relative address. Otherwise, PC equals PC plus 4, the next instruction. Those are the two options available. And with that, we can do all of the control flow that you're used to writing in C or Java or Python or whatever. You can jump forward for if and else, you can jump backwards for for loops. And so on. We generally have available to us at least branch if equal. But again, depending upon the complexity of the processor, you may or may not have other options. ARM makes a lot of options available. more than what we have here. Greater than, less than, not equal, greater than and equal, less than or equal. And there are other ones that… linguistically don't make as much sense, because ARM version 7 differentiates between comparisons of unsigned integers and signed integers, and the reason it does that is because the overflow condition is different. So we have our picture of our… Fetch control. And we've changed it a bit. Instead of always just doing PC equals PC plus 4, now we have a MUX where we can select between 4, for the thing that we're adding to PC, or an immediate value, which is sign extended, because sometimes we want to jump backwards. We do that all the time for loops. Go 4 plus 4 plus 4 plus 4 plus 4 minus 12. Minus 16. But we never do minus, we just add a negative number. Questions? Lucy. Oh, you said that we can't? Like… Access, memory, or, like, parts of, for example, structured memory out of sync. Hop. But there's, like, nothing hardware-wise that's preventing us from, like. indexed to a really weird location. You see, it's supposed to get 4 bytes each time, but we could theoretically set the immediate value to 3, but every time. So, the question is, Why can't I just… Access and instruction at a odd number. And it is true that nothing from a hardware perspective is preventing you from doing this, but the assembler will not let you do it. The assembler will say… first, the assembler will say. No, you're trying to perform an unaligned, fetch here. That is verboten. And if… if… if you, for some reason. you're, like, if you… in ARM, you can do an add instruction with the program counter. You can say add into PC, PC plus the contents of R2, and maybe R2 has a 3 in it. The compiler, the assembler, can't help you in that particular case, but then the hardware will stop you. The hardware will say, sorry, this instruction address is not divisible by 4, Segmentation fault. It's not exactly a segmentation fault, it's probably a bus fault, or a… some other kind of specified hard fault that stops the execution of your program. It will not allow you to do it. Interdeep. How many other languages can we say prohibited in? But yes. The hardware that we've seen so far wouldn't stop you from doing that, but there are mechanisms in place to prevent you from doing it. One reason is to catch bugs, it's sort of, like, understood that that's not desired operation. Another reason to do it is for security purposes, because of code injection attacks. just makes it a little bit harder to get over the hurdle to be able to inject arbitrary code for the CPU to execute. If you enforce aligned, Accesses for instructions, for instance. Does that answer your question? Other questions here? You can ask me if the person next to you doesn't know the answer. Okay. So… We have these conditions that we check. Equal, not equal, less than, greater than. The ALU is what tells us Whether or not these conditions are met. The instruction encodes the condition that we're checking for. So the instruction will encode, I want a branch if equal. The bit pattern for that is zeros. And if that's the bit pattern that we're… that we're getting out of the instruction register, then that tells us that we need to check to see that Z equals 1. You will implement the hardware that decodes these bit patterns for branch instructions. So that the ALU can tell you the branch should be taken. Based… or the control logic can tell you that the branch should be taken based on the outputs from the ALU when you do the comparison. Ryan. That's what we've told you to do in Lab 1, I think. So… That leads to a difference in how we encode the relative address. So if… And again, ARM does it even differently from this. If in the fetch stage, we do PC equals PC plus 4 all the time. And then in the execute stage, we discover that our condition is true, and we want to add the relative address. It means that the relative address has to be computed based on PC plus 4 plus relative address. the previous value of the PC plus 4 plus the relative address. In ARM, for reasons that I will not explain today, it's PC plus 8 plus relative address. So if… and that means that if you want to branch ahead one instruction, you're actually adding a negative number in ARM because of the way that they've done things. But yes, you have to use whatever the value that PC is gonna be when you change it again based on your branch instruction. Does that answer your question? Exactly. Absolutely. That's right. Okay. So, using the way that we've been talking about instruction coding today. This is what our branch instruction would look like. We encode the condition that the branch instruction is supposed to execute under in the first 3 bits. There's our condition bit patterns. The next one indicates that it's a branch. What kind of branch? MUX select is 0, because it is not a memory access instruction. ALU function is 1. Which is subtract… Because if we perform a subtraction. then we can actually make these comparisons. We do A minus B, and we set our ALU flags, and that will tell us if A is greater than B, or less than, or equal to. IMUX select is 0. We do have an immediate value in the instruction, but we do not want the immediate value to go to our ALU. It's going someplace else. The immediate value is going over there. Note that the immediate value always goes over there. But the multiplexer is such that we will usually select the 4 instead. Because your processor sends current everywhere, all the time, And MUXs are the gatekeepers. Controlled by control signals, From the finite state machine. Register A, sorry, RN and RM are our two source registers. Notice that Instead of having our second source register in operand 2, it is in the place of the destination register this time. So bits 5, 15, down to 12 are not always the destination register. Because everything, everywhere, all the time, B is address C, We don't write to the register file, because register file write enable is zero for this instruction. Otherwise, who knows what would go there, unless I ask you to figure it out for an exam question. because I care, I'm invested in your understanding of the material. And then our immediate value, operand 2, we have, in this example, 12 bits. That means that we can jump forward, or backward. A couple of thousand instructions. Which is… not great. And it's not how things are done, but for the purposes of our example today. It works. ARM version 7 actually uses 24 bits of immediate value out of 32 for its branch instructions. And does some other clever things in order to try to increase the range of a branch instruction as much as possible. Because sometimes you need to move to code that is very far away. from your current PC value. You could conceivably write a loop that is large enough that this immediate value wouldn't allow you to jump all the way back to the beginning of it. Questions? Yes. Yep. Well, so, like, the mucks is always… Using precise language in computer engineering is super important. Because when you say activate, what I hear is turn on. When it's combinational logic, it is always on. There's always going to be… If I'm doing an ad instruction, if I'm doing ad negative 3, The sign extended immediate value from that second add instruction is going to appear at the input of that MUX. But because branch taken is 0, We just add 4 instead. So if you don't get your control signals right, It's chaos. It can be really hard to debug, because you might not understand why numbers are suddenly looking so weird, and it's because there's weird numbers everywhere in your processor. Your processor computes every possible outcome. At the same time, and then selects the right one. With control signals. Did that answer your question? Okay. Computer hardware does not work like software. It is completely parallel, everything happening all at the same time. Whereas… and we can describe the behavior of a computer in hardware like a program, saying, first we do this, and then we do that, and then we do this, but that's not how it works. It's just, like, you open the floodgates, current flows. And capacitors are charged and discharged. And then you have control signals that determine which MUX input is selected to go to the output. Okay. All right. So we had a five-stage We started class basically with a four-stage finite state machine. Now we've got 5. And with branching, we have a few extra paths that we are taking here. Processors don't all do it this way. But if we know at the end of the execute stage. that we will be taking a branch. We don't have to do the rest. It's not obligatory. We can just go directly back to the fetch stage. Whereas if we do take the branch, then we can continue to proceed through the… The flow of the finite state machine. We could rewrite this too, though, for when branches, taken to just continue on and only manipulate how we update the PC If the branch is taken. We're just wasting time going through memory and write-back in that stage, but it doesn't actually change the operation at all, because a branch instruction doesn't do anything in the memory or write-back stages. And as we'll see next time when we start talking about pipelining. Every single stage is executed by every single instruction all the time, because that allows us to have very uniform throughput of instructions through our processor, especially when, if it's a Pentium 4, we might have 20 pipeline stages, or if it's a high-performance ARM processor, and we've got 10 to 15 pipeline stages. We don't try to short-circuit any of the instructions going through, because they all need to just go through, and that's okay. Okay. Alright, so… Going back to our example. Our simple example with a max function. If A is greater than B, we want our output to be A, otherwise we want it to be B. We have our two add instructions. A and B are in R0 and R1. Our result is going in R2. So, we can implement this. By having a branch less than R0, R1… Plus 8. So the branch gets executed if R0 is less than R1. Which is the same as saying A is less than B. If A is less than B, the desired functionality is that our output is B. Ranch, less than R0, R1, plus 8. That jumps us down to the second add instruction. Press 4. plus 8, And plus the 4, from the fact that I incremented my PC in the Fetch stage. The moment I fetch the branch instruction, even before it's decoded, I'm changing PC to be equal to PC plus 4, so then it's pointing to the first add instruction. When I add a plus 8 then, the first plus 4 add points it to the next branch instruction, and the next plus 4 points it to the add instruction. Plus 8 takes me to the second add instruction, even though it's 3 instructions away. Because I always do PC equals PC plus 4. That's what you'll see in Lab 1. ARM actually always does PC plus 4 and then plus 4 again, so you're dealing with plus 8, not just plus 4. If the branch is not taken. PC stays at PC plus 4, and I execute the first add instruction. Why do I need the second branch, the unconditional branch just specified by B? Why is that there? That's right. What's your name? Games. We need the second branch instruction, because we've put R1 into R2, and if we don't jump over the second add, then we're gonna put R1 into R2, which breaks our code. So we have an unconditional branch, a branch with no more letters after the B, that means it always is taken, there's no comparison to make. And it is plus 4, because again, PC equals PC plus 4, always and forever, and then we add another 4 To jump past the ad. So, I have another question. What does the instruction encoding look like for an unconditional branch? Because my branch encoding encodes comparisons that I'm supposed to make, and conditions that I'm supposed to check. How would I encode an instruction that… Anyways. is executed. A branch that is always executed. Lucy? Probably one more. There's an easier way to do it. I don't need to create a new bit pattern. Yeah. That's right. We just check to see if a register is equal to itself. So, to encode a B, an unconditional branch. I can pick any register I want, I can pick register 0. And I can check to see if register 0 minus register 0 Is equal to zero. And that's bit pattern 000. So I can take from my branch. I can encode condition 0, RM is all zeros, RB… our RM is all zeros. And it works just fine. Questions? Okay. So, if there are no more questions… That's it for today. And I will see you on Monday for pipelining.
Play Video
Seek back 10 seconds

Play

Seek forward 30 seconds

Mute
Current Time 
0:03
/
Duration 
1:05:23
 
1x
Playback Rate

Captions

Fullscreen

Picture-in-Picture
