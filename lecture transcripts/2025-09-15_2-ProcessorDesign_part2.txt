
2025-FALL / ECSE-324-001
Captions
Search current recording by keyword
Brett Meyer, Prof: Okay. So, to get started today, We're gonna do a Let's Ask ChatGPT question that came up in last… Lecture notes? And let's see today if you're smarter than ChatGPT when it comes to this question. We were talking about SRAM arrays, you know, arrays of bit cells, We mentioned briefly, Why are they square? Because if I have… A billion addresses. And each of them is a byte. The most straightforward, logical way to do it would be for they'd be 8 bits wide and 1 billion rows long, but that's insane, no one does it. We wouldn't be able to design it. it would be… not great. So… Why do we make them square instead? Why are they square? Muhammad. I think it minimizes the fact that I vote on him. I understand. Making them square… Minimizes the capacitance of the word lines and bit lines in combination. And that allows our memory to be faster than it would be, because if I have a really long bit line, because I have a billion rows. Then we… then I have all of the capacitance from all the transistors sitting on that bit line. That's going to determine how quickly I can read something. You never want a billion things connected to a wire. Very, very, very high capacitance. Capacitance is the problem. So, what ChatGPT says here… is that… We want the… we don't want the array to be very wide, many columns, because then the bit lines have higher capacitance and delay. And we don't want it to be very tall, because then the word lines become very long. I think that's actually backwards, Chad GPT, you got it wrong. And they say higher resistance! Is resistance ever a problem in the circuits that we're talking about in computer organization? No. Resistance is never a problem. Because we have copper. And we can size the copper to make resistance not an issue at all. It's always capacitance when it comes to delay. Once we start talking about off-chip communication and PCBs and crap like that, which we're not really going to discuss in this class, but once that enters into the electronics conversation, resistance can sometimes be an issue, but Inside of computers, basically never. So… If ChatGPT were answering this question on an exam, they might get half credit? not really great. Don't talk about resistance. If I ever ask you about delay, the answer to the question, whatever it's about, is basically capacitance. Always and forever. A couple people came to office hours today to ask about the memory stuff. If you don't, really understands the memory stuff, then you should come and talk to me, too. I'm just gonna skip that one, I think, yeah. And we will do… Our lecture now. Where'd my slides go? There they are. Okay. So, we are in the middle of our… Processor design lecture notes. We've talked about memory, we've started to talk about the processor, and the different operations that we can do. We have done… Most recently, looked at some logical operations, shifting, and stuff like that. And we've talked about adders already. I would really like to not have to talk over y'all. It'll just shred my voice. And so now we're gonna try to put it all together. So, in the… one of the earliest pictures we saw in the previous set of lecture notes of the inside of a computer, we had the ALU, the register file, we had memory. The ALU is a big black box, but we've seen all the different things now that go into it. The ALU is the collection of all the different arithmetic and logical operations that the CPU can do. So it isn't, like, a single thing with a single set of inputs and outputs. As you are seeing in Lab 1, depending on how far along you've gotten, it's actually a whole bunch of different things that are all computing on inputs, and then you have, like, a MUX at the end that picks the output. We tend to draw it with that little trapezoid kind of a thing. If you ever see that kind of diagram, it almost looks like a mux, but it has the little carrot taken out of it at the top. That's the symbol, the universal symbol for an ALU. It has the two inputs, A and B, because if we're going to add two things, we need two inputs. I do know enough of your names to start calling you out if you're talking. But I would love to save us all the embarrassments. If we're doing addition. or if we're ANDing things together, we got our two inputs, A and B. On the left, you see the function input. That's basically saying what's the thing that we want the ALU to do. We get flags that come out on the right. The flags are useful for branch instructions, like we've talked about. If I want to do a branch under certain circumstances, branch greater than or equal to zero. the flags come out, allow me to know whether or not the comparison that I made in the ALU satisfies that condition, and that the branch should be taken. And then you get your actual result out the bottom, Z. So, like we've talked about, like you'll do in Lab 1, the ALU isn't one magical box that does all the things, it's actually a whole bunch of boxes. Each box gets both of the inputs, each box always does the operation, and then it's the MUX R at the end that determines what output we actually see. So that means that… If I have a shift instruction, or an OR instruction. With this organization, I am adding every single time. And yes, that is a waste of energy. But it's also faster than the alternative. Because deciding not to do something here would require more circuitry, which makes everything slower. Computer engineering, for a very long time, was only ever focused on making things faster, Even today, still. Concern about energy or power is secondary to performance. Except in very niche application domains, where you need very ultra-low power, and then we sort of re-architect this so that you don't always add if all you wanted to do was a shift. Or you don't always shift if what you really wanted to do was just an AND. This organization optimizes for performance. Because it means that If I have 6 different units in my ALU, they are all going every single time anything goes to the ALU. Are you with me on that? You understand? It would be like… I don't know what a good analogy is, but it's like, I have… I just… instead of telling you a particular thing to do on an exam, I just say, here are your two inputs, and you divide the labor, everyone does a different operation on it, and you always do it, all the time, even if only one of the answers is actually correct. One of the answers is actually the one that we need to make use of. All the work, all the time. what you're gonna do for Lab 1 is something very similar to this, if not identical, I don't remember exactly. You will have an ALU boxed And inside of that ALU box, you will have all those different things that you're building, and then you will define the function code, according to the Lab 1 spec, for each of those different operations. And we can see that add and subtract have different function codes. Add and subtract each use the add and subtractor. But they get a different function code, because if I go back… let's see, how far back do I have to go? If I go back to here. Add and subtract happen in slightly different ways. If I'm subtracting, I need to use the inverted inputs. And I need to have my carry 0 be equal to 1. Whereas if I'm adding, then I don't. So inside of my ALU, I take the function code. And that function code is decoded into control signals. for the different units inside, so that the MUXs get set up right. So the add or subtractor does the right operation. And then the function also determines which result we get out of R, at R, because I want the output of the add or subtractor when function is 0 and when function is 1. So there's logic that has to be set up accordingly. Combinational logic. There you go. What's… Thank you. Yes. There's an excuse. the CPU, I don't know how far back I'd have to go to get to a picture, but I will draw one. So the simplified picture that we've seen so far of our computer system is we have the CPU, for instance, and memory. And the CPU has… the register file, which we will talk about shortly, and then the ALU, And there's other stuff in there too, but the… the AOU inputs come from the register file, and the AOU output goes to the register file. Sometimes the ALU output goes to memory, other things go to memory, and And so on. But the ALU is a big part of the CPU, that's where all of the data processing happens inside of the CPU. In simple processors, there is exactly one of these. But in high-performance, more complex processors, there's more than one. Because in high-performance, more complex processors, we might actually want to do more than one of these things at the same time. But for our simple processors, we're only ever doing one thing at a time. Lucy. Is that what, like, cores are? Cores are multiple CPUs. But if I have a superscalar core, it means that that core can do more than one instruction at the same time. So it might perform an add and a load at the same time, or an add and a multiply, or even two adds, sort of depending upon how many of these different kinds of boxes I put inside of each CPU. Did that answer your question? Theo, did I answer your question? Other questions? Fair. I should have looked at my watch to see how many steps I had before I started teaching, because my step counter for last Wednesday was really high, despite not actually going for a run, and I'm just kind of curious, am I getting in a thousand steps, just pacing around the classroom while I talk to you? I'm all over the place. I'm gonna lose my stuff. Basic outside interface to the ALU. to these flags. The flags are principally used for things like branches. We talked about branches very briefly. Branch is the instruction that's used to change control flow. Under normal operation, we only ever just get the next instruction. PC equals PC plus 4, forever. But this doesn't allow me to do if-else, it doesn't allow me to do loops. If I want to change to go backwards because I'm doing a loop, or if I want to change to jump forward because I'm doing an if-else, then I need to have a way to manipulate the program counter. And I have to know whether or not now is the right time to do it. With an if-else, Whether or not I do it depends on the data that I'm looking at. That's where these flags come in. Because I might say branch if A is less than B. I can do math. inside of the AOU, I can do a subtraction, in fact, to see whether or not a number is greater than another number, and then I can look at the… the nature of the result. I don't care what the number is, if I'm doing a comparison, I don't care what Z is, the output of the AOU. But I do care whether or not the result is zero. Or if the result is positive. If A minus B is positive, it means that A is greater than B. If A minus B is 0, it means that A is equal to B. And so, if I have different conditions that I'm checking. whether or not the result is positive, or zero, if I have carry, or an overflow, these are the sorts of things that can tell me whether or not my branch is supposed to be taken. So your ALU, in addition to producing these results. It also produces extra outputs based on the nature of the result to identify whether or not the result is negative. Is it zero? Was there a carry generated? An ultimate carry out? Or is there overflow? This can be useful information for branching and for other purposes. So the AOU provides them as outputs. And so will you in Lab 1. Because you implement branch instructions in Lab 1. What I think the branching part of the lab is perhaps Technically, the hardest to get right. You should know, in case you… I don't know how far you are in Lab 1. Lab 1 is divided into tasks. They're not all worth the same amount, and they don't all take the same amount of time. If you remember 222 well, you can probably get through the first half of it pretty quickly. The second half is a lot more complicated. Okay. Let's do an example. We'll make sure that I have the answer. So we've got our ALU, And we have two inputs to it. I'm just gonna push this… Well… Going to erase this. So our inputs are up there, and we have a particular function that is being requested. And we want to know. And so we can see what the appropriate values here are, and let's just check the diagram, and then we'll try about… we'll try a subtraction. So… That function, 010, corresponds to… and… And… So we're doing a bitwise AND of A and B, which means that any place there's a 1 in both of those positions, you get a 1 in the output. What is 1 000? Because the first position is the only one where we both have… where they both have a 1. Otherwise, they're inverses of each other. So that is the output Z, and then the flags… The first flag is a 1. Why? Why is the first flag a 1? Ryan. So the number is negative. What makes it negative? Ed… The most significant bit is a 1, and that's all you have to check to know whether or not a number is negative. And the next bit is… the next flag is Z. For zero? And the answer is not zero, because if it were zero, it would be all zeros. The other two flags? What does X mean? in Digital Logic, Theo. Don't care. And what does that mean? Muhammad. It means, as far as the designer is concerned, it is undefined for this operation. From an electrical perspective, Is it ever undefined? No, it isn't. It will always be a 0 or a 1. But having the X there means that when I'm doing combinational logic optimization, I don't care if it's a 0 or a 1, because nothing that's consuming that value is going to be looking at those bit positions. But remember, we're talking ultimately about The voltage across capacitors There's no such voltage across a capacitor that we call X. The voltage across every capacitor in our carefully curated digital world is either VDD or ground. Anything else is bad behavior. That we're going to ignore in this class, because we like things… Neat and simple. And if you feel like you can do things in the analog way, you can make more money than your digital peers, go take Professor, Gordon Roberts' analog design class. Mixed signal engineers at the boundary between nice and neat digital and physics make about 30% more than digital system designers. Not because… It's easier. So, what if we were doing a subtraction instead? If we were doing a subtraction. Then our function would have to be different, it would be a 1. And then, to do subtraction, We've got A minus B, How do I set up the math here… I can't… I don't actually have a subtractor. I have an adder, With a funny interface. Yes. So that gives me 0010, but I add 1, so there. I'm gonna add these two things. Which gives me a 1, 0, carry, 1, 1. So, there's my answer. For my subtraction, for A minus B, And we'll… we'll do it again. I did not have a carry-out. So, what is my end flag? One, the number's negative. What is my Z flag? 0, because my number is not zero. How about my carry flag? C. 0, because I didn't have a carryout. And how about my V flag for overflow? Zero! So we have… Our two inputs, Are the same sign? And… my results… Just like you will. I get confused by overflow, too, so we're going to be systematic about this, and we're going to check our answer. So… what we have for B, is… Negative 3. And 0101 plus 1 gives us 011. So this is negative 5. We have negative 5 plus negative 3. Which should give us negative 8, which should be representable. Is that… 0010… No, we're doing… well, we're doing subtraction, yeah. I remember taking my linear algebra class. And the professor made an arithmetic error on the board, and someone said, excuse me, and it's like, and she said. Well… This isn't an arithmetic class. Unfortunately, I can't have that same excuse, because I have tried to teach you or remind you about binary arithmetic, but… I'm going off-script here, so whether or not… if I… whether or not I make any mistakes is sort of an open question. So this is… we… so actually, yeah, I was… we add it, and then we add one, which gives us that. So… Negative 7… Sorry, 7. This should be fine. Because the sign is the same. Tania. You're gonna do great on the midterm. Actually, I've already written the midterm, I don't remember if I've asked the question on overflow, but maybe I have. See, that's helpful information, though, because you're right, because we're not actually adding a negative number and a positive number, we're not actually adding two negative numbers, is what I mean. So… If we're gonna… if we ever add a negative number and a positive number, is overflow possible under any circumstance? No, it's not. Because you will always just move closer to zero. Thank you. If I could give extra credit points for helping me out, I would, but there's, Equity, diversity, and inclusion issue with that, because not everybody's in the room. So let's just go over that real quickly again, and I'll get your question, Ed. It is possible. That's a… that's a kind way to tell me that you think I'm wrong. 0101 plus 1… Yep. That's negative 6. And then the original one is negative 3, which we turn into positive 3, so our results should be negative 3, and we can check that, 0010 plus 1, 3. Thank you, Ed. That would be a… you get, you get, like, an achievement. Like, internet points makes you feel good, but they're not worth anything. Other questions about this? No overflow, because the two things that we are adding are one's positive, the other's negative. Overflow is impossible. If they were both negative, we would check the sign of our result, and if they were positive, we'd have a problem. Overflow. If they were both positive and the sign of our result was negative, we'd have a problem. Overflow. I suppose the question is whether or not Chad GPT would have made the same mistake that I was about to. Probably not. I'm gonna move on from this, unless there are other questions. Okay. All right. Do we have an ALU? It can do a bunch of different stuff. What's… our CPU has to do a whole bunch of different stuff. In order, based on inputs and temporary values and so on. Because your program is more than just Hey, add these two numbers together, please. So how do we manage that? If we want to do something like X plus Y minus Z, I can only do X plus Y in one step. that gives me a result, and then I can do that result minus Z in a subsequent step. But that's two different operations. So, two different function codes. in two different clock cycles, I'm gonna need a finite state machine. In order to be able to manage this. I have to be able to order those operations, and I need some sort of storage. Which brings us to a first discussion about how we integrate control with all this combinational logic. So here, we have a really simple, not very good computer that we're gonna design to be able to do just a few operations in a row. We've got our data path, Instead of a full-blown register file, I just got 3 registers on the top. And one at the bottom. I can save my 3 inputs X, Y, and Z in those registers. And then I have a finite state machine that has some control signals coming out. MUX A control, MUX B control, and up. OP is the function input for the ALU. And so… I can make a simple finite state machine to try to do X plus Y minus Z. And there it is, over on the right. If I order my output, vector, MXA, MXB, and then OP, the output of each of the states is there below the state name. You see it? So we start an ad. The operation for add is all zeros. And we want… MXA… to be… 0, and MXB to be 1. Because I want to read… X and Y, and add them. The result of that, at the end of the clock cycle, gets saved in the temporary register. And then, for the next state, when I'm going to do, subtraction. I have to have my subtract function in there, that's the 001 at the end. But then I want MUX input… MUX A input 1, because that's where the temporary value goes back to the MUX. I don't want to be… taking X, I want to be taking temp as my input. and then I also have to flip the MUXB value, so I get Z instead of Y. Now my simple ALU can do two operations in a row. The operations are different, the inputs are different. And I can satisfy my desired program, X plus Y minus Z. And did I ask ChatGPT to do that? I'm just gonna look real quick. ChatGPT is not great at finite state machine design. I did. We'll just show this real quickly. So… I gave it the picture. I uploaded the picture, provided the text. Said, consider the block diagram, draw the finite state machine. for the box labeled control to perform X plus Y minus Z, and I asked for all the outputs and whatever. And… It gave me a concise summary at the end, thankfully. But it did not do a very good job. It got the MUX outputs incorrect. And did a bunch of extra stuff, extra stuff that I didn't want it to. And it even, like, made up… Some outputs that didn't exist, Zero points. Oops. In other words, it did not do as well as I expect you would, based on your knowledge of 222. Questions about this? So with this simple finite state machine, we can program our data path to do exactly this operation, and only this operation. For arbitrary X, Y, and Z, we can do X plus Y minus Z. Which is great, if that's the only program that you ever write. What if we want to do something more complicated? How about we want to do… we want to take X and shift it left by Z, and take Y and shift it left by Z, and add those two things? In that case, we have to perform the shifting of X, then the shifting of Y, and then the addition. I don't have enough temporary storage anymore. because I only have the one temporary register at the bottom, I need some place to store my shifted X for when I shift my Y. I can't do it with this one. What if I want 4 inputs? I want X shifted left by Z, Y shifted left by W, and then I want to add those. I need 4 inputs, and 2 temporary storage locations. But I… don't have that many. What's the solution to this problem? We have already named it. It has been in some of our diagrams, like the one that I erased. What's the solution to this problem? It starts with the letter R. Registers, or the register file. The register file is the block of sequential logic. That we use for all this temporary storage, and it's also where we keep our inputs before we do data processing on them. Here we are. If you were looking at the notes, you could have just flipped ahead one slide, and you'd have the answer right there. Okay. So… We've got this problem. We need a variable number of inputs and temporary storage locations if we want to execute arbitrary code. We need a place to be able to store it. Because we're doing a load store architecture. We don't want to do this storage in actual memory. So, when I talk about these constraints and what the ideas are, this is in the context of a risk processor. You can make a processor without a register file, it just only has to work with memory. And that would make it a sisk architecture, and that's not what we're building in this class. We're building risk architectures where we only work on things, we do data processing on register values. So we're going to group a bunch of registers inside of the register file. And then we're gonna have a decoder for that, and have muxes all over the place that control which values go where in our systems, that we can do arbitrary operations on data from the register file and put it back into arbitrary places, and then we can do whatever we want with our programs. The basic picture is like this, at least from a logical standpoint. You can see we've got 8 registers in this case. A register is just a collection of bits. In our 32-bit processor, each register is 32 bits. You can write 32 bits to it, you can read 32 bits from it, And if I want… To be able to get two operations at once, or two data values at once to go to my ALU. I've got two outputs for my register file, each of which can be from any of the registers in it. Now, We've drawn this picture like this. But actually, the registers in a real register file are an SRAM bit cell array. They're not individual boxes like that in real hardware. It's a box. It's an SREM array like we looked at last time. But from a logical perspective, this picture's fine. We just wouldn't build it like this, because that kind of suggests that we're maybe building it out of flip-flops or something, and that's a terrible idea. We would use the bit cell array like we saw last time around. So, our register file… Has two outputs, A and B. We provide two addresses to pick what those outputs ought to be, address A, address B. That picks which of the register values appear over there. And then we also have inputs over here, because the only way we solve our problem with temporary storage is by allowing us to write values back into the register file, too. So the output of the ALU can go back into the register file, the output value goes in at C, and the address that we want to put it in goes in address C. But only when we have write enable. We don't have a read enable, because read is non-destructive. We have a write enable because write is destructive. Writing gets rid of the old values there. And we don't want to do that all the time. So now, we can draw our data path like this. We don't have to have… A certain number of temporary input registers and output registers. The input and output registers are always and forever just in the register file. And… Modern processors might have 16 or 32 or more registers in the register file. Which is a largest number, but way smaller than memory. Remember, memory has billions of locations. The register file has a small number of locations, because we care about the performance of the register file, whereas memory can just be slow, we fix that in other ways. So, just like back here. We have this finite state machine in order to order the operations and select appropriate values to go into the ALU. Even with our more fancy data path, we still need that. If we want to do X plus Y minus Z, we still need a control. But now, our control can be set up to be kind of arbitrary. It doesn't matter where X, Y, and Z are stored in my register file, I can develop the appropriate control signals in order to be able to carry that out. Spoiler alert, that's exactly what the assembler does when it translates your assembly into machine code. And when you start writing assembly programs for Lab 2, you'll be doing that too, basically. You'll say, well, I'm gonna put this variable in this register, and this variable in this register, and then I'm gonna add them and put the result in this register. And as you encode that in instructions, the assembler will turn it into the bits that are in the instructions that are decoded by the control that control the data path and execute your program. Ayyy… I'm going to skip this. And I would encourage you to do it on your own. It's kind of like… Writing a simple program. Which you're gonna get a lot more practice on in Lab 2. Okay. So… Walking around too much. So far, The little programs that we've written I'll have named variables, X, Y, and Z. The assumption is that X, Y, and Z can take on any value that is within the representable range for our processor. If our processor's a 32-bit processor, X, Y, and Z can be between 0 and 4 billion-ish. Positive-negative numbers, negative 2 billion-ish, positive 2 billion-ish. What if I… Always want to add 7. And what if that's what I want to encode? Instead of saying X plus Y minus Z, I want X plus Y minus 7. The way that we deal with that is what's called an immediate value. The reason we deal with it this way is because it's more efficient. What I could do in the X plus Y minus Z case, if I go back far enough. I could have an extra step. That always ensures that the number 7 is exactly what goes into the register where I saved Z. But that takes an extra instruction. And instead, what I can do is… I can put the number 7, in the instruction. It can come from the instruction, it can essentially come from control, and then go and be just a separate input to one of our MUXs before the ALU. You'll see, as we make our processor more complicated, the number of inputs to the front of the ALU will grow and grow and grow. We just need bigger and bigger multiplexers there to control for all the different things that we might want to send through the ALU. The first drawing has just the output of the register file going to the ALU. But each of those multiplexers you'll see when you make your own processor are going to be able to take more than one different input based on the kind of operation that you're trying to do. If I always want to be subtracting 7, That 7 gets encoded in the instruction, it comes from control directly, it never goes to the register file. Because that would take extra steps, That's bad for performance. But now I need to have an extra multiplexer, which means I need to have an extra control signal, so that when I have an instruction that's subtracting 7 instead of subtracting Z, I pick the appropriate I put from invalue going into the MUX instead of coming out of the register file. Let's see… Maybe we'll do… this one. No, we won't do that one. We had… we used immediate values all the time in computing. If you have a for loop. where you do I equals I plus 1, The plus 1 is an immediate value. We don't have an add one instruction, but we have an add immediate instruction. We also have an add register instruction. And depending upon the values, information just flows through differently. We're gonna change subjects rather dramatically now. Are there any questions about data path, or control, or anything else that we've talked about so far? Yes. Yes. Right. So… After we talk about processor design. In Lecture Notes 2, we're going to talk about pipelining in Lecture Notes 3. And it's related to that. In this design, Everything happens in a single clock cycle. We have a rising edge of clock. Control goes to a new state, We have new outputs. And we read from the register file, data process in the ALU, and write to the register file in a single clock period. Your processor for Lab 1 Does everything in 5 steps. Touch, decode, execute, memory, write back. And we… the reason why your Lab 1 processor will do that is that that's essentially what all processors do. Sometimes it's 3 steps, 3 clock cycles, sometimes it's 20 steps, 20 clock cycles, but we divide operations across time. A single instruction, in your case, takes 5 clock cycles to perform, which means that if I'm going to do it in that way, I need registers between the register file and the ALU, because I read the register file in one clock cycle, and then I execute in the next clock cycle. Temporary registers are needed just to hold those values so that they can be processed in the next. And then I have an output register at the ALU. It holds the value, because I'm not writing back to the register file just yet. I don't want the numbers to just go away. Typical ARM processors, sort of embedded ARM processors, do this in three steps, fetch, decode, execute. sort of standard mid-range processors since the 80s do it in 5, fetch decode, execute memory write-back. The Pentium 4 did it in 20, in part because it's reading memory for multiple clock cycles, executing for multiple clock cycles. Decode was broken into two steps. And then, since then, the number of steps required has sort of settled out between 10 and 20. But it's a design choice, but it's related to this that you have the temporary registers. Does that answer your question? Did you have a question, William? Like, what's stopping, not just making it one clock cycle? What's stopping designers from just making it one clock cycle? Performance. Performance is the issue. And we will talk about that in great detail in the third set of lecture notes, but the basic issue is that, If I want to do it in a single… if I want to do everything in one step, it means that I'm using the register file and the ALU in the single clock cycle to do just one thing. But if I put a register in between. The beauty of pipelining is that I can have… I can be reading the register file for one instruction. And then at the same time, doing the execute step for the instruction right before it. So, a Pentium 4 with 20 pipeline stages can have 20 instructions going at the same time. And the clock cycle is very short, because the amount of combinational logic that has to go in each clock cycle is relatively small. Whereas if I do a single cycle processor, my clock cycle is as long as everything all together, even though it's not all being used at the same time, because you have the information sort of flowing from left to right here. Did that answer your question? Fabulous. Lucy? Are we the people influencing the control node? Are we the people influencing the control node? Only if you show up and vote. like, the rest of it is fairly automated, but it's automated by the control node. Are we using something to control the control node, or are we, in essence. We're assembly, automating the… So, that's a good question. The control here… If we were to look inside, it would have the instruction register. So in the fetch step, I use the program counter to read an instruction from memory, that data goes into the instruction register, and then the contents of the instruction register is used by combinational logic to determine what all of those control signals are supposed to be. So, if I'm… if I'm trying to add X and Y, and X is in R0, and Y is in R1, I'm going to encode The register address 0 and 1 in my instruction. And then the control combinational logic reads those bits out of the instruction register, and then twiddles the outputs of the control block accordingly. So then, yes, you do determine what happens in the control by writing your program, and it's because the control is very systematic, Read from memory, decode IR, increment PC. read from memory, decode an IR, increment PC. The computer itself is very simple. With respect to that, it's software complexity that is essentially infinite. Does that answer your question? Santiago. With… with this set? I would say that modern processors have much more complex set of functions that's available. For instance, I think, Yasim asked. But maybe I don't remember. Someone asked about a rotate, where you don't lose a bit off the other side. So we don't have a rotate listed here. We don't have multiply listed here. And, There's a lot more cool stuff that we can do with our ALU if we're willing to bear the hardware complexity. So, every ALU will have a function table, but depending upon the instructions that are supported, it'll be longer or shorter. Yes. Yes. Yes. Great question. So the question is, if I have a bunch of different cores, can they have different functions supported in their ALUs? And the answer is absolutely yes. And we've actually done this, we meaning computer engineers, since the very early 2000s. What you're talking about is a heterogeneous multiprocessor. the multiprocessors, the multi-core systems in your phones and iPads and laptops are… From a software perspective, homogeneous multiprocessors, every core is the same. But at the same time, each of those same computers is a heterogeneous multiprocessor, because you have something special for decoding video, you have something special for decoding audio, and in, In TVs, and in cars, and basically any embedded device, the different processors have been tailored to particular tasks. They are not anymore super general purpose, and when you write software for them, you program them knowing what the different features are of each core. But in a general-purpose, high-performance standpoint, you would only ever use homogeneous multiprocessors, where they're all the same. Makes programming easier, but it gives up some performance and… at the same time. Does that answer your question? Fabulous. You should take parallel computing and computer architecture. If you ever want to know more than what we cover in this class, parallel computing, computer architecture. Okay. Alright, we're gonna talk about memory. Again, and not for the last time. Alright, so… We've been looking at controlling data path. And I've been alluding to where… All the control information comes from. It comes from our program, which is stored in memory. That's also where data comes from. We haven't really gotten into that in our drawings yet. We've talked about how in a load store architecture, we have load operations, store operations, and in between, we do our data processing. So the way that our data path is going to work is that before we can do a thing in our AOU, we have to read from memory. We happen to use the ALU to help with that. And then after we read from memory, and we do a thing in the ALU, then we need to store it back into memory. We also use the ALU to help with that. And the sequencing of the operations is also stored in memory. When we say fetch, we mean read from memory. When we say load, we mean read from memory. When we say store, we mean stored to memory. Memory is integral to our load store architecture working properly. So we can redraw our picture like this. And now we see some of our temporary registers appearing, like magic, because we have decided, between these slides, to start doing things in more than one clock cycle. Maybe for… Next fall, it'll look different, because Kristoff and I have talked about… Kristoff is the… he teaches the class the other semester in general. Talked about introducing this in a slightly different way, because you're right. There's a little bit of a mismatch between Lab 1 and what we had talked about so far, and the rationale for this doesn't really show up until the next set of lecture notes. But just bear with me, and it'll all be fine. So now we have, down here on the bottom right, our processor memory interface. The processor memory interface takes an address as an input, and it has data as an input and output. when I read an instruction, I'm getting it from memory, but that's not pictured here. When I perform a load, I'm getting it from memory 2. And the way that I do that is I first calculate the address that I want to load from by reading two registers, or possibly a register and an immediate value. The address will be calculated in the ALU, saved temporarily in RZ, You'll never hear me call it the other way. Zed? Ugh. I've held this line with my kids, they say Z, even though they both live most of their lives here. We have an RZ, the address, which goes down to the processor memory interface, We wait a clock cycle. At the end of the clock cycle, we get the appropriate data coming back. Now, for an ALU operation. like an add or a subtract, or an AND or an OR, the output of RZ is what needs to go back into the register file. But on a load instruction, I have this new MUX now. MMUX, my data is coming out and going into the first… the number 1 input instead of the number 0 input, and it's that that goes into RW to go into my register file. So if I have a load. I read from the register file to calculate my address in the ALU, data comes out of the memory interface, into RW, and back into my register file. Then if I do a… if I do processing on it, I read from the register file, do the math in the ALU, the result gets saved into RZ, then RW, and goes back into the register file. And then I want to store… where I calculate the address in the ALU, And… In this particular drawing, because I don't have enough inputs to my MUX, to my ALU, the different MUXs, I can only ever store in the exact address specified by your register. Because if you look at what's happening here. If my store address has to go into RA, And then it has to be added with Nothing… Because what's happening, or I guess it can be added with what's coming from the immediate value. Because what's coming out of RB? has to be the thing that I'm sending to memory. The path from the register file to memory is from input B… from output B… good catch. Output P, the bypass around IMUX to RD, down to the processor memory interface. Register file to memory. You're looking at me like you don't understand, which is fine, we'll get there. Yes? We have IMUX there. Because sometimes I want to encode a value in an instruction, rather than figure out first how to get it into a register and then use it. And actually, it helps us out a lot Right now, when we want to try to store, Because… when I'm doing a store, I calculate the address in the ALU, I can give the base address. And then I could say, base address plus 4, because if I have an array. An array is defined by the address for element 0, And then however many entries I have. If it's an array of integers, the first element is that X plus 0. The second element is at X plus 4, X plus 8, X plus 12. And I can do that here. I can store to… Different elements of an array in order by having a loop. That says, store in the… And the address specified by a particular register. That gets added to zero the first time from the immediate inputs. And the value that I'm actually storing has to come out of the register file at output B, and it goes around the IMUX into RD and down into the processor memory interface. Does that answer your question? Okay. I've… Talked about that. So we've added these different temporary registers, because we are now formally dividing each of the steps… we're dividing the processing in two steps, the same steps that we've talked about. And we need registers to hold the values as they flow through the processor. This isn't really necessary for our processor design, because you're not going to do pipelining. If you come to 425, we will definitely do hardware design with pipelined processors in that class. And now we have a whole bunch of extra control signals that we have to include, because we don't want RA and RB to be written all the time, only when they're supposed to be taking values from the previous hardware. So… Again, we don't have the interface for fetching pictured here, but during the decode step. I read from the register file. whatever's supposed to be coming out of A and B, and being saved in RA and RB. So during decode, RA and RB enable are high. Then, in the execute step, which is right after, we're doing the work in the AOU and saving it in RZ. We are also saving the bypass in RD. RD always has a copy of RB just one cycle later. We do that so that we can take a value from the register file and send it to memory. If I have an add instruction, What ends up in RD? Yeah. Just whatever your second operand is. We could make the control logic for RD more complicated, so that it's only high when we're doing a store. But we could also just make it really simple and make RD high every single time we're in the execute stage of our processor, which means that RD will always have something in it, RD will always, always have something in it. But it'll always have… what was ever in RB, even if it never gets used for anything. Remember, the organization of our processor is for performance, which means that every path, everywhere, all the time has values in it, and the multiplexers are there to decide, I want this value, and I want this value, and everything else, all the redundant computation, all of the redundant charging and discharging, just happens, and we ignore it. with multiplexers. Okay. The use of our processor memory interface also means we have some additional control signals there. We don't want to write to memory, except for when we really want to, because otherwise we will change things, and that's bad. So that's why we have the memory write signal. The memory read signal? doesn't really matter very much, except for the fact that if I don't send the memory read, then I can not perform a read operation in my SRAM logic, and that will save me some energy. That's like a little memory… that's a little energy optimization to have a memory read, instruction… a control signal here. Memory complete is there, because memory is slow. In a modern processor, it takes 100 to 200 clock cycles to read from memory. Which means that your processor is just sitting and waiting. Until the value that it wants comes back. That is for both instructions and data. The memory complete signal here is what the processor memory interface uses to indicate your data's ready now. In Lab 1, You're going to assume that you can read your memory in a single cycle, which makes interacting with memory a lot more straightforward. But in real life, that's not how it works for most computer systems. Though… We don't have fetch pictured here. And so we can update our finite state machine to look like this. We just have… we start everything at decode. We'll insert the fetch step later. Decode, again, is when we read the register file. Execute is when we use the ALU. Memory is when we interact with the memory, if the instruction requires that we do so. And write back is when we update the contents of the register file. So we have all of our control signals down on the left, and the different stages across the top of our table. So if we want to implement… 4 plus R5 goes into R3. That instruction is ADD, R3, R4, R5. The destination register is on the left for the assembly languages that we will be considering in this class. And so, then we fill out the control signals as such. During decode. Address A should be 4, and address B should be 5. So, we see the two… That, that picks out… Let's see… The appropriate register values from the register file. at the MUXs, so that we get the values out of the register file that we want. And then, in that stage, we also want RA writeEnable and RB writeEnable to be 1, because we want to read from the register file and save those values temporarily in those two registers. The other… The other control signals for the temporary registers are zero. Their contents aren't changing. Memory and mem-write are zero, because, those contents… oops, went too far. Those… we're not interacting with memory for this instruction. All the other values there are X's. Because we don't care what they are in this particular clock cycle. AOU function can be in X right now. The ALU is doing something, it's combination of logic, it can't help it. But it doesn't matter, because RZ, write enable, is 0. The ALU is doing stuff, But we're not saving the result anywhere. If they're flipping, no one cares. Except for Hydro-Quebec. Because every time a bit flips, Hydro Quebec sends you a bill. Does he have to charge it or discharge it? Execute! Same stuff is going on. We don't care about… the register file in the execute stage, though, so I don't care what address A, B, or C is. I don't care what the immediate value is. I do care what the inputs to the ALU are, though. So if I'm adding. And I'm adding two registers, I want the zero input to IMUX, and I don't… I get the other one automatically, and I want my function to be for add. So my function is add, IMUX select, 0, and those are the only control singles there that matter. And then we have RZRide enable and RD write enable 1. Which means that those two temporary registers get updated, and then the other registers don't get updated, and the other signals up there are don't cares, because we don't care. And this continues on. Memory is really straightforward in this operation because it is not a memory instruction. Nothing happens. Except for RW rightEnable, because we need to copy from RZ into RW. And what do we want to copy? We want to copy whatever's coming into the zero input of NMUX. Which is the only thing that is set. All the others are, don't care. It's a memory stage, but all we're doing is just passing information through it, because it's not a memory instruction. Finally, write back, where do we write back to? Well, we're saving our result in R3, address C is 3, nothing else matters, and the only other thing we care about is for the register file, we want to enable writing to it. And then we've saved our results. One simple instruction and four complicated steps. Muhammad. Yes. So address C, address A, and address B, in the case of an add instruction, are all coming from the instruction register. For other instructions, they might be decoded from the contents of the instruction register, rather than coming directly. But in ARM version 7, which is what you're going to be programming in. for a 3-operand add, each of those operands is encoded directly in the instruction. When you're looking at the binary, you can see where they are in the instruction. How about for a load? We're just gonna talk about what's different here. So, when we have an ad. We take our inputs from the register file to the ALU, we ignore the processor memory interface, and we write directly back into the register file. And we have… MUX select 0, MUX select 0, and the memory control function, the memory control outputs are also 0. Memoried and mem-write, zeros. You can sort of see what's changing here when we flip back and forth. The first thing that you'll notice, and the first thing that I'm pointing to, is that mem read is 1 in the memory stage only. Whereas it was zero before. That tells the memory that it should care about what the address is and give us data. And NMUX Select is 1. And that's gonna change what goes into RW. Because when I perform a load. When I perform load into R2, what is at address… R5? We read R5, which has a memory address, that goes through… RA, and then it passes through the ALU, added with 0 from the immediate input. At least I'm hoping that's what we have selected here. Yes, we have… we read a 0 from the immediate, and I must select as 1. And so… plus zero is in RZ, and that goes to address. And then what comes back is the data that we read from memory. Memoried is 1, MMUX select is 1, The data from memory is what goes into the register file at address 2, specified in address C over in the write-back stage. So, an add instruction and a load instruction are almost the same As far as what the hardware is doing. There's just a little bit of redirection of information. I'm still… I do… I do an addition in the ALU. In each case, Just different kinds of inputs. And then I write something back to the register file in each case, just sourced from different locations in the processor. Muhammad. No. So, you see the register transfer language up on the right? F5 is our index into memory. So whatever R5 specifies an address, whatever's at that address, that comes from memory, and then that goes into R2. Maybe it's the number 3254. Which will be different than the address that we used to get it. Yes, and remind me your name? Say it again? Da noon? And, like, if I wanted to make… if I wanted to make R… R2 equal to R5, Yeah, if I wanted to make R2 equal to R5, I could do load, I could do add. R2, R5… 0? And then R5 plus 0 would go into R2. And that's the same math that's happening in our ALU here, except I'm not saving R5 plus 0 into R2, I'm saving whatever's at the memory location defined by R5 plus 0 into R2. Does that make sense? Yes. Yes. Yeah. The value in R5 is the index into memory. You can think of memory as a massive array. Okay. Talked about that. Alright, and we've kind of talked about this too… oh, there's a typo. I'm just gonna… Write that down real quick. There. Okay. So, the load operation that we had here… dang. The load operation was just from R5, But we can do… the R… the gist from R5, we're still doing a memory address calculation, we're just doing R5 plus 0. We could do R5 plus 4 instead. And that would mean that our immediate value is 4, and IMUX would still be to get the immediate value, not the value out of the register file. And, that allows us to actually do Two different things at the same time. We can perform math, For our address calculation and read memory, In the same instruction. Muhammad. So the question is, what if R5 is negative? What happens? So… Addresses, memory addresses, are unsigned. There is no negative address. We go from 0 to… 4 billion-ish, instead of negative 2 billion to positive 2 billion. Now, I say unsigned, but you can add a negative number to an address. But we just, whenever we have an address in a register, we consider it to be an unsigned number. Does that answer your question? Awesome. Okay. Let's see. Alright. So, we have talked about… a four-step operation, But… In the previous set of lecture notes, we did talk about fetch. And we have talked about… this control thing… That is specifying the control signals in order to sequence our operations. And we've talked about how inside of that is an instruction register that has the instruction, and that the instruction is used to figure out what the control signals ought to be. So where does all that stuff come from? That's all happening in the fetch stage. And this is what gives… A processor the ability to execute anything? The fact that we can put an arbitrary program, an arbitrary sequence of operations in memory somewhere, and the processor can execute it, and it doesn't have to do anything different to execute your code, or your code, or your code. It just does the same operations over and over again, and as long as it does that, all of your code will run just fine. as long as you've tested it properly, and so on. But the… We don't have a super complicated finite state machine, because the super complicated finite state machine Is in your software. The finite state machine for the processor is really straightforward. It is basically that, except with one extra stage to the left called Fetch. Five states. That's it. All the complexity is hidden in your software. The way that we traverse the finite state machine, it depends on your software. The transitions are not fully specified in hardware, except for batch, decode, execute, memory, write back. All the variation between your program and another program, it's encoded in the software. In order to do this. We need a few extra things that hadn't been pictured so far in the last few slides. One is a program counter that keeps track of where in your program we are, or more specifically, what memory location has the instruction that we are supposed to be executing now. And then the instruction register. The instruction register is where we save a copy of the instruction that we're executing now. So that we can decode it to produce all the control signals. So we have this extra hardware that we need to add. Plus, some more stuff that's not pictured here yet. We have a program counter, Every single time we execute an instruction, we increment it by 4, Unless we're doing a branch. They snuck out before I could say goodbye. Or maybe they were waiting to see if they could come in for the next class? I don't know. The program counter… Also, indexes into memory. telling us where the next instruction should come from. We read from the… we read the instruction from memory, and that goes into the instruction register, and it's from the instruction register that we get Register file address A, address B, address C, We may or may not get the ALU function directly, sometimes that has to be decoded from other things, but all the information that we need in order to know what ALU function And are we reading from memory? Are we writing to the register file? All of the information we need for that is encoded in the instruction, which is in the register file… sorry, in the instruction register. Can we say PC plus 4? We are assuming… That each instruction is how big? Four baits! 32 bits. Instructions can be 16 bits, Instructions can be 64 bits, depending upon the processor. In general, when you specify the size of an instruction for a processor, it only has that size, but ARM likes to be different. For, you know, efficiency. So ARM actually can have 16-bit instructions or 32-bit instructions, which means that sometimes we add 2, other times we add 4. Your Lab 1 processor will only ever add 2, because your instructions are how big? 16 bits. And… We will take a look at this next time. See you on Wednesday!

Seek back 10 seconds

Pause

Seek forward 30 seconds

Mute
Current Time 
0:24
/
Duration 
1:19:33
 
1x
Playback Rate

Captions

Fullscreen

Picture-in-Picture
